{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caffc7c0-53b5-40b0-bd0d-984bca9a1dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train_lm.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train_lm.yaml\n",
    "\n",
    "lm_conf:\n",
    "    nlayers: 2\n",
    "    unit: 650\n",
    "\n",
    "token_type: bpe\n",
    "bpemodel: data/bpemodel/bpe.model  # path to BPE model if using BPE\n",
    "token_list: data/bpemodel/tokens.txt\n",
    "\n",
    "optim: sgd        # or adam\n",
    "batch_type: sorted\n",
    "batch_size: 16    # batch size in LM training\n",
    "max_epoch: 20     # if the data size is large, we can reduce this\n",
    "patience: 3\n",
    "\n",
    "best_model_criterion:\n",
    "-   - valid\n",
    "    - loss\n",
    "    - min\n",
    "\n",
    "keep_nbest_models: 1\n",
    "use_matplotlib: false\n",
    "use_tensorboard: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7596b62-2840-482b-8382-df39d1211250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package cmudict to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
     ]
    }
   ],
   "source": [
    "from espnet2.text.build_tokenizer import build_tokenizer\n",
    "from espnet2.text.token_id_converter import TokenIDConverter\n",
    "from pathlib import Path\n",
    "\n",
    "def create_lm_shape_files(\n",
    "    text_file: str,\n",
    "    shape_file: str\n",
    "):\n",
    "    \"\"\"Create shape files for language model training in ESPnet2.\n",
    "    \n",
    "    Args:\n",
    "        text_file: Input text file (utt_id + text)\n",
    "        shape_file: Output shape file path\n",
    "    \"\"\"\n",
    "    # Build tokenizer (ESPnet2 style)\n",
    "    tokenizer = build_tokenizer(\n",
    "        token_type=\"bpe\",\n",
    "        bpemodel=\"data/bpemodel/bpe.model\",\n",
    "        non_linguistic_symbols=None,\n",
    "        delimiter=None,\n",
    "    )\n",
    "    \n",
    "    # Create converter (though we only need tokenization here)\n",
    "    converter = TokenIDConverter(\n",
    "        token_list=\"data/bpemodel/tokens.txt\",\n",
    "    )\n",
    "    \n",
    "    with open(text_file) as fin, open(shape_file, \"w\") as fout:\n",
    "        for line in fin:\n",
    "            utt_id, text = line.strip().split(maxsplit=1)\n",
    "            tokens = tokenizer.text2tokens(text)\n",
    "            fout.write(f\"{utt_id} {len(tokens)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61498267-9c13-459f-b23d-6abb51eaafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_lm_shape_files(\n",
    "    text_file=\"dump/train/text\",\n",
    "    shape_file=\"dump/train/text_shape\"\n",
    ")\n",
    "\n",
    "create_lm_shape_files(\n",
    "    text_file=\"dump/valid/text\",\n",
    "    shape_file=\"dump/valid/text_shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9a6899-67bc-4499-8f1e-0f142010d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r exp/lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e227da35-e0f2-4871-967c-a02eee076029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/espnet/bin/python /opt/conda/envs/espnet/lib/python3.10/site-packages/ipykernel_launcher.py -f /home/jovyan/.local/share/jupyter/runtime/kernel-6f82f57f-22f0-4d61-9c6c-3aa0064d9d21.json\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:19,472 (lm:199) INFO: Vocabulary size: 1000\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,069 (abs_task:1383) INFO: pytorch.version=2.5.1, cuda.available=True, cudnn.version=90100, cudnn.benchmark=False, cudnn.deterministic=True\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,070 (abs_task:1384) INFO: Model structure:\n",
      "ESPnetLanguageModel(\n",
      "  (lm): SequentialRNNLM(\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (encoder): Embedding(1000, 650, padding_idx=0)\n",
      "    (rnn): LSTM(650, 650, num_layers=2, batch_first=True)\n",
      "    (decoder): Linear(in_features=650, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model summary:\n",
      "    Class Name: ESPnetLanguageModel\n",
      "    Total Number of model parameters: 8.07 M\n",
      "    Number of trainable parameters: 8.07 M (100.0%)\n",
      "    Size: 32.29 MB\n",
      "    Type: torch.float32\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,070 (abs_task:1387) INFO: Optimizer:\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0.0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.0\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,070 (abs_task:1388) INFO: Scheduler: None\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,078 (abs_task:1397) INFO: Saving the configuration in exp/lm/cy/rnn/config.yaml\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,211 (abs_task:1807) INFO: [train] dataset:\n",
      "ESPnetDataset(\n",
      "  text: {\"path\": \"dump/train/text\", \"type\": \"text\"}\n",
      "  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fca282c6cb0>)\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,212 (abs_task:1808) INFO: [train] Batch sampler: SortedBatchSampler(N-batch=482, batch_size=16, shape_file=dump/train/text_shape, sort_in_batch=descending, sort_batch=descending)\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,213 (abs_task:1809) INFO: [train] mini-batch sizes summary: N-batch=482, mean=16.0, min=16, max=17\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,222 (abs_task:1807) INFO: [valid] dataset:\n",
      "ESPnetDataset(\n",
      "  text: {\"path\": \"dump/valid/text\", \"type\": \"text\"}\n",
      "  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fc7c66e0670>)\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,222 (abs_task:1808) INFO: [valid] Batch sampler: SortedBatchSampler(N-batch=327, batch_size=16, shape_file=dump/valid/text_shape, sort_in_batch=descending, sort_batch=descending)\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,222 (abs_task:1809) INFO: [valid] mini-batch sizes summary: N-batch=327, mean=16.0, min=16, max=17\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,222 (abs_task:1496) INFO: --use_matplotlib false => Changing --num_att_plot to 0\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,223 (trainer:311) INFO: 1/20epoch started\n",
      "/opt/conda/envs/espnet/lib/python3.10/site-packages/espnet2/train/trainer.py:609: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:20,936 (trainer:780) INFO: 1epoch:train:1-24batch: iter_time=0.004, forward_time=0.007, loss=6.895, backward_time=0.002, grad_norm=0.155, clip=0.000e+00, loss_scale=1.000, optim_step_time=3.860e-04, optim0_lr0=0.100, train_time=0.030\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,038 (trainer:780) INFO: 1epoch:train:25-48batch: iter_time=4.995e-05, forward_time=0.001, loss=6.861, backward_time=0.001, grad_norm=0.153, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.181e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,135 (trainer:780) INFO: 1epoch:train:49-72batch: iter_time=4.872e-05, forward_time=0.001, loss=6.828, backward_time=0.001, grad_norm=0.170, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,235 (trainer:780) INFO: 1epoch:train:73-96batch: iter_time=4.906e-05, forward_time=0.001, loss=6.784, backward_time=0.001, grad_norm=0.178, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.168e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,334 (trainer:780) INFO: 1epoch:train:97-120batch: iter_time=4.907e-05, forward_time=0.001, loss=6.735, backward_time=0.001, grad_norm=0.207, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.137e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,434 (trainer:780) INFO: 1epoch:train:121-144batch: iter_time=4.893e-05, forward_time=0.001, loss=6.652, backward_time=0.001, grad_norm=0.253, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,531 (trainer:780) INFO: 1epoch:train:145-168batch: iter_time=4.887e-05, forward_time=0.001, loss=6.479, backward_time=0.001, grad_norm=0.353, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.145e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,629 (trainer:780) INFO: 1epoch:train:169-192batch: iter_time=4.838e-05, forward_time=0.001, loss=6.308, backward_time=0.001, grad_norm=0.377, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.138e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,734 (trainer:780) INFO: 1epoch:train:193-216batch: iter_time=4.835e-05, forward_time=0.001, loss=6.257, backward_time=0.001, grad_norm=0.388, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.144e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,830 (trainer:780) INFO: 1epoch:train:217-240batch: iter_time=4.873e-05, forward_time=0.001, loss=6.052, backward_time=9.975e-04, grad_norm=0.408, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.132e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:21,925 (trainer:780) INFO: 1epoch:train:241-264batch: iter_time=4.910e-05, forward_time=0.001, loss=5.945, backward_time=9.906e-04, grad_norm=0.440, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.139e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,027 (trainer:780) INFO: 1epoch:train:265-288batch: iter_time=4.998e-05, forward_time=0.001, loss=5.980, backward_time=0.001, grad_norm=0.418, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.139e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,130 (trainer:780) INFO: 1epoch:train:289-312batch: iter_time=4.761e-05, forward_time=0.001, loss=5.920, backward_time=0.001, grad_norm=0.435, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.176e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,228 (trainer:780) INFO: 1epoch:train:313-336batch: iter_time=4.808e-05, forward_time=0.001, loss=5.834, backward_time=0.001, grad_norm=0.422, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,329 (trainer:780) INFO: 1epoch:train:337-360batch: iter_time=4.782e-05, forward_time=0.001, loss=5.821, backward_time=0.001, grad_norm=0.417, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.153e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,430 (trainer:780) INFO: 1epoch:train:361-384batch: iter_time=4.838e-05, forward_time=0.001, loss=5.759, backward_time=0.001, grad_norm=0.470, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.146e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,529 (trainer:780) INFO: 1epoch:train:385-408batch: iter_time=5.280e-05, forward_time=0.001, loss=5.735, backward_time=0.001, grad_norm=0.452, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.180e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,632 (trainer:780) INFO: 1epoch:train:409-432batch: iter_time=4.689e-05, forward_time=0.001, loss=5.778, backward_time=0.001, grad_norm=0.479, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,733 (trainer:780) INFO: 1epoch:train:433-456batch: iter_time=4.748e-05, forward_time=0.001, loss=5.704, backward_time=0.001, grad_norm=0.515, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.155e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:22,830 (trainer:780) INFO: 1epoch:train:457-480batch: iter_time=4.790e-05, forward_time=0.001, loss=5.718, backward_time=0.001, grad_norm=0.504, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:23,669 (trainer:365) INFO: 1epoch results: [train] iter_time=2.560e-04, forward_time=0.002, loss=6.198, backward_time=0.001, grad_norm=0.360, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.287e-04, optim0_lr0=0.100, train_time=0.005, time=2.63 seconds, total_count=482, gpu_max_cached_mem_GB=0.213, [valid] loss=5.733, time=0.81 seconds, total_count=327, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,042 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,043 (trainer:299) INFO: 2/20epoch started. Estimated time to finish: 1 minute and 12.57 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,175 (trainer:780) INFO: 2epoch:train:1-24batch: iter_time=5.967e-04, forward_time=0.001, loss=5.698, backward_time=0.001, grad_norm=0.485, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.281e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,273 (trainer:780) INFO: 2epoch:train:25-48batch: iter_time=5.235e-05, forward_time=0.001, loss=5.655, backward_time=9.994e-04, grad_norm=0.525, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.168e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,374 (trainer:780) INFO: 2epoch:train:49-72batch: iter_time=5.186e-05, forward_time=0.001, loss=5.709, backward_time=0.001, grad_norm=0.563, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.173e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,476 (trainer:780) INFO: 2epoch:train:73-96batch: iter_time=5.058e-05, forward_time=0.001, loss=5.704, backward_time=0.001, grad_norm=0.526, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.178e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,575 (trainer:780) INFO: 2epoch:train:97-120batch: iter_time=5.052e-05, forward_time=0.001, loss=5.682, backward_time=0.001, grad_norm=0.520, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,673 (trainer:780) INFO: 2epoch:train:121-144batch: iter_time=5.054e-05, forward_time=0.001, loss=5.637, backward_time=0.001, grad_norm=0.579, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.169e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,775 (trainer:780) INFO: 2epoch:train:145-168batch: iter_time=5.372e-05, forward_time=0.001, loss=5.663, backward_time=0.001, grad_norm=0.553, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.207e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,876 (trainer:780) INFO: 2epoch:train:169-192batch: iter_time=5.104e-05, forward_time=0.001, loss=5.678, backward_time=0.001, grad_norm=0.542, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.157e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:24,974 (trainer:780) INFO: 2epoch:train:193-216batch: iter_time=4.966e-05, forward_time=0.001, loss=5.613, backward_time=0.001, grad_norm=0.634, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,072 (trainer:780) INFO: 2epoch:train:217-240batch: iter_time=4.709e-05, forward_time=0.001, loss=5.598, backward_time=0.001, grad_norm=0.576, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.144e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,174 (trainer:780) INFO: 2epoch:train:241-264batch: iter_time=4.635e-05, forward_time=0.001, loss=5.636, backward_time=0.001, grad_norm=0.587, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.163e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,275 (trainer:780) INFO: 2epoch:train:265-288batch: iter_time=4.694e-05, forward_time=0.001, loss=5.595, backward_time=0.001, grad_norm=0.561, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,374 (trainer:780) INFO: 2epoch:train:289-312batch: iter_time=4.845e-05, forward_time=0.001, loss=5.562, backward_time=0.001, grad_norm=0.696, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.165e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,471 (trainer:780) INFO: 2epoch:train:313-336batch: iter_time=4.799e-05, forward_time=0.001, loss=5.539, backward_time=9.873e-04, grad_norm=0.620, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.144e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,570 (trainer:780) INFO: 2epoch:train:337-360batch: iter_time=4.750e-05, forward_time=0.001, loss=5.578, backward_time=0.001, grad_norm=0.699, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.190e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,668 (trainer:780) INFO: 2epoch:train:361-384batch: iter_time=4.685e-05, forward_time=0.001, loss=5.618, backward_time=0.001, grad_norm=0.604, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,769 (trainer:780) INFO: 2epoch:train:385-408batch: iter_time=4.699e-05, forward_time=0.001, loss=5.607, backward_time=0.001, grad_norm=0.644, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,869 (trainer:780) INFO: 2epoch:train:409-432batch: iter_time=4.894e-05, forward_time=0.001, loss=5.561, backward_time=0.001, grad_norm=0.611, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.181e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:25,970 (trainer:780) INFO: 2epoch:train:433-456batch: iter_time=4.803e-05, forward_time=0.001, loss=5.596, backward_time=0.001, grad_norm=0.600, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:26,069 (trainer:780) INFO: 2epoch:train:457-480batch: iter_time=4.728e-05, forward_time=0.001, loss=5.531, backward_time=0.001, grad_norm=0.688, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.144e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:26,916 (trainer:365) INFO: 2epoch results: [train] iter_time=7.636e-05, forward_time=0.001, loss=5.624, backward_time=0.001, grad_norm=0.590, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.169e-04, optim0_lr0=0.100, train_time=0.004, time=2.05 seconds, total_count=964, gpu_max_cached_mem_GB=0.213, [valid] loss=5.574, time=0.82 seconds, total_count=654, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,277 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,280 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/1epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,281 (trainer:299) INFO: 3/20epoch started. Estimated time to finish: 1 minute and 3.52 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,415 (trainer:780) INFO: 3epoch:train:1-24batch: iter_time=6.045e-04, forward_time=0.001, loss=5.589, backward_time=0.001, grad_norm=0.599, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.282e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,517 (trainer:780) INFO: 3epoch:train:25-48batch: iter_time=4.842e-05, forward_time=0.001, loss=5.572, backward_time=0.001, grad_norm=0.642, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.188e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,616 (trainer:780) INFO: 3epoch:train:49-72batch: iter_time=4.689e-05, forward_time=0.001, loss=5.545, backward_time=0.001, grad_norm=0.731, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,715 (trainer:780) INFO: 3epoch:train:73-96batch: iter_time=4.803e-05, forward_time=0.001, loss=5.542, backward_time=0.001, grad_norm=0.773, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.162e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,814 (trainer:780) INFO: 3epoch:train:97-120batch: iter_time=4.631e-05, forward_time=0.001, loss=5.527, backward_time=0.001, grad_norm=0.635, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.133e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:27,911 (trainer:780) INFO: 3epoch:train:121-144batch: iter_time=4.702e-05, forward_time=0.001, loss=5.490, backward_time=9.941e-04, grad_norm=0.678, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.164e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,011 (trainer:780) INFO: 3epoch:train:145-168batch: iter_time=4.755e-05, forward_time=0.001, loss=5.514, backward_time=0.001, grad_norm=0.770, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,112 (trainer:780) INFO: 3epoch:train:169-192batch: iter_time=4.817e-05, forward_time=0.001, loss=5.504, backward_time=0.001, grad_norm=0.728, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,213 (trainer:780) INFO: 3epoch:train:193-216batch: iter_time=4.630e-05, forward_time=0.001, loss=5.507, backward_time=0.001, grad_norm=0.655, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.138e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,313 (trainer:780) INFO: 3epoch:train:217-240batch: iter_time=4.778e-05, forward_time=0.001, loss=5.480, backward_time=0.001, grad_norm=0.700, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.145e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,409 (trainer:780) INFO: 3epoch:train:241-264batch: iter_time=4.630e-05, forward_time=0.001, loss=5.444, backward_time=9.751e-04, grad_norm=0.727, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.126e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,510 (trainer:780) INFO: 3epoch:train:265-288batch: iter_time=4.743e-05, forward_time=0.001, loss=5.511, backward_time=0.001, grad_norm=0.649, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.155e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,611 (trainer:780) INFO: 3epoch:train:289-312batch: iter_time=8.234e-05, forward_time=0.001, loss=5.503, backward_time=0.001, grad_norm=0.701, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.134e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,708 (trainer:780) INFO: 3epoch:train:313-336batch: iter_time=4.783e-05, forward_time=0.001, loss=5.455, backward_time=9.999e-04, grad_norm=0.799, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.136e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,808 (trainer:780) INFO: 3epoch:train:337-360batch: iter_time=4.734e-05, forward_time=0.001, loss=5.513, backward_time=0.001, grad_norm=0.678, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:28,906 (trainer:780) INFO: 3epoch:train:361-384batch: iter_time=4.677e-05, forward_time=0.001, loss=5.469, backward_time=0.001, grad_norm=0.750, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.127e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:29,005 (trainer:780) INFO: 3epoch:train:385-408batch: iter_time=4.822e-05, forward_time=0.001, loss=5.456, backward_time=0.001, grad_norm=0.738, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:29,107 (trainer:780) INFO: 3epoch:train:409-432batch: iter_time=4.717e-05, forward_time=0.001, loss=5.520, backward_time=0.001, grad_norm=0.729, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.131e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:29,206 (trainer:780) INFO: 3epoch:train:433-456batch: iter_time=4.632e-05, forward_time=0.001, loss=5.500, backward_time=0.001, grad_norm=0.766, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.140e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:29,303 (trainer:780) INFO: 3epoch:train:457-480batch: iter_time=4.674e-05, forward_time=0.001, loss=5.469, backward_time=9.856e-04, grad_norm=0.729, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.138e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,159 (trainer:365) INFO: 3epoch results: [train] iter_time=7.675e-05, forward_time=0.001, loss=5.506, backward_time=0.001, grad_norm=0.708, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004, time=2.05 seconds, total_count=1446, gpu_max_cached_mem_GB=0.213, [valid] loss=5.494, time=0.83 seconds, total_count=981, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,527 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,530 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/2epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,531 (trainer:299) INFO: 4/20epoch started. Estimated time to finish: 58.41 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,667 (trainer:780) INFO: 4epoch:train:1-24batch: iter_time=6.170e-04, forward_time=0.001, loss=5.489, backward_time=0.001, grad_norm=0.618, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.248e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,769 (trainer:780) INFO: 4epoch:train:25-48batch: iter_time=4.757e-05, forward_time=0.001, loss=5.469, backward_time=0.001, grad_norm=0.703, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.189e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,869 (trainer:780) INFO: 4epoch:train:49-72batch: iter_time=4.654e-05, forward_time=0.001, loss=5.473, backward_time=0.001, grad_norm=0.760, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.197e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:30,970 (trainer:780) INFO: 4epoch:train:73-96batch: iter_time=4.722e-05, forward_time=0.001, loss=5.406, backward_time=0.001, grad_norm=0.766, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.168e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,093 (trainer:780) INFO: 4epoch:train:97-120batch: iter_time=5.037e-05, forward_time=0.002, loss=5.487, backward_time=0.001, grad_norm=0.781, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.274e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,193 (trainer:780) INFO: 4epoch:train:121-144batch: iter_time=4.609e-05, forward_time=0.001, loss=5.420, backward_time=0.001, grad_norm=0.691, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.139e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,294 (trainer:780) INFO: 4epoch:train:145-168batch: iter_time=4.589e-05, forward_time=0.001, loss=5.438, backward_time=0.001, grad_norm=0.698, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.135e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,403 (trainer:780) INFO: 4epoch:train:169-192batch: iter_time=5.321e-05, forward_time=0.001, loss=5.433, backward_time=0.001, grad_norm=0.779, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.218e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,504 (trainer:780) INFO: 4epoch:train:193-216batch: iter_time=4.705e-05, forward_time=0.001, loss=5.448, backward_time=0.001, grad_norm=0.701, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,602 (trainer:780) INFO: 4epoch:train:217-240batch: iter_time=4.634e-05, forward_time=0.001, loss=5.421, backward_time=0.001, grad_norm=0.706, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.116e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,699 (trainer:780) INFO: 4epoch:train:241-264batch: iter_time=4.506e-05, forward_time=0.001, loss=5.367, backward_time=0.001, grad_norm=0.737, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.114e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,801 (trainer:780) INFO: 4epoch:train:265-288batch: iter_time=4.705e-05, forward_time=0.001, loss=5.420, backward_time=0.001, grad_norm=0.909, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:31,902 (trainer:780) INFO: 4epoch:train:289-312batch: iter_time=4.668e-05, forward_time=0.001, loss=5.430, backward_time=0.001, grad_norm=0.649, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.107e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:32,005 (trainer:780) INFO: 4epoch:train:313-336batch: iter_time=4.614e-05, forward_time=0.001, loss=5.425, backward_time=0.001, grad_norm=0.676, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.105e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:32,102 (trainer:780) INFO: 4epoch:train:337-360batch: iter_time=4.642e-05, forward_time=0.001, loss=5.408, backward_time=0.001, grad_norm=0.829, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.108e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:32,201 (trainer:780) INFO: 4epoch:train:361-384batch: iter_time=4.610e-05, forward_time=0.001, loss=5.441, backward_time=0.001, grad_norm=0.719, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:32,302 (trainer:780) INFO: 4epoch:train:385-408batch: iter_time=4.575e-05, forward_time=0.001, loss=5.396, backward_time=0.001, grad_norm=0.648, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:32,403 (trainer:780) INFO: 4epoch:train:409-432batch: iter_time=4.545e-05, forward_time=0.001, loss=5.445, backward_time=0.001, grad_norm=0.705, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.110e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:32,503 (trainer:780) INFO: 4epoch:train:433-456batch: iter_time=4.622e-05, forward_time=0.001, loss=5.395, backward_time=0.001, grad_norm=0.781, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.123e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:32,600 (trainer:780) INFO: 4epoch:train:457-480batch: iter_time=4.657e-05, forward_time=0.001, loss=5.382, backward_time=0.001, grad_norm=0.770, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.112e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:33,448 (trainer:365) INFO: 4epoch results: [train] iter_time=7.530e-05, forward_time=0.001, loss=5.431, backward_time=0.001, grad_norm=0.731, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004, time=2.1 seconds, total_count=1928, gpu_max_cached_mem_GB=0.213, [valid] loss=5.418, time=0.82 seconds, total_count=1308, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:33,827 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:33,830 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/3epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:33,831 (trainer:299) INFO: 5/20epoch started. Estimated time to finish: 54.43 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:33,962 (trainer:780) INFO: 5epoch:train:1-24batch: iter_time=6.071e-04, forward_time=0.001, loss=5.378, backward_time=0.001, grad_norm=0.703, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.232e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,066 (trainer:780) INFO: 5epoch:train:25-48batch: iter_time=4.826e-05, forward_time=0.001, loss=5.372, backward_time=0.001, grad_norm=0.677, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.237e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,167 (trainer:780) INFO: 5epoch:train:49-72batch: iter_time=4.857e-05, forward_time=0.001, loss=5.376, backward_time=0.001, grad_norm=0.762, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.184e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,267 (trainer:780) INFO: 5epoch:train:73-96batch: iter_time=4.826e-05, forward_time=0.001, loss=5.393, backward_time=0.001, grad_norm=0.786, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.171e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,366 (trainer:780) INFO: 5epoch:train:97-120batch: iter_time=4.714e-05, forward_time=0.001, loss=5.339, backward_time=0.001, grad_norm=0.720, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.173e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,467 (trainer:780) INFO: 5epoch:train:121-144batch: iter_time=4.724e-05, forward_time=0.001, loss=5.357, backward_time=0.001, grad_norm=0.800, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,571 (trainer:780) INFO: 5epoch:train:145-168batch: iter_time=4.944e-05, forward_time=0.001, loss=5.417, backward_time=0.001, grad_norm=0.685, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.178e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,672 (trainer:780) INFO: 5epoch:train:169-192batch: iter_time=4.888e-05, forward_time=0.001, loss=5.339, backward_time=0.001, grad_norm=0.719, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.199e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,775 (trainer:780) INFO: 5epoch:train:193-216batch: iter_time=4.764e-05, forward_time=0.001, loss=5.364, backward_time=0.001, grad_norm=0.744, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.174e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,876 (trainer:780) INFO: 5epoch:train:217-240batch: iter_time=4.858e-05, forward_time=0.001, loss=5.360, backward_time=0.001, grad_norm=0.811, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:34,980 (trainer:780) INFO: 5epoch:train:241-264batch: iter_time=4.838e-05, forward_time=0.001, loss=5.378, backward_time=0.001, grad_norm=0.713, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.174e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,079 (trainer:780) INFO: 5epoch:train:265-288batch: iter_time=4.912e-05, forward_time=0.001, loss=5.331, backward_time=0.001, grad_norm=0.826, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,179 (trainer:780) INFO: 5epoch:train:289-312batch: iter_time=4.872e-05, forward_time=0.001, loss=5.317, backward_time=0.001, grad_norm=0.793, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.175e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,276 (trainer:780) INFO: 5epoch:train:313-336batch: iter_time=4.807e-05, forward_time=0.001, loss=5.291, backward_time=0.001, grad_norm=0.788, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,379 (trainer:780) INFO: 5epoch:train:337-360batch: iter_time=4.998e-05, forward_time=0.001, loss=5.305, backward_time=0.001, grad_norm=0.753, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.169e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,479 (trainer:780) INFO: 5epoch:train:361-384batch: iter_time=4.857e-05, forward_time=0.001, loss=5.350, backward_time=0.001, grad_norm=0.718, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.169e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,578 (trainer:780) INFO: 5epoch:train:385-408batch: iter_time=4.749e-05, forward_time=0.001, loss=5.361, backward_time=0.001, grad_norm=0.782, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.136e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,675 (trainer:780) INFO: 5epoch:train:409-432batch: iter_time=4.680e-05, forward_time=0.001, loss=5.289, backward_time=0.001, grad_norm=0.696, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.125e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,775 (trainer:780) INFO: 5epoch:train:433-456batch: iter_time=4.703e-05, forward_time=0.001, loss=5.346, backward_time=0.001, grad_norm=0.793, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.119e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:35,877 (trainer:780) INFO: 5epoch:train:457-480batch: iter_time=4.614e-05, forward_time=0.001, loss=5.381, backward_time=0.001, grad_norm=0.706, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:36,746 (trainer:365) INFO: 5epoch results: [train] iter_time=7.593e-05, forward_time=0.001, loss=5.352, backward_time=0.001, grad_norm=0.748, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.167e-04, optim0_lr0=0.100, train_time=0.004, time=2.07 seconds, total_count=2410, gpu_max_cached_mem_GB=0.213, [valid] loss=5.338, time=0.84 seconds, total_count=1635, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,133 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,136 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/4epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,136 (trainer:299) INFO: 6/20epoch started. Estimated time to finish: 50.74 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,268 (trainer:780) INFO: 6epoch:train:1-24batch: iter_time=6.260e-04, forward_time=0.001, loss=5.296, backward_time=0.001, grad_norm=0.781, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.248e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,368 (trainer:780) INFO: 6epoch:train:25-48batch: iter_time=4.729e-05, forward_time=0.001, loss=5.321, backward_time=0.001, grad_norm=0.824, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.136e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,466 (trainer:780) INFO: 6epoch:train:49-72batch: iter_time=4.722e-05, forward_time=0.001, loss=5.305, backward_time=0.001, grad_norm=0.736, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.122e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,564 (trainer:780) INFO: 6epoch:train:73-96batch: iter_time=4.649e-05, forward_time=0.001, loss=5.326, backward_time=0.001, grad_norm=0.830, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.138e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,663 (trainer:780) INFO: 6epoch:train:97-120batch: iter_time=4.663e-05, forward_time=0.001, loss=5.303, backward_time=0.001, grad_norm=0.789, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.127e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,757 (trainer:780) INFO: 6epoch:train:121-144batch: iter_time=4.640e-05, forward_time=0.001, loss=5.176, backward_time=9.828e-04, grad_norm=0.783, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.125e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,856 (trainer:780) INFO: 6epoch:train:145-168batch: iter_time=4.641e-05, forward_time=0.001, loss=5.308, backward_time=0.001, grad_norm=0.817, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:37,957 (trainer:780) INFO: 6epoch:train:169-192batch: iter_time=4.522e-05, forward_time=0.001, loss=5.313, backward_time=0.001, grad_norm=0.671, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.131e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,053 (trainer:780) INFO: 6epoch:train:193-216batch: iter_time=4.618e-05, forward_time=0.001, loss=5.216, backward_time=9.883e-04, grad_norm=0.834, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.116e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,158 (trainer:780) INFO: 6epoch:train:217-240batch: iter_time=4.532e-05, forward_time=0.001, loss=5.339, backward_time=0.001, grad_norm=0.690, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.105e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,256 (trainer:780) INFO: 6epoch:train:241-264batch: iter_time=4.574e-05, forward_time=0.001, loss=5.233, backward_time=0.001, grad_norm=0.841, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.121e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,353 (trainer:780) INFO: 6epoch:train:265-288batch: iter_time=4.587e-05, forward_time=0.001, loss=5.258, backward_time=0.001, grad_norm=0.793, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.114e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,455 (trainer:780) INFO: 6epoch:train:289-312batch: iter_time=4.654e-05, forward_time=0.001, loss=5.286, backward_time=0.001, grad_norm=0.818, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.111e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,555 (trainer:780) INFO: 6epoch:train:313-336batch: iter_time=4.572e-05, forward_time=0.001, loss=5.278, backward_time=0.001, grad_norm=0.760, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.124e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,654 (trainer:780) INFO: 6epoch:train:337-360batch: iter_time=4.625e-05, forward_time=0.001, loss=5.267, backward_time=0.001, grad_norm=0.805, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.121e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,753 (trainer:780) INFO: 6epoch:train:361-384batch: iter_time=4.578e-05, forward_time=0.001, loss=5.293, backward_time=0.001, grad_norm=0.822, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.114e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,851 (trainer:780) INFO: 6epoch:train:385-408batch: iter_time=4.610e-05, forward_time=0.001, loss=5.212, backward_time=0.001, grad_norm=0.809, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.114e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:38,950 (trainer:780) INFO: 6epoch:train:409-432batch: iter_time=4.566e-05, forward_time=0.001, loss=5.221, backward_time=0.001, grad_norm=0.786, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.108e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:39,050 (trainer:780) INFO: 6epoch:train:433-456batch: iter_time=4.567e-05, forward_time=0.001, loss=5.268, backward_time=0.001, grad_norm=0.790, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:39,149 (trainer:780) INFO: 6epoch:train:457-480batch: iter_time=4.561e-05, forward_time=0.001, loss=5.248, backward_time=0.001, grad_norm=0.815, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:39,983 (trainer:365) INFO: 6epoch results: [train] iter_time=7.497e-05, forward_time=0.001, loss=5.274, backward_time=0.001, grad_norm=0.789, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.126e-04, optim0_lr0=0.100, train_time=0.004, time=2.04 seconds, total_count=2892, gpu_max_cached_mem_GB=0.213, [valid] loss=5.271, time=0.81 seconds, total_count=1962, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,366 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,369 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/5epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,369 (trainer:299) INFO: 7/20epoch started. Estimated time to finish: 47.01 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,497 (trainer:780) INFO: 7epoch:train:1-24batch: iter_time=5.972e-04, forward_time=0.001, loss=5.180, backward_time=0.001, grad_norm=0.874, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.249e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,594 (trainer:780) INFO: 7epoch:train:25-48batch: iter_time=4.705e-05, forward_time=0.001, loss=5.178, backward_time=0.001, grad_norm=0.854, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.164e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,694 (trainer:780) INFO: 7epoch:train:49-72batch: iter_time=4.679e-05, forward_time=0.001, loss=5.241, backward_time=0.001, grad_norm=0.807, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.185e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,794 (trainer:780) INFO: 7epoch:train:73-96batch: iter_time=4.764e-05, forward_time=0.001, loss=5.207, backward_time=0.001, grad_norm=0.818, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.189e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:40,896 (trainer:780) INFO: 7epoch:train:97-120batch: iter_time=4.887e-05, forward_time=0.001, loss=5.280, backward_time=0.001, grad_norm=0.847, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.178e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,000 (trainer:780) INFO: 7epoch:train:121-144batch: iter_time=4.965e-05, forward_time=0.001, loss=5.182, backward_time=0.001, grad_norm=0.773, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.195e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,099 (trainer:780) INFO: 7epoch:train:145-168batch: iter_time=4.848e-05, forward_time=0.001, loss=5.169, backward_time=0.001, grad_norm=0.792, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.197e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,204 (trainer:780) INFO: 7epoch:train:169-192batch: iter_time=4.881e-05, forward_time=0.001, loss=5.222, backward_time=0.001, grad_norm=0.777, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.170e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,305 (trainer:780) INFO: 7epoch:train:193-216batch: iter_time=4.760e-05, forward_time=0.001, loss=5.221, backward_time=0.001, grad_norm=0.830, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.189e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,407 (trainer:780) INFO: 7epoch:train:217-240batch: iter_time=4.750e-05, forward_time=0.001, loss=5.154, backward_time=0.001, grad_norm=0.749, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.184e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,503 (trainer:780) INFO: 7epoch:train:241-264batch: iter_time=4.825e-05, forward_time=0.001, loss=5.134, backward_time=9.865e-04, grad_norm=0.981, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.159e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,609 (trainer:780) INFO: 7epoch:train:265-288batch: iter_time=4.675e-05, forward_time=0.001, loss=5.277, backward_time=0.001, grad_norm=0.749, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.157e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,712 (trainer:780) INFO: 7epoch:train:289-312batch: iter_time=4.706e-05, forward_time=0.001, loss=5.200, backward_time=0.001, grad_norm=0.832, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.172e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,810 (trainer:780) INFO: 7epoch:train:313-336batch: iter_time=4.893e-05, forward_time=0.001, loss=5.182, backward_time=0.001, grad_norm=0.935, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.197e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:41,913 (trainer:780) INFO: 7epoch:train:337-360batch: iter_time=4.782e-05, forward_time=0.001, loss=5.179, backward_time=0.001, grad_norm=0.780, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.183e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:42,013 (trainer:780) INFO: 7epoch:train:361-384batch: iter_time=4.741e-05, forward_time=0.001, loss=5.186, backward_time=0.001, grad_norm=0.807, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.165e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:42,116 (trainer:780) INFO: 7epoch:train:385-408batch: iter_time=4.793e-05, forward_time=0.001, loss=5.212, backward_time=0.001, grad_norm=0.898, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:42,214 (trainer:780) INFO: 7epoch:train:409-432batch: iter_time=4.806e-05, forward_time=0.001, loss=5.139, backward_time=0.001, grad_norm=0.839, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.162e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:42,314 (trainer:780) INFO: 7epoch:train:433-456batch: iter_time=4.789e-05, forward_time=0.001, loss=5.142, backward_time=0.001, grad_norm=0.832, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:42,417 (trainer:780) INFO: 7epoch:train:457-480batch: iter_time=4.830e-05, forward_time=0.001, loss=5.183, backward_time=0.001, grad_norm=0.835, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:43,251 (trainer:365) INFO: 7epoch results: [train] iter_time=7.532e-05, forward_time=0.001, loss=5.195, backward_time=0.001, grad_norm=0.830, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.178e-04, optim0_lr0=0.100, train_time=0.004, time=2.07 seconds, total_count=3374, gpu_max_cached_mem_GB=0.213, [valid] loss=5.188, time=0.81 seconds, total_count=2289, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:43,625 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:43,628 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/6epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:43,629 (trainer:299) INFO: 8/20epoch started. Estimated time to finish: 43.47 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:43,770 (trainer:780) INFO: 8epoch:train:1-24batch: iter_time=6.103e-04, forward_time=0.001, loss=5.167, backward_time=0.001, grad_norm=0.805, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.362e-04, optim0_lr0=0.100, train_time=0.006\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:43,871 (trainer:780) INFO: 8epoch:train:25-48batch: iter_time=4.839e-05, forward_time=0.001, loss=5.180, backward_time=0.001, grad_norm=0.863, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.241e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:43,970 (trainer:780) INFO: 8epoch:train:49-72batch: iter_time=4.885e-05, forward_time=0.001, loss=5.059, backward_time=0.001, grad_norm=0.960, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,073 (trainer:780) INFO: 8epoch:train:73-96batch: iter_time=4.910e-05, forward_time=0.001, loss=5.193, backward_time=0.001, grad_norm=0.907, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.128e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,176 (trainer:780) INFO: 8epoch:train:97-120batch: iter_time=5.235e-05, forward_time=0.001, loss=5.138, backward_time=0.001, grad_norm=0.755, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.155e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,275 (trainer:780) INFO: 8epoch:train:121-144batch: iter_time=5.228e-05, forward_time=0.001, loss=5.144, backward_time=0.001, grad_norm=0.883, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.165e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,374 (trainer:780) INFO: 8epoch:train:145-168batch: iter_time=5.191e-05, forward_time=0.001, loss=5.073, backward_time=0.001, grad_norm=0.894, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.130e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,485 (trainer:780) INFO: 8epoch:train:169-192batch: iter_time=5.584e-05, forward_time=0.001, loss=5.112, backward_time=0.001, grad_norm=0.894, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.276e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,583 (trainer:780) INFO: 8epoch:train:193-216batch: iter_time=4.700e-05, forward_time=0.001, loss=5.025, backward_time=0.001, grad_norm=0.896, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.119e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,686 (trainer:780) INFO: 8epoch:train:217-240batch: iter_time=4.542e-05, forward_time=0.001, loss=5.177, backward_time=0.001, grad_norm=0.817, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.115e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,786 (trainer:780) INFO: 8epoch:train:241-264batch: iter_time=4.593e-05, forward_time=0.001, loss=5.105, backward_time=0.001, grad_norm=0.848, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,884 (trainer:780) INFO: 8epoch:train:265-288batch: iter_time=4.527e-05, forward_time=0.001, loss=5.062, backward_time=0.001, grad_norm=0.985, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.102e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:44,981 (trainer:780) INFO: 8epoch:train:289-312batch: iter_time=4.532e-05, forward_time=0.001, loss=5.043, backward_time=0.001, grad_norm=0.917, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.116e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:45,079 (trainer:780) INFO: 8epoch:train:313-336batch: iter_time=4.449e-05, forward_time=0.001, loss=5.084, backward_time=0.001, grad_norm=0.885, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.111e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:45,178 (trainer:780) INFO: 8epoch:train:337-360batch: iter_time=4.551e-05, forward_time=0.001, loss=5.106, backward_time=0.001, grad_norm=0.912, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.115e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:45,279 (trainer:780) INFO: 8epoch:train:361-384batch: iter_time=4.470e-05, forward_time=0.001, loss=5.133, backward_time=0.001, grad_norm=0.914, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.118e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:45,380 (trainer:780) INFO: 8epoch:train:385-408batch: iter_time=4.544e-05, forward_time=0.001, loss=5.120, backward_time=0.001, grad_norm=0.909, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.122e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:45,483 (trainer:780) INFO: 8epoch:train:409-432batch: iter_time=4.629e-05, forward_time=0.001, loss=5.138, backward_time=0.001, grad_norm=0.833, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:45,580 (trainer:780) INFO: 8epoch:train:433-456batch: iter_time=4.570e-05, forward_time=0.001, loss=5.071, backward_time=0.001, grad_norm=1.050, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.115e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:45,679 (trainer:780) INFO: 8epoch:train:457-480batch: iter_time=4.567e-05, forward_time=0.001, loss=5.061, backward_time=0.001, grad_norm=0.918, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.109e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:46,509 (trainer:365) INFO: 8epoch results: [train] iter_time=7.565e-05, forward_time=0.001, loss=5.111, backward_time=0.001, grad_norm=0.893, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004, time=2.08 seconds, total_count=3856, gpu_max_cached_mem_GB=0.213, [valid] loss=5.138, time=0.8 seconds, total_count=2616, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:46,871 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:46,875 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/7epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:46,875 (trainer:299) INFO: 9/20epoch started. Estimated time to finish: 39.98 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,007 (trainer:780) INFO: 9epoch:train:1-24batch: iter_time=6.057e-04, forward_time=0.001, loss=5.019, backward_time=0.001, grad_norm=0.872, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.299e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,109 (trainer:780) INFO: 9epoch:train:25-48batch: iter_time=4.777e-05, forward_time=0.001, loss=5.071, backward_time=0.001, grad_norm=0.877, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.140e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,208 (trainer:780) INFO: 9epoch:train:49-72batch: iter_time=4.607e-05, forward_time=0.001, loss=5.014, backward_time=0.001, grad_norm=0.906, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.119e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,306 (trainer:780) INFO: 9epoch:train:73-96batch: iter_time=4.587e-05, forward_time=0.001, loss=5.077, backward_time=0.001, grad_norm=0.928, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.128e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,408 (trainer:780) INFO: 9epoch:train:97-120batch: iter_time=4.677e-05, forward_time=0.001, loss=5.068, backward_time=0.001, grad_norm=0.869, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.116e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,508 (trainer:780) INFO: 9epoch:train:121-144batch: iter_time=4.627e-05, forward_time=0.001, loss=5.083, backward_time=0.001, grad_norm=1.002, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.124e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,608 (trainer:780) INFO: 9epoch:train:145-168batch: iter_time=4.645e-05, forward_time=0.001, loss=5.059, backward_time=0.001, grad_norm=0.920, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.119e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,707 (trainer:780) INFO: 9epoch:train:169-192batch: iter_time=4.492e-05, forward_time=0.001, loss=4.963, backward_time=0.001, grad_norm=0.918, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.104e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,804 (trainer:780) INFO: 9epoch:train:193-216batch: iter_time=4.877e-05, forward_time=0.001, loss=5.026, backward_time=0.001, grad_norm=0.936, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:47,899 (trainer:780) INFO: 9epoch:train:217-240batch: iter_time=4.655e-05, forward_time=0.001, loss=4.932, backward_time=9.949e-04, grad_norm=1.015, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.097e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,000 (trainer:780) INFO: 9epoch:train:241-264batch: iter_time=4.538e-05, forward_time=0.001, loss=5.053, backward_time=0.001, grad_norm=0.911, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.126e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,102 (trainer:780) INFO: 9epoch:train:265-288batch: iter_time=4.627e-05, forward_time=0.001, loss=5.069, backward_time=0.001, grad_norm=0.929, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.108e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,202 (trainer:780) INFO: 9epoch:train:289-312batch: iter_time=4.599e-05, forward_time=0.001, loss=5.040, backward_time=0.001, grad_norm=0.975, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.116e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,300 (trainer:780) INFO: 9epoch:train:313-336batch: iter_time=4.588e-05, forward_time=0.001, loss=5.006, backward_time=0.001, grad_norm=1.033, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.111e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,398 (trainer:780) INFO: 9epoch:train:337-360batch: iter_time=4.721e-05, forward_time=0.001, loss=4.981, backward_time=0.001, grad_norm=0.988, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.104e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,495 (trainer:780) INFO: 9epoch:train:361-384batch: iter_time=4.573e-05, forward_time=0.001, loss=4.963, backward_time=0.001, grad_norm=0.959, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.127e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,595 (trainer:780) INFO: 9epoch:train:385-408batch: iter_time=5.165e-05, forward_time=0.001, loss=4.939, backward_time=0.001, grad_norm=0.946, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.183e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,697 (trainer:780) INFO: 9epoch:train:409-432batch: iter_time=4.680e-05, forward_time=0.001, loss=4.997, backward_time=0.001, grad_norm=0.985, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.116e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,795 (trainer:780) INFO: 9epoch:train:433-456batch: iter_time=4.691e-05, forward_time=0.001, loss=4.962, backward_time=0.001, grad_norm=0.977, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.115e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:48,893 (trainer:780) INFO: 9epoch:train:457-480batch: iter_time=4.561e-05, forward_time=0.001, loss=4.956, backward_time=0.001, grad_norm=0.974, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.115e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:49,722 (trainer:365) INFO: 9epoch results: [train] iter_time=7.450e-05, forward_time=0.001, loss=5.015, backward_time=0.001, grad_norm=0.946, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.129e-04, optim0_lr0=0.100, train_time=0.004, time=2.04 seconds, total_count=4338, gpu_max_cached_mem_GB=0.213, [valid] loss=5.024, time=0.8 seconds, total_count=2943, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,103 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,106 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/8epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,107 (trainer:299) INFO: 10/20epoch started. Estimated time to finish: 36.52 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,236 (trainer:780) INFO: 10epoch:train:1-24batch: iter_time=6.135e-04, forward_time=0.001, loss=4.896, backward_time=0.001, grad_norm=0.966, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.235e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,335 (trainer:780) INFO: 10epoch:train:25-48batch: iter_time=4.705e-05, forward_time=0.001, loss=4.917, backward_time=0.001, grad_norm=1.003, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,435 (trainer:780) INFO: 10epoch:train:49-72batch: iter_time=4.673e-05, forward_time=0.001, loss=4.947, backward_time=0.001, grad_norm=0.973, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.132e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,535 (trainer:780) INFO: 10epoch:train:73-96batch: iter_time=4.579e-05, forward_time=0.001, loss=5.015, backward_time=0.001, grad_norm=1.014, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.122e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,632 (trainer:780) INFO: 10epoch:train:97-120batch: iter_time=4.685e-05, forward_time=0.001, loss=4.889, backward_time=0.001, grad_norm=1.078, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,731 (trainer:780) INFO: 10epoch:train:121-144batch: iter_time=4.661e-05, forward_time=0.001, loss=4.931, backward_time=0.001, grad_norm=0.990, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.110e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,831 (trainer:780) INFO: 10epoch:train:145-168batch: iter_time=4.645e-05, forward_time=0.001, loss=4.910, backward_time=0.001, grad_norm=0.898, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:50,931 (trainer:780) INFO: 10epoch:train:169-192batch: iter_time=4.551e-05, forward_time=0.001, loss=4.935, backward_time=0.001, grad_norm=0.950, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.105e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,032 (trainer:780) INFO: 10epoch:train:193-216batch: iter_time=4.570e-05, forward_time=0.001, loss=4.964, backward_time=0.001, grad_norm=0.953, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.120e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,129 (trainer:780) INFO: 10epoch:train:217-240batch: iter_time=4.555e-05, forward_time=0.001, loss=4.864, backward_time=0.001, grad_norm=1.072, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.119e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,228 (trainer:780) INFO: 10epoch:train:241-264batch: iter_time=4.532e-05, forward_time=0.001, loss=4.932, backward_time=0.001, grad_norm=0.980, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.106e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,325 (trainer:780) INFO: 10epoch:train:265-288batch: iter_time=4.606e-05, forward_time=0.001, loss=4.915, backward_time=0.001, grad_norm=1.119, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.108e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,422 (trainer:780) INFO: 10epoch:train:289-312batch: iter_time=4.613e-05, forward_time=0.001, loss=4.892, backward_time=0.001, grad_norm=1.117, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,519 (trainer:780) INFO: 10epoch:train:313-336batch: iter_time=4.606e-05, forward_time=0.001, loss=4.858, backward_time=0.001, grad_norm=1.026, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.103e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,620 (trainer:780) INFO: 10epoch:train:337-360batch: iter_time=4.735e-05, forward_time=0.001, loss=4.856, backward_time=0.001, grad_norm=0.990, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.128e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,720 (trainer:780) INFO: 10epoch:train:361-384batch: iter_time=4.722e-05, forward_time=0.001, loss=4.936, backward_time=0.001, grad_norm=1.031, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.114e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,820 (trainer:780) INFO: 10epoch:train:385-408batch: iter_time=4.668e-05, forward_time=0.001, loss=4.909, backward_time=0.001, grad_norm=1.063, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.123e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:51,915 (trainer:780) INFO: 10epoch:train:409-432batch: iter_time=4.600e-05, forward_time=0.001, loss=4.823, backward_time=9.970e-04, grad_norm=1.178, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.106e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:52,014 (trainer:780) INFO: 10epoch:train:433-456batch: iter_time=4.561e-05, forward_time=0.001, loss=4.904, backward_time=0.001, grad_norm=1.021, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.104e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:52,114 (trainer:780) INFO: 10epoch:train:457-480batch: iter_time=4.721e-05, forward_time=0.001, loss=4.908, backward_time=0.001, grad_norm=1.066, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.118e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:52,954 (trainer:365) INFO: 10epoch results: [train] iter_time=7.456e-05, forward_time=0.001, loss=4.912, backward_time=0.001, grad_norm=1.024, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.122e-04, optim0_lr0=0.100, train_time=0.004, time=2.03 seconds, total_count=4820, gpu_max_cached_mem_GB=0.213, [valid] loss=4.909, time=0.81 seconds, total_count=3270, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,335 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,338 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/9epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,339 (trainer:299) INFO: 11/20epoch started. Estimated time to finish: 33.12 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,469 (trainer:780) INFO: 11epoch:train:1-24batch: iter_time=6.120e-04, forward_time=0.001, loss=4.792, backward_time=0.001, grad_norm=0.993, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.256e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,568 (trainer:780) INFO: 11epoch:train:25-48batch: iter_time=4.797e-05, forward_time=0.001, loss=4.823, backward_time=0.001, grad_norm=1.047, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,669 (trainer:780) INFO: 11epoch:train:49-72batch: iter_time=4.684e-05, forward_time=0.001, loss=4.846, backward_time=0.001, grad_norm=1.082, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.147e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,768 (trainer:780) INFO: 11epoch:train:73-96batch: iter_time=4.597e-05, forward_time=0.001, loss=4.810, backward_time=0.001, grad_norm=1.104, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.123e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,864 (trainer:780) INFO: 11epoch:train:97-120batch: iter_time=4.657e-05, forward_time=0.001, loss=4.742, backward_time=9.981e-04, grad_norm=1.102, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.127e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:53,964 (trainer:780) INFO: 11epoch:train:121-144batch: iter_time=4.585e-05, forward_time=0.001, loss=4.893, backward_time=0.001, grad_norm=1.081, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.122e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,066 (trainer:780) INFO: 11epoch:train:145-168batch: iter_time=4.692e-05, forward_time=0.001, loss=4.872, backward_time=0.001, grad_norm=1.036, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.125e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,166 (trainer:780) INFO: 11epoch:train:169-192batch: iter_time=4.604e-05, forward_time=0.001, loss=4.882, backward_time=0.001, grad_norm=1.135, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.131e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,266 (trainer:780) INFO: 11epoch:train:193-216batch: iter_time=4.715e-05, forward_time=0.001, loss=4.852, backward_time=0.001, grad_norm=1.020, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.115e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,363 (trainer:780) INFO: 11epoch:train:217-240batch: iter_time=4.696e-05, forward_time=0.001, loss=4.769, backward_time=0.001, grad_norm=1.161, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.140e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,464 (trainer:780) INFO: 11epoch:train:241-264batch: iter_time=4.700e-05, forward_time=0.001, loss=4.823, backward_time=0.001, grad_norm=1.025, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,564 (trainer:780) INFO: 11epoch:train:265-288batch: iter_time=4.653e-05, forward_time=0.001, loss=4.804, backward_time=0.001, grad_norm=1.069, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.106e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,663 (trainer:780) INFO: 11epoch:train:289-312batch: iter_time=4.717e-05, forward_time=0.001, loss=4.721, backward_time=0.001, grad_norm=1.106, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.118e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,761 (trainer:780) INFO: 11epoch:train:313-336batch: iter_time=4.810e-05, forward_time=0.001, loss=4.784, backward_time=0.001, grad_norm=1.161, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.130e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,858 (trainer:780) INFO: 11epoch:train:337-360batch: iter_time=4.770e-05, forward_time=0.001, loss=4.704, backward_time=0.001, grad_norm=1.135, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.112e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:54,955 (trainer:780) INFO: 11epoch:train:361-384batch: iter_time=4.708e-05, forward_time=0.001, loss=4.747, backward_time=0.001, grad_norm=1.083, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.129e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:55,055 (trainer:780) INFO: 11epoch:train:385-408batch: iter_time=4.693e-05, forward_time=0.001, loss=4.827, backward_time=0.001, grad_norm=1.165, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.124e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:55,154 (trainer:780) INFO: 11epoch:train:409-432batch: iter_time=4.639e-05, forward_time=0.001, loss=4.799, backward_time=0.001, grad_norm=1.101, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.121e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:55,253 (trainer:780) INFO: 11epoch:train:433-456batch: iter_time=4.669e-05, forward_time=0.001, loss=4.791, backward_time=0.001, grad_norm=1.218, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:55,353 (trainer:780) INFO: 11epoch:train:457-480batch: iter_time=4.648e-05, forward_time=0.001, loss=4.791, backward_time=0.001, grad_norm=1.059, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.119e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,190 (trainer:365) INFO: 11epoch results: [train] iter_time=7.498e-05, forward_time=0.001, loss=4.805, backward_time=0.001, grad_norm=1.095, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.131e-04, optim0_lr0=0.100, train_time=0.004, time=2.04 seconds, total_count=5302, gpu_max_cached_mem_GB=0.213, [valid] loss=4.827, time=0.81 seconds, total_count=3597, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,548 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,552 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/10epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,552 (trainer:299) INFO: 12/20epoch started. Estimated time to finish: 29.72 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,686 (trainer:780) INFO: 12epoch:train:1-24batch: iter_time=6.125e-04, forward_time=0.001, loss=4.772, backward_time=0.001, grad_norm=1.146, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.267e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,785 (trainer:780) INFO: 12epoch:train:25-48batch: iter_time=4.775e-05, forward_time=0.001, loss=4.698, backward_time=0.001, grad_norm=1.179, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.172e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,887 (trainer:780) INFO: 12epoch:train:49-72batch: iter_time=4.883e-05, forward_time=0.001, loss=4.790, backward_time=0.001, grad_norm=1.047, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.153e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:56,988 (trainer:780) INFO: 12epoch:train:73-96batch: iter_time=4.859e-05, forward_time=0.001, loss=4.772, backward_time=0.001, grad_norm=1.204, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.172e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,088 (trainer:780) INFO: 12epoch:train:97-120batch: iter_time=4.730e-05, forward_time=0.001, loss=4.745, backward_time=0.001, grad_norm=1.090, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.135e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,184 (trainer:780) INFO: 12epoch:train:121-144batch: iter_time=4.676e-05, forward_time=0.001, loss=4.648, backward_time=9.883e-04, grad_norm=1.266, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.140e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,282 (trainer:780) INFO: 12epoch:train:145-168batch: iter_time=4.547e-05, forward_time=0.001, loss=4.702, backward_time=0.001, grad_norm=1.193, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,383 (trainer:780) INFO: 12epoch:train:169-192batch: iter_time=4.730e-05, forward_time=0.001, loss=4.767, backward_time=0.001, grad_norm=1.210, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,486 (trainer:780) INFO: 12epoch:train:193-216batch: iter_time=4.590e-05, forward_time=0.001, loss=4.783, backward_time=0.001, grad_norm=1.213, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.136e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,584 (trainer:780) INFO: 12epoch:train:217-240batch: iter_time=4.652e-05, forward_time=0.001, loss=4.671, backward_time=0.001, grad_norm=1.137, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,681 (trainer:780) INFO: 12epoch:train:241-264batch: iter_time=4.591e-05, forward_time=0.001, loss=4.672, backward_time=0.001, grad_norm=1.175, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.134e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,784 (trainer:780) INFO: 12epoch:train:265-288batch: iter_time=4.790e-05, forward_time=0.001, loss=4.722, backward_time=0.001, grad_norm=1.060, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,883 (trainer:780) INFO: 12epoch:train:289-312batch: iter_time=4.682e-05, forward_time=0.001, loss=4.655, backward_time=0.001, grad_norm=1.166, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.135e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:57,980 (trainer:780) INFO: 12epoch:train:313-336batch: iter_time=4.704e-05, forward_time=0.001, loss=4.646, backward_time=0.001, grad_norm=1.175, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:58,079 (trainer:780) INFO: 12epoch:train:337-360batch: iter_time=4.674e-05, forward_time=0.001, loss=4.613, backward_time=0.001, grad_norm=1.179, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.132e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:58,180 (trainer:780) INFO: 12epoch:train:361-384batch: iter_time=4.702e-05, forward_time=0.001, loss=4.745, backward_time=0.001, grad_norm=1.295, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.144e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:58,281 (trainer:780) INFO: 12epoch:train:385-408batch: iter_time=4.683e-05, forward_time=0.001, loss=4.674, backward_time=0.001, grad_norm=1.157, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.146e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:58,378 (trainer:780) INFO: 12epoch:train:409-432batch: iter_time=4.637e-05, forward_time=0.001, loss=4.625, backward_time=0.001, grad_norm=1.180, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.123e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:58,478 (trainer:780) INFO: 12epoch:train:433-456batch: iter_time=4.795e-05, forward_time=0.001, loss=4.622, backward_time=0.001, grad_norm=1.227, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.120e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:58,575 (trainer:780) INFO: 12epoch:train:457-480batch: iter_time=4.581e-05, forward_time=0.001, loss=4.590, backward_time=9.974e-04, grad_norm=1.263, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.121e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:59,413 (trainer:365) INFO: 12epoch results: [train] iter_time=7.514e-05, forward_time=0.001, loss=4.697, backward_time=0.001, grad_norm=1.178, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004, time=2.05 seconds, total_count=5784, gpu_max_cached_mem_GB=0.213, [valid] loss=4.732, time=0.81 seconds, total_count=3924, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:59,800 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:59,803 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/11epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:59,803 (trainer:299) INFO: 13/20epoch started. Estimated time to finish: 26.39 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:01:59,938 (trainer:780) INFO: 13epoch:train:1-24batch: iter_time=6.023e-04, forward_time=0.001, loss=4.670, backward_time=0.001, grad_norm=1.181, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.234e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,042 (trainer:780) INFO: 13epoch:train:25-48batch: iter_time=4.913e-05, forward_time=0.001, loss=4.660, backward_time=0.001, grad_norm=1.226, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,139 (trainer:780) INFO: 13epoch:train:49-72batch: iter_time=4.746e-05, forward_time=0.001, loss=4.559, backward_time=0.001, grad_norm=1.277, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.146e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,242 (trainer:780) INFO: 13epoch:train:73-96batch: iter_time=4.738e-05, forward_time=0.001, loss=4.638, backward_time=0.001, grad_norm=1.170, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.139e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,341 (trainer:780) INFO: 13epoch:train:97-120batch: iter_time=4.620e-05, forward_time=0.001, loss=4.641, backward_time=0.001, grad_norm=1.253, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.110e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,434 (trainer:780) INFO: 13epoch:train:121-144batch: iter_time=4.664e-05, forward_time=0.001, loss=4.439, backward_time=9.693e-04, grad_norm=1.298, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.107e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,530 (trainer:780) INFO: 13epoch:train:145-168batch: iter_time=4.636e-05, forward_time=0.001, loss=4.560, backward_time=0.001, grad_norm=1.286, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.126e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,631 (trainer:780) INFO: 13epoch:train:169-192batch: iter_time=4.638e-05, forward_time=0.001, loss=4.598, backward_time=0.001, grad_norm=1.253, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.112e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,743 (trainer:780) INFO: 13epoch:train:193-216batch: iter_time=5.115e-05, forward_time=0.001, loss=4.575, backward_time=0.001, grad_norm=1.232, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.222e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,845 (trainer:780) INFO: 13epoch:train:217-240batch: iter_time=4.750e-05, forward_time=0.001, loss=4.612, backward_time=0.001, grad_norm=1.220, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.136e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:00,943 (trainer:780) INFO: 13epoch:train:241-264batch: iter_time=4.523e-05, forward_time=0.001, loss=4.573, backward_time=0.001, grad_norm=1.263, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.120e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,045 (trainer:780) INFO: 13epoch:train:265-288batch: iter_time=4.697e-05, forward_time=0.001, loss=4.666, backward_time=0.001, grad_norm=1.328, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.112e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,145 (trainer:780) INFO: 13epoch:train:289-312batch: iter_time=4.535e-05, forward_time=0.001, loss=4.599, backward_time=0.001, grad_norm=1.258, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.107e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,261 (trainer:780) INFO: 13epoch:train:313-336batch: iter_time=4.292e-04, forward_time=0.001, loss=4.533, backward_time=0.001, grad_norm=1.291, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.213e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,366 (trainer:780) INFO: 13epoch:train:337-360batch: iter_time=4.745e-05, forward_time=0.001, loss=4.651, backward_time=0.001, grad_norm=1.259, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.132e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,466 (trainer:780) INFO: 13epoch:train:361-384batch: iter_time=4.766e-05, forward_time=0.001, loss=4.585, backward_time=0.001, grad_norm=1.276, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,566 (trainer:780) INFO: 13epoch:train:385-408batch: iter_time=4.757e-05, forward_time=0.001, loss=4.539, backward_time=0.001, grad_norm=1.291, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.154e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,664 (trainer:780) INFO: 13epoch:train:409-432batch: iter_time=4.727e-05, forward_time=0.001, loss=4.547, backward_time=0.001, grad_norm=1.317, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,766 (trainer:780) INFO: 13epoch:train:433-456batch: iter_time=4.695e-05, forward_time=0.001, loss=4.630, backward_time=0.001, grad_norm=1.270, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.157e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:01,862 (trainer:780) INFO: 13epoch:train:457-480batch: iter_time=4.757e-05, forward_time=0.001, loss=4.504, backward_time=9.847e-04, grad_norm=1.409, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:02,701 (trainer:365) INFO: 13epoch results: [train] iter_time=9.388e-05, forward_time=0.001, loss=4.593, backward_time=0.001, grad_norm=1.268, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.146e-04, optim0_lr0=0.100, train_time=0.004, time=2.08 seconds, total_count=6266, gpu_max_cached_mem_GB=0.213, [valid] loss=4.651, time=0.81 seconds, total_count=4251, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,072 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,077 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/12epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,077 (trainer:299) INFO: 14/20epoch started. Estimated time to finish: 23.08 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,209 (trainer:780) INFO: 14epoch:train:1-24batch: iter_time=6.182e-04, forward_time=0.001, loss=4.518, backward_time=0.001, grad_norm=1.301, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.266e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,311 (trainer:780) INFO: 14epoch:train:25-48batch: iter_time=4.810e-05, forward_time=0.001, loss=4.563, backward_time=0.001, grad_norm=1.329, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.147e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,410 (trainer:780) INFO: 14epoch:train:49-72batch: iter_time=4.704e-05, forward_time=0.001, loss=4.518, backward_time=0.001, grad_norm=1.290, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.123e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,506 (trainer:780) INFO: 14epoch:train:73-96batch: iter_time=4.559e-05, forward_time=0.001, loss=4.478, backward_time=9.992e-04, grad_norm=1.323, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.122e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,606 (trainer:780) INFO: 14epoch:train:97-120batch: iter_time=4.762e-05, forward_time=0.001, loss=4.459, backward_time=0.001, grad_norm=1.318, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.118e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,706 (trainer:780) INFO: 14epoch:train:121-144batch: iter_time=4.634e-05, forward_time=0.001, loss=4.580, backward_time=0.001, grad_norm=1.450, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.116e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,803 (trainer:780) INFO: 14epoch:train:145-168batch: iter_time=4.597e-05, forward_time=0.001, loss=4.473, backward_time=9.955e-04, grad_norm=1.376, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.125e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:03,902 (trainer:780) INFO: 14epoch:train:169-192batch: iter_time=4.702e-05, forward_time=0.001, loss=4.545, backward_time=0.001, grad_norm=1.269, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.129e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,005 (trainer:780) INFO: 14epoch:train:193-216batch: iter_time=4.894e-05, forward_time=0.001, loss=4.515, backward_time=0.001, grad_norm=1.349, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.168e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,105 (trainer:780) INFO: 14epoch:train:217-240batch: iter_time=4.714e-05, forward_time=0.001, loss=4.474, backward_time=0.001, grad_norm=1.406, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.172e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,205 (trainer:780) INFO: 14epoch:train:241-264batch: iter_time=4.729e-05, forward_time=0.001, loss=4.486, backward_time=0.001, grad_norm=1.355, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,307 (trainer:780) INFO: 14epoch:train:265-288batch: iter_time=4.812e-05, forward_time=0.001, loss=4.482, backward_time=0.001, grad_norm=1.290, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.181e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,404 (trainer:780) INFO: 14epoch:train:289-312batch: iter_time=4.850e-05, forward_time=0.001, loss=4.405, backward_time=0.001, grad_norm=1.397, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.146e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,504 (trainer:780) INFO: 14epoch:train:313-336batch: iter_time=4.786e-05, forward_time=0.001, loss=4.468, backward_time=0.001, grad_norm=1.379, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,604 (trainer:780) INFO: 14epoch:train:337-360batch: iter_time=4.838e-05, forward_time=0.001, loss=4.468, backward_time=0.001, grad_norm=1.403, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.159e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,703 (trainer:780) INFO: 14epoch:train:361-384batch: iter_time=4.759e-05, forward_time=0.001, loss=4.427, backward_time=0.001, grad_norm=1.482, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,800 (trainer:780) INFO: 14epoch:train:385-408batch: iter_time=4.711e-05, forward_time=0.001, loss=4.441, backward_time=9.973e-04, grad_norm=1.362, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:04,901 (trainer:780) INFO: 14epoch:train:409-432batch: iter_time=4.787e-05, forward_time=0.001, loss=4.531, backward_time=0.001, grad_norm=1.343, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:05,001 (trainer:780) INFO: 14epoch:train:433-456batch: iter_time=4.728e-05, forward_time=0.001, loss=4.469, backward_time=0.001, grad_norm=1.319, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.175e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:05,104 (trainer:780) INFO: 14epoch:train:457-480batch: iter_time=4.741e-05, forward_time=0.001, loss=4.483, backward_time=0.001, grad_norm=1.388, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.159e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:05,999 (trainer:365) INFO: 14epoch results: [train] iter_time=7.585e-05, forward_time=0.001, loss=4.490, backward_time=0.001, grad_norm=1.356, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.153e-04, optim0_lr0=0.100, train_time=0.004, time=2.05 seconds, total_count=6748, gpu_max_cached_mem_GB=0.213, [valid] loss=4.558, time=0.87 seconds, total_count=4578, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,374 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,378 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/13epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,378 (trainer:299) INFO: 15/20epoch started. Estimated time to finish: 19.78 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,511 (trainer:780) INFO: 15epoch:train:1-24batch: iter_time=6.051e-04, forward_time=0.001, loss=4.406, backward_time=0.001, grad_norm=1.490, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.276e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,612 (trainer:780) INFO: 15epoch:train:25-48batch: iter_time=4.819e-05, forward_time=0.001, loss=4.402, backward_time=0.001, grad_norm=1.378, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.165e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,716 (trainer:780) INFO: 15epoch:train:49-72batch: iter_time=4.707e-05, forward_time=0.001, loss=4.474, backward_time=0.001, grad_norm=1.460, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.170e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,814 (trainer:780) INFO: 15epoch:train:73-96batch: iter_time=4.657e-05, forward_time=0.001, loss=4.357, backward_time=0.001, grad_norm=1.442, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:06,917 (trainer:780) INFO: 15epoch:train:97-120batch: iter_time=4.786e-05, forward_time=0.001, loss=4.415, backward_time=0.001, grad_norm=1.378, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,017 (trainer:780) INFO: 15epoch:train:121-144batch: iter_time=4.608e-05, forward_time=0.001, loss=4.401, backward_time=0.001, grad_norm=1.444, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,115 (trainer:780) INFO: 15epoch:train:145-168batch: iter_time=4.634e-05, forward_time=0.001, loss=4.348, backward_time=0.001, grad_norm=1.518, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,219 (trainer:780) INFO: 15epoch:train:169-192batch: iter_time=4.570e-05, forward_time=0.001, loss=4.473, backward_time=0.001, grad_norm=1.309, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.154e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,320 (trainer:780) INFO: 15epoch:train:193-216batch: iter_time=4.628e-05, forward_time=0.001, loss=4.416, backward_time=0.001, grad_norm=1.398, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.154e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,420 (trainer:780) INFO: 15epoch:train:217-240batch: iter_time=4.630e-05, forward_time=0.001, loss=4.381, backward_time=0.001, grad_norm=1.474, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,518 (trainer:780) INFO: 15epoch:train:241-264batch: iter_time=4.677e-05, forward_time=0.001, loss=4.323, backward_time=0.001, grad_norm=1.436, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,619 (trainer:780) INFO: 15epoch:train:265-288batch: iter_time=4.645e-05, forward_time=0.001, loss=4.382, backward_time=0.001, grad_norm=1.433, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.139e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,719 (trainer:780) INFO: 15epoch:train:289-312batch: iter_time=4.601e-05, forward_time=0.001, loss=4.314, backward_time=0.001, grad_norm=1.496, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.141e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,819 (trainer:780) INFO: 15epoch:train:313-336batch: iter_time=4.804e-05, forward_time=0.001, loss=4.357, backward_time=0.001, grad_norm=1.542, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.145e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:07,919 (trainer:780) INFO: 15epoch:train:337-360batch: iter_time=4.710e-05, forward_time=0.001, loss=4.379, backward_time=0.001, grad_norm=1.466, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:08,019 (trainer:780) INFO: 15epoch:train:361-384batch: iter_time=4.822e-05, forward_time=0.001, loss=4.409, backward_time=0.001, grad_norm=1.427, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.144e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:08,119 (trainer:780) INFO: 15epoch:train:385-408batch: iter_time=4.791e-05, forward_time=0.001, loss=4.350, backward_time=0.001, grad_norm=1.416, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.141e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:08,217 (trainer:780) INFO: 15epoch:train:409-432batch: iter_time=4.787e-05, forward_time=0.001, loss=4.337, backward_time=0.001, grad_norm=1.504, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.138e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:08,316 (trainer:780) INFO: 15epoch:train:433-456batch: iter_time=4.765e-05, forward_time=0.001, loss=4.410, backward_time=0.001, grad_norm=1.603, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.139e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:08,416 (trainer:780) INFO: 15epoch:train:457-480batch: iter_time=4.797e-05, forward_time=0.001, loss=4.379, backward_time=0.001, grad_norm=1.468, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.146e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:09,287 (trainer:365) INFO: 15epoch results: [train] iter_time=7.485e-05, forward_time=0.001, loss=4.387, backward_time=0.001, grad_norm=1.455, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.155e-04, optim0_lr0=0.100, train_time=0.004, time=2.06 seconds, total_count=7230, gpu_max_cached_mem_GB=0.213, [valid] loss=4.528, time=0.84 seconds, total_count=4905, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:09,647 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:09,650 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/14epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:09,651 (trainer:299) INFO: 16/20epoch started. Estimated time to finish: 16.48 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:09,781 (trainer:780) INFO: 16epoch:train:1-24batch: iter_time=6.194e-04, forward_time=0.001, loss=4.263, backward_time=0.001, grad_norm=1.575, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.285e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:09,880 (trainer:780) INFO: 16epoch:train:25-48batch: iter_time=4.959e-05, forward_time=0.001, loss=4.262, backward_time=0.001, grad_norm=1.503, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.170e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:09,981 (trainer:780) INFO: 16epoch:train:49-72batch: iter_time=4.665e-05, forward_time=0.001, loss=4.307, backward_time=0.001, grad_norm=1.534, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,084 (trainer:780) INFO: 16epoch:train:73-96batch: iter_time=4.709e-05, forward_time=0.001, loss=4.422, backward_time=0.001, grad_norm=1.509, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,186 (trainer:780) INFO: 16epoch:train:97-120batch: iter_time=4.673e-05, forward_time=0.001, loss=4.318, backward_time=0.001, grad_norm=1.485, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.159e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,284 (trainer:780) INFO: 16epoch:train:121-144batch: iter_time=4.756e-05, forward_time=0.001, loss=4.252, backward_time=0.001, grad_norm=1.490, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.153e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,386 (trainer:780) INFO: 16epoch:train:145-168batch: iter_time=4.790e-05, forward_time=0.001, loss=4.339, backward_time=0.001, grad_norm=1.557, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,486 (trainer:780) INFO: 16epoch:train:169-192batch: iter_time=4.813e-05, forward_time=0.001, loss=4.280, backward_time=0.001, grad_norm=1.532, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.137e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,585 (trainer:780) INFO: 16epoch:train:193-216batch: iter_time=4.878e-05, forward_time=0.001, loss=4.290, backward_time=0.001, grad_norm=1.549, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.153e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,688 (trainer:780) INFO: 16epoch:train:217-240batch: iter_time=4.611e-05, forward_time=0.001, loss=4.293, backward_time=0.001, grad_norm=1.452, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.184e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,789 (trainer:780) INFO: 16epoch:train:241-264batch: iter_time=4.748e-05, forward_time=0.001, loss=4.314, backward_time=0.001, grad_norm=1.544, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.159e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,890 (trainer:780) INFO: 16epoch:train:265-288batch: iter_time=4.801e-05, forward_time=0.001, loss=4.262, backward_time=0.001, grad_norm=1.531, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.164e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:10,992 (trainer:780) INFO: 16epoch:train:289-312batch: iter_time=4.775e-05, forward_time=0.001, loss=4.308, backward_time=0.001, grad_norm=1.598, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:11,092 (trainer:780) INFO: 16epoch:train:313-336batch: iter_time=4.705e-05, forward_time=0.001, loss=4.279, backward_time=0.001, grad_norm=1.525, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:11,192 (trainer:780) INFO: 16epoch:train:337-360batch: iter_time=4.840e-05, forward_time=0.001, loss=4.282, backward_time=0.001, grad_norm=1.634, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:11,290 (trainer:780) INFO: 16epoch:train:361-384batch: iter_time=4.837e-05, forward_time=0.001, loss=4.215, backward_time=0.001, grad_norm=1.510, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.147e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:11,391 (trainer:780) INFO: 16epoch:train:385-408batch: iter_time=4.806e-05, forward_time=0.001, loss=4.296, backward_time=0.001, grad_norm=1.585, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.172e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:11,488 (trainer:780) INFO: 16epoch:train:409-432batch: iter_time=4.724e-05, forward_time=0.001, loss=4.161, backward_time=9.979e-04, grad_norm=1.542, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.154e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:11,589 (trainer:780) INFO: 16epoch:train:433-456batch: iter_time=4.760e-05, forward_time=0.001, loss=4.329, backward_time=0.001, grad_norm=1.568, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:11,688 (trainer:780) INFO: 16epoch:train:457-480batch: iter_time=4.778e-05, forward_time=0.001, loss=4.187, backward_time=9.979e-04, grad_norm=1.558, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.147e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:12,522 (trainer:365) INFO: 16epoch results: [train] iter_time=7.615e-05, forward_time=0.001, loss=4.285, backward_time=0.001, grad_norm=1.538, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.164e-04, optim0_lr0=0.100, train_time=0.004, time=2.06 seconds, total_count=7712, gpu_max_cached_mem_GB=0.213, [valid] loss=4.392, time=0.81 seconds, total_count=5232, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:12,897 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:12,900 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/15epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:12,901 (trainer:299) INFO: 17/20epoch started. Estimated time to finish: 13.17 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,033 (trainer:780) INFO: 17epoch:train:1-24batch: iter_time=6.240e-04, forward_time=0.001, loss=4.221, backward_time=0.001, grad_norm=1.583, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.256e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,133 (trainer:780) INFO: 17epoch:train:25-48batch: iter_time=5.123e-05, forward_time=0.001, loss=4.199, backward_time=0.001, grad_norm=1.563, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.189e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,234 (trainer:780) INFO: 17epoch:train:49-72batch: iter_time=4.709e-05, forward_time=0.001, loss=4.245, backward_time=0.001, grad_norm=1.550, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.171e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,334 (trainer:780) INFO: 17epoch:train:73-96batch: iter_time=4.913e-05, forward_time=0.001, loss=4.197, backward_time=0.001, grad_norm=1.606, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,431 (trainer:780) INFO: 17epoch:train:97-120batch: iter_time=4.681e-05, forward_time=0.001, loss=4.090, backward_time=0.001, grad_norm=1.566, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,534 (trainer:780) INFO: 17epoch:train:121-144batch: iter_time=4.636e-05, forward_time=0.001, loss=4.248, backward_time=0.001, grad_norm=1.672, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,635 (trainer:780) INFO: 17epoch:train:145-168batch: iter_time=4.804e-05, forward_time=0.001, loss=4.212, backward_time=0.001, grad_norm=1.588, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.152e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,730 (trainer:780) INFO: 17epoch:train:169-192batch: iter_time=4.814e-05, forward_time=0.001, loss=4.099, backward_time=0.001, grad_norm=1.651, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,833 (trainer:780) INFO: 17epoch:train:193-216batch: iter_time=4.706e-05, forward_time=0.001, loss=4.198, backward_time=0.001, grad_norm=1.497, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:13,933 (trainer:780) INFO: 17epoch:train:217-240batch: iter_time=4.690e-05, forward_time=0.001, loss=4.153, backward_time=0.001, grad_norm=1.555, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,034 (trainer:780) INFO: 17epoch:train:241-264batch: iter_time=4.772e-05, forward_time=0.001, loss=4.203, backward_time=0.001, grad_norm=1.729, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.159e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,132 (trainer:780) INFO: 17epoch:train:265-288batch: iter_time=4.753e-05, forward_time=0.001, loss=4.138, backward_time=0.001, grad_norm=1.629, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.179e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,233 (trainer:780) INFO: 17epoch:train:289-312batch: iter_time=4.841e-05, forward_time=0.001, loss=4.169, backward_time=0.001, grad_norm=1.570, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,335 (trainer:780) INFO: 17epoch:train:313-336batch: iter_time=4.803e-05, forward_time=0.001, loss=4.229, backward_time=0.001, grad_norm=1.577, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,432 (trainer:780) INFO: 17epoch:train:337-360batch: iter_time=4.758e-05, forward_time=0.001, loss=4.091, backward_time=0.001, grad_norm=1.650, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,533 (trainer:780) INFO: 17epoch:train:361-384batch: iter_time=4.771e-05, forward_time=0.001, loss=4.174, backward_time=0.001, grad_norm=1.695, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,632 (trainer:780) INFO: 17epoch:train:385-408batch: iter_time=4.773e-05, forward_time=0.001, loss=4.109, backward_time=0.001, grad_norm=1.646, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.164e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,734 (trainer:780) INFO: 17epoch:train:409-432batch: iter_time=4.727e-05, forward_time=0.001, loss=4.178, backward_time=0.001, grad_norm=1.570, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.150e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,837 (trainer:780) INFO: 17epoch:train:433-456batch: iter_time=4.695e-05, forward_time=0.001, loss=4.186, backward_time=0.001, grad_norm=1.675, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:14,937 (trainer:780) INFO: 17epoch:train:457-480batch: iter_time=4.805e-05, forward_time=0.001, loss=4.146, backward_time=0.001, grad_norm=1.668, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:15,774 (trainer:365) INFO: 17epoch results: [train] iter_time=7.645e-05, forward_time=0.001, loss=4.177, backward_time=0.001, grad_norm=1.611, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.165e-04, optim0_lr0=0.100, train_time=0.004, time=2.06 seconds, total_count=8194, gpu_max_cached_mem_GB=0.213, [valid] loss=4.318, time=0.81 seconds, total_count=5559, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,144 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,147 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/16epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,148 (trainer:299) INFO: 18/20epoch started. Estimated time to finish: 9.87 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,280 (trainer:780) INFO: 18epoch:train:1-24batch: iter_time=6.099e-04, forward_time=0.001, loss=4.073, backward_time=0.001, grad_norm=1.637, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.288e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,383 (trainer:780) INFO: 18epoch:train:25-48batch: iter_time=4.865e-05, forward_time=0.001, loss=4.125, backward_time=0.001, grad_norm=1.634, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.183e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,488 (trainer:780) INFO: 18epoch:train:49-72batch: iter_time=4.781e-05, forward_time=0.001, loss=4.155, backward_time=0.001, grad_norm=1.588, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.176e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,587 (trainer:780) INFO: 18epoch:train:73-96batch: iter_time=4.799e-05, forward_time=0.001, loss=4.032, backward_time=0.001, grad_norm=1.625, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.186e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,689 (trainer:780) INFO: 18epoch:train:97-120batch: iter_time=4.711e-05, forward_time=0.001, loss=4.117, backward_time=0.001, grad_norm=1.698, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,791 (trainer:780) INFO: 18epoch:train:121-144batch: iter_time=4.719e-05, forward_time=0.001, loss=4.137, backward_time=0.001, grad_norm=1.626, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.168e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,891 (trainer:780) INFO: 18epoch:train:145-168batch: iter_time=4.686e-05, forward_time=0.001, loss=4.093, backward_time=0.001, grad_norm=1.643, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.165e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:16,989 (trainer:780) INFO: 18epoch:train:169-192batch: iter_time=4.601e-05, forward_time=0.001, loss=4.066, backward_time=0.001, grad_norm=1.813, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.157e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,090 (trainer:780) INFO: 18epoch:train:193-216batch: iter_time=4.638e-05, forward_time=0.001, loss=4.040, backward_time=0.001, grad_norm=1.631, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.157e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,207 (trainer:780) INFO: 18epoch:train:217-240batch: iter_time=5.149e-05, forward_time=0.001, loss=4.103, backward_time=0.002, grad_norm=1.697, clip=0.000e+00, loss_scale=1.000, optim_step_time=2.658e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,308 (trainer:780) INFO: 18epoch:train:241-264batch: iter_time=4.995e-05, forward_time=0.001, loss=4.055, backward_time=0.001, grad_norm=1.735, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.177e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,406 (trainer:780) INFO: 18epoch:train:265-288batch: iter_time=4.981e-05, forward_time=0.001, loss=4.044, backward_time=0.001, grad_norm=1.710, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.178e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,508 (trainer:780) INFO: 18epoch:train:289-312batch: iter_time=4.985e-05, forward_time=0.001, loss=4.140, backward_time=0.001, grad_norm=1.599, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.174e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,610 (trainer:780) INFO: 18epoch:train:313-336batch: iter_time=5.242e-05, forward_time=0.001, loss=4.002, backward_time=0.001, grad_norm=1.770, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.168e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,711 (trainer:780) INFO: 18epoch:train:337-360batch: iter_time=4.932e-05, forward_time=0.001, loss=4.095, backward_time=0.001, grad_norm=1.752, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.164e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,812 (trainer:780) INFO: 18epoch:train:361-384batch: iter_time=4.991e-05, forward_time=0.001, loss=4.076, backward_time=0.001, grad_norm=1.802, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.170e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:17,911 (trainer:780) INFO: 18epoch:train:385-408batch: iter_time=4.964e-05, forward_time=0.001, loss=4.040, backward_time=0.001, grad_norm=1.726, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.192e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:18,008 (trainer:780) INFO: 18epoch:train:409-432batch: iter_time=4.978e-05, forward_time=0.001, loss=4.012, backward_time=9.893e-04, grad_norm=1.767, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.162e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:18,108 (trainer:780) INFO: 18epoch:train:433-456batch: iter_time=5.066e-05, forward_time=0.001, loss=4.047, backward_time=0.001, grad_norm=1.686, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.170e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:18,208 (trainer:780) INFO: 18epoch:train:457-480batch: iter_time=5.059e-05, forward_time=0.001, loss=3.993, backward_time=0.001, grad_norm=1.688, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,047 (trainer:365) INFO: 18epoch results: [train] iter_time=7.693e-05, forward_time=0.001, loss=4.074, backward_time=0.001, grad_norm=1.691, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.250e-04, optim0_lr0=0.100, train_time=0.004, time=2.09 seconds, total_count=8676, gpu_max_cached_mem_GB=0.213, [valid] loss=4.246, time=0.81 seconds, total_count=5886, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,416 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,419 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/17epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,420 (trainer:299) INFO: 19/20epoch started. Estimated time to finish: 6.58 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,555 (trainer:780) INFO: 19epoch:train:1-24batch: iter_time=6.101e-04, forward_time=0.001, loss=3.985, backward_time=0.001, grad_norm=1.718, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.295e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,658 (trainer:780) INFO: 19epoch:train:25-48batch: iter_time=4.923e-05, forward_time=0.001, loss=4.061, backward_time=0.001, grad_norm=1.728, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.202e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,758 (trainer:780) INFO: 19epoch:train:49-72batch: iter_time=4.709e-05, forward_time=0.001, loss=3.994, backward_time=0.001, grad_norm=1.685, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.164e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,859 (trainer:780) INFO: 19epoch:train:73-96batch: iter_time=4.722e-05, forward_time=0.001, loss=4.006, backward_time=0.001, grad_norm=1.775, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.157e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:19,961 (trainer:780) INFO: 19epoch:train:97-120batch: iter_time=4.753e-05, forward_time=0.001, loss=4.022, backward_time=0.001, grad_norm=1.753, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.169e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,064 (trainer:780) INFO: 19epoch:train:121-144batch: iter_time=4.764e-05, forward_time=0.001, loss=4.047, backward_time=0.001, grad_norm=1.791, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.161e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,163 (trainer:780) INFO: 19epoch:train:145-168batch: iter_time=4.651e-05, forward_time=0.001, loss=3.965, backward_time=0.001, grad_norm=1.778, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.154e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,262 (trainer:780) INFO: 19epoch:train:169-192batch: iter_time=4.705e-05, forward_time=0.001, loss=3.892, backward_time=9.958e-04, grad_norm=1.776, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.147e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,362 (trainer:780) INFO: 19epoch:train:193-216batch: iter_time=4.793e-05, forward_time=0.001, loss=3.988, backward_time=0.001, grad_norm=1.723, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.146e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,461 (trainer:780) INFO: 19epoch:train:217-240batch: iter_time=4.739e-05, forward_time=0.001, loss=3.932, backward_time=0.001, grad_norm=1.784, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.163e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,559 (trainer:780) INFO: 19epoch:train:241-264batch: iter_time=4.619e-05, forward_time=0.001, loss=3.902, backward_time=9.999e-04, grad_norm=1.705, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.158e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,659 (trainer:780) INFO: 19epoch:train:265-288batch: iter_time=4.836e-05, forward_time=0.001, loss=4.029, backward_time=0.001, grad_norm=1.870, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.149e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,760 (trainer:780) INFO: 19epoch:train:289-312batch: iter_time=4.752e-05, forward_time=0.001, loss=4.037, backward_time=0.001, grad_norm=1.866, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.156e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,861 (trainer:780) INFO: 19epoch:train:313-336batch: iter_time=4.732e-05, forward_time=0.001, loss=3.967, backward_time=0.001, grad_norm=1.802, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.142e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:20,961 (trainer:780) INFO: 19epoch:train:337-360batch: iter_time=4.783e-05, forward_time=0.001, loss=3.987, backward_time=0.001, grad_norm=1.753, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.159e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:21,062 (trainer:780) INFO: 19epoch:train:361-384batch: iter_time=4.794e-05, forward_time=0.001, loss=4.001, backward_time=0.001, grad_norm=1.748, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.166e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:21,161 (trainer:780) INFO: 19epoch:train:385-408batch: iter_time=4.704e-05, forward_time=0.001, loss=3.945, backward_time=0.001, grad_norm=1.760, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.160e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:21,261 (trainer:780) INFO: 19epoch:train:409-432batch: iter_time=4.837e-05, forward_time=0.001, loss=3.906, backward_time=0.001, grad_norm=1.783, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.173e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:21,358 (trainer:780) INFO: 19epoch:train:433-456batch: iter_time=4.766e-05, forward_time=0.001, loss=3.865, backward_time=9.865e-04, grad_norm=1.761, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.153e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:21,456 (trainer:780) INFO: 19epoch:train:457-480batch: iter_time=4.781e-05, forward_time=0.001, loss=3.877, backward_time=9.959e-04, grad_norm=1.780, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.151e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:22,294 (trainer:365) INFO: 19epoch results: [train] iter_time=7.556e-05, forward_time=0.001, loss=3.973, backward_time=0.001, grad_norm=1.766, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.166e-04, optim0_lr0=0.100, train_time=0.004, time=2.06 seconds, total_count=9158, gpu_max_cached_mem_GB=0.213, [valid] loss=4.179, time=0.81 seconds, total_count=6213, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:22,680 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:22,683 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/18epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:22,684 (trainer:299) INFO: 20/20epoch started. Estimated time to finish: 3.29 seconds\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:22,817 (trainer:780) INFO: 20epoch:train:1-24batch: iter_time=6.213e-04, forward_time=0.001, loss=3.860, backward_time=0.001, grad_norm=1.721, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.275e-04, optim0_lr0=0.100, train_time=0.005\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:22,919 (trainer:780) INFO: 20epoch:train:25-48batch: iter_time=4.759e-05, forward_time=0.001, loss=3.938, backward_time=0.001, grad_norm=1.881, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.133e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,019 (trainer:780) INFO: 20epoch:train:49-72batch: iter_time=4.713e-05, forward_time=0.001, loss=3.904, backward_time=0.001, grad_norm=1.691, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.124e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,118 (trainer:780) INFO: 20epoch:train:73-96batch: iter_time=4.547e-05, forward_time=0.001, loss=3.874, backward_time=0.001, grad_norm=1.747, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,212 (trainer:780) INFO: 20epoch:train:97-120batch: iter_time=4.582e-05, forward_time=0.001, loss=3.756, backward_time=9.938e-04, grad_norm=1.871, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.118e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,312 (trainer:780) INFO: 20epoch:train:121-144batch: iter_time=4.519e-05, forward_time=0.001, loss=3.901, backward_time=0.001, grad_norm=1.939, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.143e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,412 (trainer:780) INFO: 20epoch:train:145-168batch: iter_time=4.632e-05, forward_time=0.001, loss=3.866, backward_time=0.001, grad_norm=1.766, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.117e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,514 (trainer:780) INFO: 20epoch:train:169-192batch: iter_time=4.651e-05, forward_time=0.001, loss=3.947, backward_time=0.001, grad_norm=1.826, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.125e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,611 (trainer:780) INFO: 20epoch:train:193-216batch: iter_time=4.643e-05, forward_time=0.001, loss=3.833, backward_time=0.001, grad_norm=1.797, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.128e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,711 (trainer:780) INFO: 20epoch:train:217-240batch: iter_time=4.572e-05, forward_time=0.001, loss=3.934, backward_time=0.001, grad_norm=1.871, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.108e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,808 (trainer:780) INFO: 20epoch:train:241-264batch: iter_time=4.564e-05, forward_time=0.001, loss=3.826, backward_time=9.954e-04, grad_norm=1.862, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.111e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:23,906 (trainer:780) INFO: 20epoch:train:265-288batch: iter_time=4.573e-05, forward_time=0.001, loss=3.861, backward_time=0.001, grad_norm=1.834, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.112e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,007 (trainer:780) INFO: 20epoch:train:289-312batch: iter_time=4.664e-05, forward_time=0.001, loss=3.884, backward_time=0.001, grad_norm=1.742, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.114e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,105 (trainer:780) INFO: 20epoch:train:313-336batch: iter_time=4.557e-05, forward_time=0.001, loss=3.862, backward_time=0.001, grad_norm=1.803, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.111e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,205 (trainer:780) INFO: 20epoch:train:337-360batch: iter_time=4.567e-05, forward_time=0.001, loss=3.891, backward_time=0.001, grad_norm=1.816, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.113e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,300 (trainer:780) INFO: 20epoch:train:361-384batch: iter_time=4.648e-05, forward_time=0.001, loss=3.756, backward_time=9.871e-04, grad_norm=1.849, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.118e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,399 (trainer:780) INFO: 20epoch:train:385-408batch: iter_time=4.588e-05, forward_time=0.001, loss=3.859, backward_time=0.001, grad_norm=1.782, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.111e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,499 (trainer:780) INFO: 20epoch:train:409-432batch: iter_time=4.537e-05, forward_time=0.001, loss=3.921, backward_time=0.001, grad_norm=1.941, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.108e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,595 (trainer:780) INFO: 20epoch:train:433-456batch: iter_time=4.580e-05, forward_time=0.001, loss=3.833, backward_time=0.001, grad_norm=1.939, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.112e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:24,692 (trainer:780) INFO: 20epoch:train:457-480batch: iter_time=4.544e-05, forward_time=0.001, loss=3.811, backward_time=9.951e-04, grad_norm=1.747, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.100e-04, optim0_lr0=0.100, train_time=0.004\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:25,535 (trainer:365) INFO: 20epoch results: [train] iter_time=7.466e-05, forward_time=0.001, loss=3.867, backward_time=0.001, grad_norm=1.823, clip=0.000e+00, loss_scale=1.000, optim_step_time=1.125e-04, optim0_lr0=0.100, train_time=0.004, time=2.03 seconds, total_count=9640, gpu_max_cached_mem_GB=0.213, [valid] loss=4.135, time=0.82 seconds, total_count=6540, gpu_max_cached_mem_GB=0.213\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:25,917 (trainer:433) INFO: The best model has been updated: valid.loss\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:25,920 (trainer:487) INFO: The model files were removed: exp/lm/cy/rnn/19epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-04 13:02:25,920 (trainer:505) INFO: The training was finished at 20 epochs \n"
     ]
    }
   ],
   "source": [
    "from espnet2.tasks.lm import LMTask\n",
    "\n",
    "LMTask.main(cmd=[\n",
    "    \"--config\", \"train_lm.yaml\",\n",
    "    \"--train_data_path_and_name_and_type\", \"dump/train/text,text,text\",\n",
    "    \"--valid_data_path_and_name_and_type\", \"dump/valid/text,text,text\",\n",
    "    \"--train_shape_file\", \"dump/train/text_shape\",\n",
    "    \"--valid_shape_file\", \"dump/valid/text_shape\",\n",
    "    \"--output_dir\", \"exp/lm/cy/rnn\",\n",
    "    \"--ngpu\", \"1\",\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espnet",
   "language": "python",
   "name": "espnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
