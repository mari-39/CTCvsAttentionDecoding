{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJfV0Ql6Q7UH"
   },
   "source": [
    "## Configure Training Process\n",
    "\n",
    "For configuring the training process, you can utilize the configuration files already provided by ESPnet contributors. To use a configuration file, you'll need to create a YAML file on your local machine. For instance, you can use the [e-branchformer config](train_asr_e-branchformer_size256_mlp1024_linear1024_e12_mactrue_edrop0.0_ddrop0.0.yaml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AS_TiL8oogtX",
    "outputId": "32705626-53c0-4de8-c748-8d5b824ef405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train.yml\n",
    "# network architecture\n",
    "\n",
    "# frontend related\n",
    "# This is a configuration file for training an ASR model using ESPnet.\n",
    "# It specifies the architecture, optimization settings, and data processing parameters.\n",
    "# The model uses a conformer encoder and a transformer decoder with hybrid CTC/attention loss\n",
    "# Since we compare CTC and attention decoding, we keep the encoder input identical. \n",
    "# 80-dim log-mel is ESPnet's default input representation.\n",
    "\n",
    "frontend: default\n",
    "frontend_conf:\n",
    "    n_fft: 512 # Number of FFT points for STFT, 32 ms @ 16 kHz\n",
    "    win_length: 400 # Window length for STFT, 25 ms @ 16 kHz\n",
    "    hop_length: 160 # Hop length for STFT, 10 ms @ 16 kHz\n",
    "\n",
    "# this configures how audio is converted to spectrograms -> the input\n",
    "# representation for the neural network\n",
    "\n",
    "\n",
    "# encoder related\n",
    "# The encoder is a conformer model, which combines convolutional and self-attention mechanisms.\n",
    "# It consists of 12 blocks with a linear unit size of 2048 and an output size of 256.\n",
    "# The attention mechanism uses 4 heads, and the model employs relative positional encoding.\n",
    "# The activation function is Swish, and it uses a macaron style with CNN modules\n",
    "# with a kernel size of 15. \n",
    "# A conformer combines the strengths of convolutional neural networks (CNNs, local feature extraction) and \n",
    "# transformers (long-range dependencies). Why conformer?\n",
    "# Convolution (local invariance, which means it can recognize patterns regardless of their position in the input sequence) \n",
    "# is good for local feature extraction, while self-attention (global invariance) \n",
    "# is good for long-range dependencies.\n",
    "# This is particularly good for small datasets, because the CNN module works as an inductive bias \n",
    "# (i.e., it helps the model generalize better from limited data), and SpecAugment makes it robust to noise.\n",
    "\n",
    "encoder: conformer\n",
    "encoder_conf:\n",
    "    input_layer: conv2d # strided 2-D CNN front\n",
    "    num_blocks: 12\n",
    "    linear_units: 2048 # FFN inner-dim \n",
    "    dropout_rate: 0.1\n",
    "    output_size: 256 # hidden dim per frame\n",
    "    attention_heads: 4\n",
    "    attention_dropout_rate: 0.0\n",
    "    pos_enc_layer_type: rel_pos\n",
    "    selfattention_layer_type: rel_selfattn\n",
    "    activation_type: swish\n",
    "    macaron_style: true\n",
    "    use_cnn_module: true\n",
    "    cnn_module_kernel: 15\n",
    "\n",
    "\n",
    "# decoder related\n",
    "# The decoder is a transformer model with 6 blocks, each having a linear unit size of 2048.\n",
    "# It uses an embedding layer for input and has a dropout rate of 0.1.\n",
    "# The transformer decoder is designed to handle sequential data.\n",
    "decoder_conf:\n",
    "    input_layer: embed \n",
    "    num_blocks: 6\n",
    "    linear_units: 2048\n",
    "    dropout_rate: 0.1\n",
    "\n",
    "# The decoder generates text sequences from the encoded audio features.\n",
    "\n",
    "# hybrid CTC/attention\n",
    "# The model uses a hybrid CTC/attention mechanism for training.\n",
    "# CTC (Connectionist Temporal Classification) is used for sequence-to-sequence tasks where the alignment \n",
    "# between input and output sequences is not known.\n",
    "# The attention mechanism allows the model to focus on specific parts of the input sequence when generating each output token.\n",
    "# Therefore it provides better sequence modeling.\n",
    "# The CTC weight is set to 0.3, and the label smoothing weight is set to 0.1.\n",
    "# This weight can be adjusted to compare CTC and attention decoding.\n",
    "\n",
    "# Length\n",
    "# ctc weight 1 - pure CTC, no auto-reg decoding -> can test greedy CTC decoding\n",
    "# ctc weight 0 - pure attention, no CTC loss -> can test autoreg decoding\n",
    "# ctc_weight: 0.3 - \n",
    "model_conf:\n",
    "    ctc_weight: 0.3 # 0.3 * CTC loss + 0.7 * attention loss\n",
    "    lsm_weight: 0.1 # label smoothing weight, which helps prevent overfitting by smoothing the target labels\n",
    "    length_normalized_loss: false\n",
    "\n",
    "# optimization related\n",
    "# The optimizer used is Adam with a learning rate of 4.0.\n",
    "# Gradient accumulation is set to 1, meaning gradients are updated after each batch.\n",
    "# Gradient clipping is set to 3 to prevent exploding gradients.\n",
    "# The maximum number of epochs for training is set to 50.\n",
    "# The Noam learning rate scheduler is used with a model size of 256 and a warmup period of 25000 steps.\n",
    "# The Noam scheduler gradually increases the learning rate during the warmup phase and then decreases it.\n",
    "# This helps stabilize training in the initial stages.\n",
    "optim: adam\n",
    "accum_grad: 1\n",
    "grad_clip: 3\n",
    "max_epoch: 50\n",
    "optim_conf:\n",
    "    lr: 4.0 #  # This is NOT a raw LR!  ESPnet’s Noam LR = scale * d_model^-0.5\n",
    "scheduler: noamlr\n",
    "scheduler_conf:\n",
    "    model_size: 256\n",
    "    warmup_steps: 25000\n",
    "\n",
    "\n",
    "\n",
    "# minibatch\n",
    "# the batch means the number of samples in each training step. The type of batch is 'numel', which means \n",
    "# the batch size is determined by the total number of elements in the batch.\n",
    "# The batch_bins parameter specifies the number of bins for batching, which is set to 10 million.\n",
    "batch_type: numel\n",
    "batch_bins: 10000000\n",
    "\n",
    "# the best_model_criterion specifies the metric used to select the best model during training.\n",
    "# In this case, it uses validation accuracy ('valid' and 'acc') and selects the maximum value.\n",
    "# This means the model with the highest validation accuracy will be saved as the best model.\n",
    "# The keep_nbest_models parameter specifies how many of the best models to keep during training.\n",
    "best_model_criterion:\n",
    "-   - valid\n",
    "    - acc\n",
    "    - max\n",
    "keep_nbest_models: 3\n",
    "# valid/acc in ESPnet = 1 – WER during dev decoding (because higher = better).\n",
    "\n",
    "\n",
    "# SpeAugment is a data augmentation technique that applies various transformations to the input audio data.\n",
    "# It includes time warping, frequency masking, and time masking to improve the model's robustness. \n",
    "# It masks certain frequency bands and time segments in the spectrogram to simulate noise and variability in the data.\n",
    "# This helps the model generalize better to unseen data.\n",
    "# The configuration specifies that time warping is applied with a window size of 5, \n",
    "# frequency masking is applied with a width range of 0 to 30, and time masking is applied with a width range of 0 to 40.\n",
    "# The number of frequency masks is set to 2, and the number of time masks is set to 2.\n",
    "# The time warping mode is set to bicubic interpolation, which provides smooth transformations.\n",
    "\n",
    "specaug: specaug # Data augmentation\n",
    "specaug_conf: \n",
    "    apply_time_warp: true\n",
    "    time_warp_window: 5\n",
    "    time_warp_mode: bicubic\n",
    "    apply_freq_mask: true\n",
    "    freq_mask_width_range:\n",
    "    - 0\n",
    "    - 30\n",
    "    num_freq_mask: 2\n",
    "    apply_time_mask: true\n",
    "    time_mask_width_range:\n",
    "    - 0\n",
    "    - 40\n",
    "    num_time_mask: 2\n",
    "    \n",
    "\n",
    "# The training process will not use any visualization tools like Matplotlib or TensorBoard as of now.\n",
    "# But in the future, we will work on this.\n",
    "use_matplotlib: false\n",
    "use_tensorboard: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hf03KvM_oztz",
    "outputId": "f9469d2b-feeb-4777-d146-8396fc691e08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./preprocess.yaml\n"
     ]
    }
   ],
   "source": [
    "# preprocessing configuration\n",
    "# This section specifies the preprocessing steps for the input data.\n",
    "# It includes the use of a preprocessor, tokenization method (BPE), and various audio processing parameters.\n",
    "# The preprocessor is set to 'default', and the configuration includes parameters for speech normalization, noise application, and tokenization.\n",
    "# The BPE model is specified, and the token list is provided for the model to understand the vocabulary.\n",
    "# The configuration also allows for the application of RIR (Room Impulse Response) and noise to the audio data, with specified probabilities for their application.\n",
    "# The speech volume normalization and non-linguistic symbols are set to null, indicating no specific processing for these aspects.\n",
    "# The g2p (grapheme-to-phoneme) and cleaner configurations are also set to null, meaning no specific processing is applied for these tasks.\n",
    "# The token list is specified, which contains the vocabulary used for tokenization.\n",
    "# The preprocessor_conf section specifies the names of the speech and text fields in the data.\n",
    "# The use_preprocessor flag indicates whether to use a preprocessor for the data.\n",
    "\n",
    "\n",
    "\n",
    "%%writefile ./preprocess.yaml\n",
    "use_preprocessor: true\n",
    "\n",
    "token_type: bpe # Tokenization method, same for both models\n",
    "bpemodel: data/bpemodel/bpe.model # BPE model file\n",
    "rir_scp: null # Room Impulse Response script\n",
    "rir_apply_prob: 1.0 # Probability of applying RIR -> currently 1.0. RIR simulates the effect of different room acoustics on the audio data.\n",
    "noise_scp: null # Noise script\n",
    "noise_apply_prob: 1.0 # Probability of applying noise, currently 1.0\n",
    "noise_db_range: '13_15' # Range of noise dB levels to apply\n",
    "speech_volume_normalize: null # Speech volume normalization\n",
    "non_linguistic_symbols: null \n",
    "\n",
    "cleaner: null # Text cleaner\n",
    "g2p: null # Grapheme-to-phoneme conversion, null means no conversion\n",
    "preprocessor: default \n",
    "preprocessor_conf:\n",
    "  speech_name: speech # Name of the speech field in the data\n",
    "  text_name: text # Name of the text field in the data\n",
    "\n",
    "token_list: data/bpemodel/tokens.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2o-498EQ7UI"
   },
   "source": [
    "## Training\n",
    "\n",
    "To prepare the stats file before training, you can execute the `collect_stats` method. This step is required before the training process and ensuring accurate statistics for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r ./exp/stats\n",
    "# !rm -r ./exp/train_asr_branchformer_e24_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMWd0vwiQ7UI",
    "outputId": "8eb6f479-97cc-4533-e8b2-7c53d13f7dd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/espnet/bin/python /opt/conda/envs/espnet/lib/python3.10/site-packages/ipykernel_launcher.py -f /home/jovyan/.local/share/jupyter/runtime/kernel-510df032-2600-4a04-accf-ec5898abdc32.json\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,091 (asr:523) INFO: Vocabulary size: 1000\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,093 (conformer_encoder:146) WARNING: Using legacy_rel_pos and it will be deprecated in the future.\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,102 (conformer_encoder:269) WARNING: Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,472 (abs_task:1383) INFO: pytorch.version=2.5.1, cuda.available=True, cudnn.version=90100, cudnn.benchmark=False, cudnn.deterministic=True\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,477 (abs_task:1384) INFO: Model structure:\n",
      "ESPnetASRModel(\n",
      "  (frontend): DefaultFrontend(\n",
      "    (stft): Stft(n_fft=512, win_length=400, hop_length=160, center=True, normalized=False, onesided=True)\n",
      "    (frontend): Frontend()\n",
      "    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)\n",
      "  )\n",
      "  (specaug): SpecAug(\n",
      "    (time_warp): TimeWarp(window=5, mode=bicubic)\n",
      "    (freq_mask): MaskAlongAxis(mask_width_range=[0, 30], num_mask=2, axis=freq)\n",
      "    (time_mask): MaskAlongAxis(mask_width_range=[0, 40], num_mask=2, axis=time)\n",
      "  )\n",
      "  (normalize): UtteranceMVN(norm_means=True, norm_vars=False)\n",
      "  (encoder): ConformerEncoder(\n",
      "    (embed): Conv2dSubsampling(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (out): Sequential(\n",
      "        (0): Linear(in_features=4864, out_features=256, bias=True)\n",
      "        (1): LegacyRelPositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoders): MultiSequential(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (6): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (7): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (8): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (9): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (10): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (11): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embed): Sequential(\n",
      "      (0): Embedding(1000, 256)\n",
      "      (1): PositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "    (output_layer): Linear(in_features=256, out_features=1000, bias=True)\n",
      "    (decoders): MultiSequential(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion_att): LabelSmoothingLoss(\n",
      "    (criterion): KLDivLoss()\n",
      "  )\n",
      "  (ctc): CTC(\n",
      "    (ctc_lo): Linear(in_features=256, out_features=1000, bias=True)\n",
      "    (ctc_loss): CTCLoss()\n",
      "  )\n",
      ")\n",
      "\n",
      "Model summary:\n",
      "    Class Name: ESPnetASRModel\n",
      "    Total Number of model parameters: 43.71 M\n",
      "    Number of trainable parameters: 43.71 M (100.0%)\n",
      "    Size: 174.83 MB\n",
      "    Type: torch.float32\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,477 (abs_task:1387) INFO: Optimizer:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 4.0\n",
      "    lr: 6.324555320336758e-08\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,478 (abs_task:1388) INFO: Scheduler: NoamLR(model_size=256, warmup_steps=25000)\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,480 (abs_task:1397) INFO: Saving the configuration in exp/stats/config.yaml\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,497 (abs_task:1408) INFO: Namespace(log_level='INFO', drop_last_iter=False, dry_run=False, iterator_type='sequence', valid_iterator_type=None, output_dir='exp/stats', seed=0, num_workers=1, num_att_plot=3, dist_backend='nccl', dist_init_method='env://', dist_world_size=None, dist_rank=None, local_rank=None, dist_master_addr=None, dist_master_port=None, dist_launcher=None, multiprocessing_distributed=False, unused_parameters=False, sharded_ddp=False, use_deepspeed=False, deepspeed_config=None, cudnn_enabled=True, cudnn_benchmark=False, cudnn_deterministic=True, use_tf32=False, collect_stats=True, write_collected_feats=False, max_epoch=50, patience=None, val_scheduler_criterion=('valid', 'loss'), early_stopping_criterion=('valid', 'loss', 'min'), best_model_criterion=[['valid', 'acc', 'max']], keep_nbest_models=3, nbest_averaging_interval=0, grad_clip=3, grad_clip_type=2.0, grad_noise=False, accum_grad=1, no_forward_run=False, resume=False, train_dtype='float32', use_amp=False, log_interval=None, use_matplotlib=False, use_tensorboard=False, create_graph_in_tensorboard=False, use_wandb=False, wandb_project=None, wandb_id=None, wandb_entity=None, wandb_name=None, wandb_model_log_interval=-1, detect_anomaly=False, use_adapter=False, adapter='lora', save_strategy='all', adapter_conf={}, pretrain_path=None, init_param=[], ignore_init_mismatch=False, freeze_param=[], num_iters_per_epoch=None, batch_size=20, valid_batch_size=None, batch_bins=10000000, valid_batch_bins=None, category_sample_size=10, train_shape_file=[], valid_shape_file=[], batch_type='numel', valid_batch_type=None, fold_length=[], sort_in_batch='descending', shuffle_within_batch=False, sort_batch='descending', multiple_iterator=False, chunk_length=500, chunk_shift_ratio=0.5, num_cache_chunks=1024, chunk_excluded_key_prefixes=[], chunk_default_fs=None, chunk_max_abs_length=None, chunk_discard_short_samples=True, train_data_path_and_name_and_type=[('dump/train/wav.scp', 'speech', 'sound'), ('dump/train/text', 'text', 'text')], valid_data_path_and_name_and_type=[('dump/valid/wav.scp', 'speech', 'sound'), ('dump/valid/text', 'text', 'text')], multi_task_dataset=False, allow_variable_data_keys=False, max_cache_size=0.0, max_cache_fd=32, allow_multi_rates=False, valid_max_cache_size=None, exclude_weight_decay=False, exclude_weight_decay_conf={}, optim='adam', optim_conf={'lr': 4.0}, scheduler='noamlr', scheduler_conf={'model_size': 256, 'warmup_steps': 25000}, token_list=['<blank>', '<unk>', '▁y', 'dd', '▁a', '▁g', '▁yn', 'ae', 'wy', 'th', '▁c', 'an', '▁d', 'ei', '▁o', 'yn', '▁f', '▁b', 'll', '▁i', '▁h', 'au', 'edd', 'ol', 'er', 'ch', '▁m', 'ai', 'en', 'ed', '▁M', 'ad', 'io', '▁ar', 'ar', 'od', '▁s', 'wn', '▁n', 'ydd', 'yd', '▁Mae', '▁p', '▁r', 'yf', 'el', '▁dd', '▁ei', '▁w', 'ri', '▁t', 'ef', '▁D', '▁C', 'es', 'or', 'eu', 'af', 'oedd', '▁ll', 'ym', 'on', 'aw', 'un', 'odd', '▁gw', '▁R', 'aeth', 'edi', '▁rh', '▁am', 'iad', '▁G', 'sg', '▁Y', 'wydd', 'ro', '▁A', '▁yr', '▁di', 'yw', 'st', '▁ch', 'eg', '▁ym', 'ir', 'al', '▁B', '▁gan', '▁l', 'as', '▁ff', 'ig', '▁wedi', 'in', 'ynn', '▁oedd', 'iau', 'ff', 'wyd', 'eth', '▁Roedd', 'eith', 'ewn', '▁ac', 'ion', '▁N', 'og', '▁un', 'os', 'ell', 'wr', 'wyn', '▁gyf', 'ob', '▁yw', '▁P', 'id', 'eb', '▁S', 'yg', 'yr', '▁L', '▁mae', 'ur', '▁mewn', 'at', '▁cyf', '▁E', 'ys', '▁F', 'ael', 'ych', '▁ddi', 'ach', 'wyr', '▁an', 'il', 'ant', 'yl', 'am', 'all', 'efn', '▁hi', 'rif', 'awn', '▁T', '▁dr', 'enn', 'aith', 'ymr', '▁gyd', '▁bl', 'efyd', '▁Ll', 'ag', 'wch', 'of', 'nd', '▁hyn', 'aid', 'tr', '▁er', '▁fel', '▁W', '▁eu', '▁O', 'us', '▁ad', 'wys', '▁hefyd', 'ddi', 'awr', '▁ni', 'gh', 'ysg', 'ain', '▁br', '▁tr', 'yfr', 'aen', '▁Yn', '▁at', \"▁'\", 'iadau', 'eud', '▁gyda', '▁bod', '▁H', '▁nh', '▁cyn', '▁fod', '▁sy', 'iaeth', 'em', '▁Rh', 'om', '▁wr', 'iw', 'fer', 'ann', 'efnydd', 'ech', 'wedd', 'ôl', '▁yd', 'ew', '▁iawn', '▁â', 'iol', '▁chw', 'eir', '▁nhw', 'ud', 'et', 'wl', 'aidd', 'bl', 'ein', 'is', 'ddo', 'ynd', 'ath', '▁ddim', '▁en', '▁Cymr', '▁cael', 'fr', '▁si', '▁bob', '▁fy', '▁ysg', 'ewydd', 'add', '▁th', '▁pl', '▁gr', '▁ôl', '▁dro', 'wneud', '▁wrth', '▁Ar', '▁Yr', '▁gyfer', 'lyn', '▁co', '▁gl', 'ynt', '▁cr', '▁hwn', 'ang', 'edig', 'rych', '▁Gw', '▁neu', 'awer', 'ab', 'lu', '▁sg', '▁I', 'wyth', 'eid', '▁ph', '▁yma', 'ori', '▁can', 'wm', 'ent', 'est', '▁st', '▁e', 'ais', 'eol', '▁ti', '▁gor', '▁Bydd', '▁newydd', '▁chi', '▁hynn', '▁ag', 'ws', 'asg', 'wyl', '▁cynn', 'eil', 'eld', 'yma', '▁gael', '▁all', '▁pob', 'ap', '▁Bu', 'afodd', 'eithio', '▁ef', 'air', '▁ond', 'ic', 'erch', '▁mynd', 'fa', 'yll', '▁Dw', '▁go', '▁hynny', 'arn', 'gen', '▁cl', 'erth', '▁yng', 'byn', 'eis', 'rin', '▁fl', '▁ho', '▁Mi', 'ni', '▁pr', 'nod', '▁hun', 'gl', 'if', 'ŵr', 'wd', '▁mwy', '▁Nid', '▁hyd', 'fan', 'ill', 'wyb', '▁dros', '▁ger', '▁yst', 'ac', '▁Dyma', 'oi', '▁u', 'wng', 'ynydd', 'aeg', '▁Fe', '▁hen', 'rh', '▁J', '▁ol', 'iodd', '▁dyn', '▁enw', '▁roedd', 'di', 'ia', 'echr', '▁fwy', '▁ydy', '▁rhyw', '▁medd', '▁llawer', 'wg', '▁dim', '▁fydd', '▁defnydd', 'oc', 'oes', '▁gwr', '▁sydd', 'yth', 'anol', 'aff', 'ofel', 'wyll', 'ah', 'ot', 'ordd', '▁bach', 'hau', 'iant', '▁bar', '▁ben', 'awl', '▁dy', '▁Ond', 'yddol', '▁na', '▁pen', 'ec', 'ân', 'ast', '▁bu', '▁Cymru', '▁chwar', 'liad', 'ylch', '▁dar', 'edl', 'fod', 'elod', '▁beth', 'yh', '▁car', '▁gall', '▁arall', '▁U', '▁wn', 'arth', '▁Ceir', '▁cer', '▁cym', 'aill', '▁aml', '▁yna', '▁Gymr', '▁Ni', '▁or', '▁bobl', 'yst', '▁add', '▁bydd', '▁iddo', 'chw', 'ryd', 'ser', 'yng', '▁Al', 'tref', '▁gol', '▁ysgol', 'eithiau', '▁cynnwys', '▁dw', 'si', 'iog', 'odi', '▁gym', '▁ddau', '▁drwy', '▁ed', 'eiri', '▁hon', '▁oes', '▁hedd', 'ml', 'awd', 'edin', '▁par', '▁Cafodd', '▁gar', 'yhoedd', '▁aelod', '▁allan', '▁angen', '▁gwaith', '▁chwarae', 'na', 'and', 'aws', 'gar', '▁lle', 'wybod', '▁rhai', '▁amser', 'op', 'wrdd', 'wynt', '▁dig', 'angos', '▁Gall', 'ryw', 'aiff', '▁sym', 'fredin', 'ôr', 'aer', '▁tu', '▁gyn', '▁yno', '▁siar', '▁wneud', 'arw', 'res', '▁gad', '▁tro', '▁nifer', '▁ffordd', '▁oh', 'ysgu', '▁adr', '▁edrych', '▁eraill', 'der', 'isg', 'ygu', 'rhyw', '▁bro', '▁han', '▁mor', 'wyneb', '▁plant', '▁gwneud', '▁unrhyw', 'edr', '▁mi', 'ywod', 'ellir', '▁mawr', '▁Doedd', '▁rhwng', 'ans', '▁Dd', 'eulu', '▁nid', '▁syl', 'uniau', 'eiml', '▁ach', '▁byd', '▁disg', '▁rhan', 'ellach', 'ut', 'edw', '▁fr', 'iaid', '▁hir', '▁yml', 'asgliad', '▁ddefnydd', 'ôn', '▁fe', 'yrch', '▁dat', '▁heb', '▁unig', '▁Am', '▁gen', '▁hel', '▁oed', 'ynyddoedd', 'dal', 'fyn', '▁de', '▁fi', 'adau', 'wdur', '▁Mar', '▁Ngh', '▁Rwy', '▁ail', '▁str', '▁gwel', '▁llyfr', '▁uch', '▁lliw', 'le', 'ith', 'asan', '▁cys', '▁dda', '▁ein', '▁iddi', '▁rhag', '▁dechr', '▁gweld', 'gr', 'aig', 'ian', 'urf', '▁Ch', '▁Un', '▁du', '▁dal', '▁dydd', '▁fath', 'rifenn', '▁Daeth', '▁amryw', 'asanaeth', 'osi', '▁Ym', '▁et', 'estr', '▁per', '▁ardd', '▁fwyd', '▁pobl', '▁blant', '▁swydd', 'edlaeth', 'lad', 'orm', 'udd', 'aint', 'arch', 'ebyg', 'elly', 'ewid', 'odau', '▁ngh', '▁hanes', '▁Cymraeg', 'no', '▁Er', '▁el', 'roes', 'ynnu', 'ynnag', '▁Maen', '▁ddwy', '▁awdur', '▁bynnag', 'yddiaeth', '▁St', 'iann', 'yllt', '▁dan', '▁gof', 'ysgol', '▁cynt', '▁fawr', '▁fewn', 'ahanol', 'weddar', 'wyddyn', '▁arfer', '▁defnyddio', 'eig', 'erm', 'yrr', 'ioed', 'lwyn', 'oleg', 'siau', '▁nad', 'rwydd', '▁hoff', '▁lawr', '▁peth', '▁weld', 'egr', 'rig', '▁An', 'stud', '▁pan', '▁Wedi', '▁Llyfr', '▁meddwl', 'ha', '▁is', '▁dau', 'waith', '▁sawl', 'riaeth', '▁ardal', '▁siarad', 'edu', 'iwn', 'llen', '▁bor', '▁dod', '▁eto', '▁rai', 'deith', '▁Nofel', 'deithas', 'fl', 'och', '▁cw', 'ddor', '▁Dyn', '▁Ysg', '▁ddr', '▁dwy', '▁nos', 'eilad', '▁eich', '▁blaen', '▁rhaid', '▁erioed', '▁gweith', '▁Casgliad', 'mp', 'eff', '▁Cl', '▁Di', 'ywed', '▁Cyn', '▁sio', 'barth', '▁Aeth', '▁fach', '▁fynd', '▁gynn', '▁Gellir', '▁cyntaf', '▁Defnydd', 'yt', 'fon', 'gor', 'iod', 'len', '▁Tr', '▁al', '▁da', 'ardd', 'orri', '▁mwyn', '▁nofel', '▁heddiw', '▁gweithio', '▁blynyddoedd', 'adl', 'ail', 'ani', 'deb', 'gan', 'nes', 'wel', 'yri', '▁os', '▁arb', '▁byw', '▁nod', '▁pro', '▁fedd', '▁astud', '▁symud', '▁ganddo', 'ug', 'ist', 'ogl', '▁of', '▁wy', 'aedd', 'egau', 'ones', '▁cof', '▁gal', '▁awyr', '▁bryd', '▁holl', '▁rhoi', '▁lleol', 'rifysgol', '▁Th', '▁cad', '▁eff', '▁fyn', '▁môr', 'raeth', '▁Does', '▁trwy', '▁wyth', '▁Jones', '▁erbyn', '▁digwydd', 'yb', 'aed', '▁Ed', 'adol', '▁mod', '▁nes', '▁agor', '▁ddig', '▁llawn', '▁gwybod', '▁ymlaen', '▁Gymraeg', 'sb', 'nab', '▁mh', 'iwyd', 'oeth', '▁mai', 'ddynt', 'ieith', '▁mwyaf', '▁newid', '▁wnaeth', '▁adeilad', 'edlaethol', 'it', 'êl', 'iwr', 'tor', '▁eg', '▁es', '▁fu', 'awdd', 'edeg', 'orff', 'ywyd', '▁arw', 'ennau', 'erbyn', 'ethol', '▁Mary', '▁ddyn', '▁gyfr', '▁ohon', '▁ferch', '▁iaith', '▁ystod', 'dr', 'ip', 'oh', 'awb', 'ert', 'aneg', 'beth', 'eidd', '▁amg', '▁byr', '▁mam', '▁syn', 'eisio', 'inell', 'wysig', '▁Gwel', '▁Llan', '▁chyf', '▁cyfr', '▁ddod', '▁cyfar', '▁ffurf', '▁lawer', '▁merch', '▁bellach', '▁ddiweddar', '▁ddefnyddio', 'anc', 'uri', '▁Da', 'ydig', 'yfel', 'ilydd', '▁Mewn', '▁ddar', '▁gwyn', '▁math', 'erwydd', '▁Rhaid', '▁gallu', '▁eisiau', '▁ysgrifenn', 'enedlaethol', 'nos', 'ost', 'son', '▁Ef', '▁Ew', '▁tŷ', 'apur', 'ewis', 'oegr', '▁Cer', '▁Cyf', '▁Cym', '▁amd', '▁cyd', '▁dŵr', '▁sef', '▁wel', 'iolch', 'wrnod', 'ymryd', 'yntaf', '▁coed', '▁Diolch', '▁dechrau', '▁cyffredin', 'chr', 'iam', '▁Ff', 'annu', 'ateg', 'llun', 'orth', '▁ber', '▁sgw', '▁sut', '▁Beth', '▁byth', '▁gwir', '▁bywyd', 'chwaneg', 'ywodraeth', 'ilm', 'lon', '▁Bl', 'inio', '▁Sir', '▁hed', '▁rhy', '▁ymg', 'entyn', 'iadol', '▁wyneb', 'osbarth', 'ghr', 'nau', 'rop', '▁Os', 'allt', 'emau', 'maen', '▁dir', '▁dyf', '▁myn', '▁nat', '▁neb', '▁ran', '▁tri', 'chwil', 'ennaf', '▁Cyfr', '▁angh', '▁dref', '▁farw', '▁ochr', '▁prif', 'chydig', '▁achos', '▁rhydd', '▁Edrych', '▁\"', 'euon', 'odol', '▁Dwi', '▁Fel', '▁fan', '▁ryw', 'anner', 'euodd', '▁aeth', '▁bore', '▁llyg', 'derfyn', '▁ffilm', '▁rheol', '▁teulu', 'eithiol', '▁', 'd', 'a', 'y', 'e', 'n', 'i', 'r', 'o', 'l', 'w', 'h', 'f', 'g', 't', 's', 'u', 'c', '.', 'm', 'b', \"'\", 'p', 'M', ',', 'D', 'C', 'R', 'G', 'Y', 'A', 'B', 'N', 'P', 'S', 'L', 'E', 'F', 'â', 'ô', 'T', '?', 'W', 'O', '-', 'H', 'ŵ', 'I', 'ê', 'J', 'U', 'ŷ', '\"', 'v', 'ï', '!', 'j', 'k', 'î', '<sos/eos>'], init=None, input_size=None, ctc_conf={'dropout_rate': 0.0, 'ctc_type': 'builtin', 'reduce': True, 'ignore_nan_grad': None, 'zero_infinity': True, 'brctc_risk_strategy': 'exp', 'brctc_group_strategy': 'end', 'brctc_risk_factor': 0.0}, joint_net_conf=None, use_preprocessor=True, use_lang_prompt=False, use_nlp_prompt=False, token_type='bpe', bpemodel='data/bpemodel/bpe.model', non_linguistic_symbols=None, cleaner=None, g2p=None, speech_volume_normalize=None, rir_scp=None, rir_apply_prob=1.0, noise_scp=None, noise_apply_prob=1.0, noise_db_range='13_15', short_noise_thres=0.5, aux_ctc_tasks=[], frontend='default', frontend_conf={'n_fft': 512, 'win_length': 400, 'hop_length': 160}, specaug='specaug', specaug_conf={'apply_time_warp': True, 'time_warp_window': 5, 'time_warp_mode': 'bicubic', 'apply_freq_mask': True, 'freq_mask_width_range': [0, 30], 'num_freq_mask': 2, 'apply_time_mask': True, 'time_mask_width_range': [0, 40], 'num_time_mask': 2}, normalize='utterance_mvn', normalize_conf={'norm_means': True, 'norm_vars': False, 'eps': 1e-20}, model='espnet', model_conf={'ctc_weight': 0.3, 'lsm_weight': 0.1, 'length_normalized_loss': False}, preencoder=None, preencoder_conf={}, encoder='conformer', encoder_conf={'input_layer': 'conv2d', 'num_blocks': 12, 'linear_units': 2048, 'dropout_rate': 0.1, 'output_size': 256, 'attention_heads': 4, 'attention_dropout_rate': 0.0, 'pos_enc_layer_type': 'rel_pos', 'selfattention_layer_type': 'rel_selfattn', 'activation_type': 'swish', 'macaron_style': True, 'use_cnn_module': True, 'cnn_module_kernel': 15}, postencoder=None, postencoder_conf={}, decoder='transformer', decoder_conf={'input_layer': 'embed', 'num_blocks': 6, 'linear_units': 2048, 'dropout_rate': 0.1}, preprocessor='default', preprocessor_conf={'speech_name': 'speech', 'text_name': 'text'}, ngpu=1, print_config=False, required=['output_dir', 'token_list'], version='202412', distributed=False)\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,498 (asr:495) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:12,499 (asr:495) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:23,131 (collect_stats:107) INFO: Niter: 100\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:33,428 (collect_stats:107) INFO: Niter: 200\n",
      "[jupyter-wpc0385] 2025-07-03 10:33:43,826 (collect_stats:107) INFO: Niter: 300\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:03,501 (collect_stats:107) INFO: Niter: 100\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:13,934 (collect_stats:107) INFO: Niter: 200\n"
     ]
    }
   ],
   "source": [
    "# This script sets up the training configuration for an ASR model using ESPnet.\n",
    "\n",
    "import espnetez as ez # Importing the espnetez library for ASR tasks\n",
    "import yaml # Importing the yaml library for reading configuration files\n",
    "\n",
    "data_info = { # Data information dictionary\n",
    "    # This dictionary specifies the structure of the data used for training.\n",
    "    # It includes the names of the fields for speech and text data.\n",
    "    # The \"speech\" field contains the audio data, and the \"text\" field contains\n",
    "    # the corresponding transcriptions.\n",
    "    # The \"wav.scp\" file contains the audio file paths, and the \"text\" file contains the transcriptions.\n",
    "    # This structure is used to load and preprocess the data for training the ASR model.\n",
    "    \"speech\": [\"wav.scp\", \"sound\"],\n",
    "    \"text\": [\"text\", \"text\"],\n",
    "}\n",
    "\n",
    "EXP_DIR = \"exp/train_asr_branchformer_e24_amp\" # Directory where the training outputs will be saved\n",
    "# This directory will contain the trained model, logs, and other related files.\n",
    "STATS_DIR = \"exp/stats\" # Directory where the statistics of the training data will be saved\n",
    "\n",
    "# load config\n",
    "# For the configuration, please refer to the last cell in this notebook.\n",
    "training_config = ez.config.from_yaml(\n",
    "    \"asr\",\n",
    "    \"train.yml\",\n",
    ")\n",
    "\n",
    "with open(\"preprocess.yaml\") as stream:\n",
    "    preprocessor_config = yaml.safe_load(stream)\n",
    "    training_config.update(preprocessor_config)\n",
    "\n",
    "with open(preprocessor_config[\"token_list\"], \"r\") as f:\n",
    "    training_config[\"token_list\"] = [t.replace(\"\\n\", \"\") for t in f.readlines()]\n",
    "\n",
    "# When you don't use yaml file, you can load finetune_config in the following way.\n",
    "# task_class = ez.task.get_ez_task(\"asr\")\n",
    "# default_config = task_class.get_default_config()\n",
    "# training_config = default_config.update(your_config_in_dict)\n",
    "\n",
    "# Define the Trainer class\n",
    "# The Trainer class is responsible for managing the training process, including data loading, model training, and evaluation.\n",
    "# It takes various parameters such as the task type, training configuration, data information, output directory, and statistics directory.\n",
    "# The ngpu parameter specifies the number of GPUs to use for training (0 for CPU, 1 for GPU).\n",
    "# The collect_stats method is called to gather statistics from the training data, which is necessary for normalization and other preprocessing steps.\n",
    "trainer = ez.Trainer(\n",
    "    task='asr',\n",
    "    train_config=training_config,\n",
    "    train_dump_dir=\"dump/train\",\n",
    "    valid_dump_dir=\"dump/valid\",\n",
    "    data_info=data_info,\n",
    "    output_dir=EXP_DIR,\n",
    "    stats_dir=STATS_DIR,\n",
    "    ngpu=1, # number of GPU, change to 0 if run on CPU, 1 if run on GPU (colab)\n",
    ")\n",
    "trainer.collect_stats() # ESPnet requires statistics of the training data for normalization and other preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z66bGXKQ7UI"
   },
   "source": [
    "Finally, we are ready to begin the training process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uW8IrP3xQ7UI",
    "outputId": "5d27e310-f374-4cd5-be32-b5b3607af89b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/espnet/bin/python /opt/conda/envs/espnet/lib/python3.10/site-packages/ipykernel_launcher.py -f /home/jovyan/.local/share/jupyter/runtime/kernel-510df032-2600-4a04-accf-ec5898abdc32.json\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:20,649 (asr:523) INFO: Vocabulary size: 1000\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:20,651 (conformer_encoder:146) WARNING: Using legacy_rel_pos and it will be deprecated in the future.\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:20,793 (conformer_encoder:269) WARNING: Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,071 (abs_task:1383) INFO: pytorch.version=2.5.1, cuda.available=True, cudnn.version=90100, cudnn.benchmark=False, cudnn.deterministic=True\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,076 (abs_task:1384) INFO: Model structure:\n",
      "ESPnetASRModel(\n",
      "  (frontend): DefaultFrontend(\n",
      "    (stft): Stft(n_fft=512, win_length=400, hop_length=160, center=True, normalized=False, onesided=True)\n",
      "    (frontend): Frontend()\n",
      "    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)\n",
      "  )\n",
      "  (specaug): SpecAug(\n",
      "    (time_warp): TimeWarp(window=5, mode=bicubic)\n",
      "    (freq_mask): MaskAlongAxis(mask_width_range=[0, 30], num_mask=2, axis=freq)\n",
      "    (time_mask): MaskAlongAxis(mask_width_range=[0, 40], num_mask=2, axis=time)\n",
      "  )\n",
      "  (normalize): UtteranceMVN(norm_means=True, norm_vars=False)\n",
      "  (encoder): ConformerEncoder(\n",
      "    (embed): Conv2dSubsampling(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (out): Sequential(\n",
      "        (0): Linear(in_features=4864, out_features=256, bias=True)\n",
      "        (1): LegacyRelPositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoders): MultiSequential(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (6): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (7): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (8): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (9): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (10): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (11): EncoderLayer(\n",
      "        (self_attn): LegacyRelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (linear_pos): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (feed_forward_macaron): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (conv_module): ConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)\n",
      "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "          (activation): Swish()\n",
      "        )\n",
      "        (norm_ff): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embed): Sequential(\n",
      "      (0): Embedding(1000, 256)\n",
      "      (1): PositionalEncoding(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "    (output_layer): Linear(in_features=256, out_features=1000, bias=True)\n",
      "    (decoders): MultiSequential(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (linear_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion_att): LabelSmoothingLoss(\n",
      "    (criterion): KLDivLoss()\n",
      "  )\n",
      "  (ctc): CTC(\n",
      "    (ctc_lo): Linear(in_features=256, out_features=1000, bias=True)\n",
      "    (ctc_loss): CTCLoss()\n",
      "  )\n",
      ")\n",
      "\n",
      "Model summary:\n",
      "    Class Name: ESPnetASRModel\n",
      "    Total Number of model parameters: 43.71 M\n",
      "    Number of trainable parameters: 43.71 M (100.0%)\n",
      "    Size: 174.83 MB\n",
      "    Type: torch.float32\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,077 (abs_task:1387) INFO: Optimizer:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 4.0\n",
      "    lr: 6.324555320336758e-08\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,077 (abs_task:1388) INFO: Scheduler: NoamLR(model_size=256, warmup_steps=25000)\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,081 (abs_task:1397) INFO: Saving the configuration in exp/train_asr_branchformer_e24_amp/config.yaml\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,106 (asr:495) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,130 (abs_task:1807) INFO: [train] dataset:\n",
      "ESPnetDataset(\n",
      "  speech: {\"path\": \"dump/train/wav.scp\", \"type\": \"sound\"}\n",
      "  text: {\"path\": \"dump/train/text\", \"type\": \"text\"}\n",
      "  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f6ab03bba60>)\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,130 (abs_task:1808) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=65, batch_bins=10000000, sort_in_batch=descending, sort_batch=descending)\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,131 (abs_task:1809) INFO: [train] mini-batch sizes summary: N-batch=65, mean=118.9, min=3, max=222\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,136 (asr:495) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,153 (abs_task:1807) INFO: [valid] dataset:\n",
      "ESPnetDataset(\n",
      "  speech: {\"path\": \"dump/valid/wav.scp\", \"type\": \"sound\"}\n",
      "  text: {\"path\": \"dump/valid/text\", \"type\": \"text\"}\n",
      "  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f6a8ec29630>)\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,153 (abs_task:1808) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=47, batch_bins=10000000, sort_in_batch=descending, sort_batch=descending)\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,153 (abs_task:1809) INFO: [valid] mini-batch sizes summary: N-batch=47, mean=111.6, min=18, max=193\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,154 (abs_task:1496) INFO: --use_matplotlib false => Changing --num_att_plot to 0\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:21,154 (trainer:311) INFO: 1/50epoch started\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:25,536 (trainer:780) INFO: 1epoch:train:1-10batch: iter_time=0.028, forward_time=0.188, loss_ctc=743.536, loss_att=124.598, acc=0.001, loss=310.280, backward_time=0.076, grad_norm=539.446, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=4.111e-07, train_time=0.438\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:29,540 (trainer:780) INFO: 1epoch:train:11-20batch: iter_time=1.233e-04, forward_time=0.181, loss_ctc=712.636, loss_att=121.968, acc=8.510e-04, loss=299.168, backward_time=0.076, grad_norm=774.284, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.044e-06, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:33,543 (trainer:780) INFO: 1epoch:train:21-30batch: iter_time=1.115e-04, forward_time=0.182, loss_ctc=629.334, loss_att=119.065, acc=8.453e-04, loss=272.146, backward_time=0.075, grad_norm=877.705, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.676e-06, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:37,545 (trainer:780) INFO: 1epoch:train:31-40batch: iter_time=1.178e-04, forward_time=0.180, loss_ctc=604.290, loss_att=132.641, acc=8.265e-04, loss=274.136, backward_time=0.076, grad_norm=884.008, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.308e-06, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:41,541 (trainer:780) INFO: 1epoch:train:41-50batch: iter_time=8.403e-05, forward_time=0.180, loss_ctc=440.668, loss_att=122.466, acc=8.313e-04, loss=217.927, backward_time=0.076, grad_norm=665.289, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.941e-06, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:45,339 (trainer:780) INFO: 1epoch:train:51-60batch: iter_time=1.220e-04, forward_time=0.174, loss_ctc=423.029, loss_att=145.043, acc=8.584e-04, loss=228.439, backward_time=0.072, grad_norm=711.292, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.573e-06, train_time=0.380\n",
      "[jupyter-wpc0385] 2025-07-03 10:34:58,702 (trainer:365) INFO: 1epoch results: [train] iter_time=0.004, forward_time=0.180, loss_ctc=582.981, loss_att=127.956, acc=8.844e-04, loss=264.463, backward_time=0.075, grad_norm=723.336, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.150e-06, train_time=0.403, time=26.21 seconds, total_count=65, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=185.670, cer_ctc=1.000, loss_att=126.524, acc=0.001, cer=1.045, wer=1.000, loss=144.268, time=11.33 seconds, total_count=47, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:00,650 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:00,651 (trainer:299) INFO: 2/50epoch started. Estimated time to finish: 32 minutes and 15.36 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:04,635 (trainer:780) INFO: 2epoch:train:1-10batch: iter_time=0.019, forward_time=0.173, loss_ctc=227.141, loss_att=127.950, acc=9.256e-04, loss=157.707, backward_time=0.073, grad_norm=366.425, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=4.522e-06, train_time=0.398\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:08,647 (trainer:780) INFO: 2epoch:train:11-20batch: iter_time=9.018e-05, forward_time=0.180, loss_ctc=174.216, loss_att=118.245, acc=9.519e-04, loss=135.036, backward_time=0.076, grad_norm=234.929, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.155e-06, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:12,660 (trainer:780) INFO: 2epoch:train:21-30batch: iter_time=1.003e-04, forward_time=0.180, loss_ctc=156.194, loss_att=120.306, acc=9.305e-04, loss=131.072, backward_time=0.077, grad_norm=159.728, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.787e-06, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:16,641 (trainer:780) INFO: 2epoch:train:31-40batch: iter_time=8.484e-05, forward_time=0.177, loss_ctc=162.111, loss_att=133.571, acc=0.001, loss=142.133, backward_time=0.077, grad_norm=117.855, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=6.419e-06, train_time=0.398\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:20,642 (trainer:780) INFO: 2epoch:train:41-50batch: iter_time=1.014e-04, forward_time=0.177, loss_ctc=155.707, loss_att=132.972, acc=0.001, loss=139.792, backward_time=0.077, grad_norm=86.109, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.052e-06, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:24,644 (trainer:780) INFO: 2epoch:train:51-60batch: iter_time=7.728e-05, forward_time=0.179, loss_ctc=138.535, loss_att=121.460, acc=0.001, loss=126.583, backward_time=0.076, grad_norm=57.493, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.684e-06, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:38,082 (trainer:365) INFO: 2epoch results: [train] iter_time=0.003, forward_time=0.177, loss_ctc=167.259, loss_att=126.367, acc=0.001, loss=138.635, backward_time=0.076, grad_norm=161.485, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.261e-06, train_time=0.400, time=26.01 seconds, total_count=130, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=137.292, cer_ctc=1.000, loss_att=123.292, acc=0.002, cer=0.994, wer=1.000, loss=127.492, time=11.41 seconds, total_count=94, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:41,891 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:41,892 (trainer:299) INFO: 3/50epoch started. Estimated time to finish: 32 minutes and 17.7 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:46,148 (trainer:780) INFO: 3epoch:train:1-10batch: iter_time=0.023, forward_time=0.177, loss_ctc=141.202, loss_att=125.920, acc=0.002, loss=130.505, backward_time=0.077, grad_norm=46.419, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=8.633e-06, train_time=0.425\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:50,144 (trainer:780) INFO: 3epoch:train:11-20batch: iter_time=9.719e-05, forward_time=0.180, loss_ctc=124.861, loss_att=113.074, acc=0.008, loss=116.610, backward_time=0.075, grad_norm=30.659, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.265e-06, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:54,148 (trainer:780) INFO: 3epoch:train:21-30batch: iter_time=1.065e-04, forward_time=0.180, loss_ctc=131.616, loss_att=119.799, acc=0.038, loss=123.344, backward_time=0.076, grad_norm=30.317, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=9.898e-06, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:35:58,139 (trainer:780) INFO: 3epoch:train:31-40batch: iter_time=1.112e-04, forward_time=0.175, loss_ctc=136.731, loss_att=124.050, acc=0.061, loss=127.854, backward_time=0.077, grad_norm=29.512, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.053e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:02,142 (trainer:780) INFO: 3epoch:train:41-50batch: iter_time=1.106e-04, forward_time=0.176, loss_ctc=147.179, loss_att=133.742, acc=0.062, loss=137.773, backward_time=0.078, grad_norm=25.981, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.116e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:05,858 (trainer:780) INFO: 3epoch:train:51-60batch: iter_time=8.662e-05, forward_time=0.168, loss_ctc=126.516, loss_att=115.534, acc=0.075, loss=118.829, backward_time=0.071, grad_norm=25.179, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.180e-05, train_time=0.371\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:19,382 (trainer:365) INFO: 3epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=133.986, loss_att=121.412, acc=0.042, loss=125.184, backward_time=0.076, grad_norm=30.844, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.037e-05, train_time=0.399, time=25.98 seconds, total_count=195, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=128.564, cer_ctc=0.984, loss_att=116.184, acc=0.075, cer=1.293, wer=1.000, loss=119.898, time=11.51 seconds, total_count=141, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:23,175 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:23,176 (trainer:299) INFO: 4/50epoch started. Estimated time to finish: 31 minutes and 51.68 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:27,443 (trainer:780) INFO: 4epoch:train:1-10batch: iter_time=0.028, forward_time=0.173, loss_ctc=126.833, loss_att=115.014, acc=0.081, loss=118.560, backward_time=0.077, grad_norm=20.009, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.274e-05, train_time=0.426\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:31,439 (trainer:780) INFO: 4epoch:train:11-20batch: iter_time=8.597e-05, forward_time=0.177, loss_ctc=144.563, loss_att=130.502, acc=0.074, loss=134.720, backward_time=0.077, grad_norm=20.408, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.338e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:35,442 (trainer:780) INFO: 4epoch:train:21-30batch: iter_time=9.014e-05, forward_time=0.177, loss_ctc=130.512, loss_att=116.937, acc=0.083, loss=121.010, backward_time=0.077, grad_norm=17.538, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.401e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:39,459 (trainer:780) INFO: 4epoch:train:31-40batch: iter_time=8.235e-05, forward_time=0.179, loss_ctc=113.666, loss_att=101.614, acc=0.097, loss=105.229, backward_time=0.077, grad_norm=18.054, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.464e-05, train_time=0.402\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:43,142 (trainer:780) INFO: 4epoch:train:41-50batch: iter_time=9.002e-05, forward_time=0.165, loss_ctc=123.046, loss_att=109.482, acc=0.092, loss=113.551, backward_time=0.071, grad_norm=20.770, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.527e-05, train_time=0.368\n",
      "[jupyter-wpc0385] 2025-07-03 10:36:47,107 (trainer:780) INFO: 4epoch:train:51-60batch: iter_time=7.466e-05, forward_time=0.176, loss_ctc=121.188, loss_att=107.323, acc=0.095, loss=111.482, backward_time=0.076, grad_norm=14.654, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.591e-05, train_time=0.396\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:00,803 (trainer:365) INFO: 4epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=126.443, loss_att=113.120, acc=0.088, loss=117.117, backward_time=0.076, grad_norm=18.524, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.448e-05, train_time=0.399, time=26 seconds, total_count=260, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=123.486, cer_ctc=0.984, loss_att=107.952, acc=0.095, cer=0.963, wer=1.000, loss=112.612, time=11.63 seconds, total_count=188, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:02,906 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:03,208 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/1epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:03,209 (trainer:299) INFO: 5/50epoch started. Estimated time to finish: 31 minutes and 3.63 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:07,541 (trainer:780) INFO: 5epoch:train:1-10batch: iter_time=0.026, forward_time=0.183, loss_ctc=120.652, loss_att=106.076, acc=0.101, loss=110.449, backward_time=0.076, grad_norm=14.085, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.685e-05, train_time=0.433\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:11,549 (trainer:780) INFO: 5epoch:train:11-20batch: iter_time=9.176e-05, forward_time=0.178, loss_ctc=120.372, loss_att=105.383, acc=0.101, loss=109.879, backward_time=0.077, grad_norm=13.475, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.749e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:15,546 (trainer:780) INFO: 5epoch:train:21-30batch: iter_time=1.407e-04, forward_time=0.175, loss_ctc=146.730, loss_att=127.608, acc=0.088, loss=133.345, backward_time=0.078, grad_norm=14.591, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.812e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:19,241 (trainer:780) INFO: 5epoch:train:31-40batch: iter_time=8.821e-05, forward_time=0.167, loss_ctc=117.404, loss_att=101.788, acc=0.117, loss=106.473, backward_time=0.071, grad_norm=16.629, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.875e-05, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:23,242 (trainer:780) INFO: 5epoch:train:41-50batch: iter_time=9.956e-05, forward_time=0.178, loss_ctc=112.625, loss_att=97.531, acc=0.122, loss=102.059, backward_time=0.077, grad_norm=11.261, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.938e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:27,245 (trainer:780) INFO: 5epoch:train:51-60batch: iter_time=7.705e-05, forward_time=0.177, loss_ctc=122.672, loss_att=105.766, acc=0.113, loss=110.838, backward_time=0.077, grad_norm=12.701, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.002e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:40,376 (trainer:365) INFO: 5epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=121.794, loss_att=105.906, acc=0.109, loss=110.672, backward_time=0.076, grad_norm=13.526, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.859e-05, train_time=0.400, time=26.06 seconds, total_count=325, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=119.425, cer_ctc=0.923, loss_att=102.604, acc=0.107, cer=0.895, wer=1.000, loss=107.650, time=11.11 seconds, total_count=235, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:42,400 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:42,756 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/2epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:42,757 (trainer:299) INFO: 6/50epoch started. Estimated time to finish: 30 minutes and 14.42 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:46,749 (trainer:780) INFO: 6epoch:train:1-10batch: iter_time=0.026, forward_time=0.168, loss_ctc=106.680, loss_att=91.908, acc=0.128, loss=96.340, backward_time=0.071, grad_norm=13.852, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=2.097e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:50,743 (trainer:780) INFO: 6epoch:train:11-20batch: iter_time=8.463e-05, forward_time=0.176, loss_ctc=111.657, loss_att=95.746, acc=0.124, loss=100.519, backward_time=0.077, grad_norm=10.873, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.160e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:54,743 (trainer:780) INFO: 6epoch:train:21-30batch: iter_time=9.174e-05, forward_time=0.179, loss_ctc=118.855, loss_att=101.915, acc=0.114, loss=106.997, backward_time=0.076, grad_norm=8.193, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.223e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:37:58,738 (trainer:780) INFO: 6epoch:train:31-40batch: iter_time=8.612e-05, forward_time=0.178, loss_ctc=117.789, loss_att=100.944, acc=0.117, loss=105.997, backward_time=0.076, grad_norm=8.535, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.286e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:02,747 (trainer:780) INFO: 6epoch:train:41-50batch: iter_time=7.491e-05, forward_time=0.177, loss_ctc=124.159, loss_att=106.024, acc=0.117, loss=111.464, backward_time=0.077, grad_norm=9.716, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.350e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:06,737 (trainer:780) INFO: 6epoch:train:51-60batch: iter_time=8.011e-05, forward_time=0.176, loss_ctc=128.036, loss_att=109.367, acc=0.112, loss=114.968, backward_time=0.077, grad_norm=11.058, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.413e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:19,893 (trainer:365) INFO: 6epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=118.630, loss_att=101.625, acc=0.118, loss=106.727, backward_time=0.076, grad_norm=10.346, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.271e-05, train_time=0.399, time=26 seconds, total_count=390, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=117.033, cer_ctc=0.923, loss_att=99.865, acc=0.114, cer=0.858, wer=1.000, loss=105.016, time=11.14 seconds, total_count=282, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:21,958 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:22,286 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/3epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:22,287 (trainer:299) INFO: 7/50epoch started. Estimated time to finish: 29 minutes and 28.31 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:26,556 (trainer:780) INFO: 7epoch:train:1-10batch: iter_time=0.026, forward_time=0.175, loss_ctc=111.052, loss_att=94.485, acc=0.128, loss=99.455, backward_time=0.077, grad_norm=8.439, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=2.508e-05, train_time=0.426\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:30,543 (trainer:780) INFO: 7epoch:train:11-20batch: iter_time=1.037e-04, forward_time=0.175, loss_ctc=130.703, loss_att=111.295, acc=0.113, loss=117.118, backward_time=0.077, grad_norm=8.909, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.571e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:34,544 (trainer:780) INFO: 7epoch:train:21-30batch: iter_time=8.797e-05, forward_time=0.177, loss_ctc=126.686, loss_att=107.775, acc=0.118, loss=113.449, backward_time=0.077, grad_norm=8.751, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.634e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:38,543 (trainer:780) INFO: 7epoch:train:31-40batch: iter_time=1.041e-04, forward_time=0.179, loss_ctc=109.889, loss_att=93.604, acc=0.131, loss=98.490, backward_time=0.076, grad_norm=7.594, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.697e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:42,245 (trainer:780) INFO: 7epoch:train:41-50batch: iter_time=8.805e-05, forward_time=0.167, loss_ctc=108.287, loss_att=92.178, acc=0.140, loss=97.011, backward_time=0.071, grad_norm=11.994, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.761e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:46,242 (trainer:780) INFO: 7epoch:train:51-60batch: iter_time=1.035e-04, forward_time=0.178, loss_ctc=114.389, loss_att=97.252, acc=0.130, loss=102.393, backward_time=0.077, grad_norm=8.360, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.824e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:38:59,482 (trainer:365) INFO: 7epoch results: [train] iter_time=0.004, forward_time=0.174, loss_ctc=116.997, loss_att=99.562, acc=0.126, loss=104.792, backward_time=0.076, grad_norm=9.032, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.682e-05, train_time=0.398, time=25.95 seconds, total_count=455, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=116.011, cer_ctc=0.923, loss_att=98.530, acc=0.122, cer=0.838, wer=1.000, loss=103.775, time=11.25 seconds, total_count=329, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:01,896 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:01,911 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/4epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:01,912 (trainer:299) INFO: 8/50epoch started. Estimated time to finish: 28 minutes and 44.65 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:06,142 (trainer:780) INFO: 8epoch:train:1-10batch: iter_time=0.024, forward_time=0.172, loss_ctc=128.434, loss_att=109.109, acc=0.121, loss=114.906, backward_time=0.077, grad_norm=10.145, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=2.919e-05, train_time=0.423\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:10,145 (trainer:780) INFO: 8epoch:train:11-20batch: iter_time=8.726e-05, forward_time=0.179, loss_ctc=107.786, loss_att=91.232, acc=0.137, loss=96.198, backward_time=0.076, grad_norm=6.899, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.982e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:13,848 (trainer:780) INFO: 8epoch:train:21-30batch: iter_time=7.501e-05, forward_time=0.168, loss_ctc=96.040, loss_att=81.495, acc=0.150, loss=85.858, backward_time=0.071, grad_norm=10.630, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.045e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:17,847 (trainer:780) INFO: 8epoch:train:31-40batch: iter_time=7.389e-05, forward_time=0.178, loss_ctc=113.772, loss_att=96.138, acc=0.140, loss=101.428, backward_time=0.077, grad_norm=7.664, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=3.109e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:21,849 (trainer:780) INFO: 8epoch:train:41-50batch: iter_time=9.482e-05, forward_time=0.176, loss_ctc=125.815, loss_att=106.328, acc=0.126, loss=112.174, backward_time=0.077, grad_norm=7.784, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.172e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:25,845 (trainer:780) INFO: 8epoch:train:51-60batch: iter_time=1.023e-04, forward_time=0.178, loss_ctc=120.040, loss_att=101.244, acc=0.130, loss=106.883, backward_time=0.076, grad_norm=7.307, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.235e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:38,975 (trainer:365) INFO: 8epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=116.135, loss_att=98.275, acc=0.133, loss=103.633, backward_time=0.076, grad_norm=8.415, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.093e-05, train_time=0.399, time=25.96 seconds, total_count=520, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=115.520, cer_ctc=0.923, loss_att=97.298, acc=0.128, cer=0.809, wer=1.000, loss=102.764, time=11.1 seconds, total_count=376, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:41,272 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:41,286 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/5epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:41,287 (trainer:299) INFO: 9/50epoch started. Estimated time to finish: 28 minutes and 0.7 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:45,544 (trainer:780) INFO: 9epoch:train:1-10batch: iter_time=0.027, forward_time=0.172, loss_ctc=133.459, loss_att=112.554, acc=0.121, loss=118.826, backward_time=0.077, grad_norm=8.278, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=3.330e-05, train_time=0.425\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:49,537 (trainer:780) INFO: 9epoch:train:11-20batch: iter_time=1.177e-04, forward_time=0.177, loss_ctc=111.559, loss_att=93.688, acc=0.141, loss=99.049, backward_time=0.077, grad_norm=7.554, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.393e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:53,544 (trainer:780) INFO: 9epoch:train:21-30batch: iter_time=1.262e-04, forward_time=0.177, loss_ctc=126.366, loss_att=106.188, acc=0.130, loss=112.241, backward_time=0.077, grad_norm=7.844, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=3.456e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:39:57,546 (trainer:780) INFO: 9epoch:train:31-40batch: iter_time=1.032e-04, forward_time=0.179, loss_ctc=116.767, loss_att=97.878, acc=0.141, loss=103.545, backward_time=0.076, grad_norm=7.740, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=3.520e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:01,540 (trainer:780) INFO: 9epoch:train:41-50batch: iter_time=1.031e-04, forward_time=0.178, loss_ctc=106.774, loss_att=89.475, acc=0.149, loss=94.665, backward_time=0.077, grad_norm=7.105, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.583e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:05,243 (trainer:780) INFO: 9epoch:train:51-60batch: iter_time=1.128e-04, forward_time=0.168, loss_ctc=108.096, loss_att=90.224, acc=0.153, loss=95.586, backward_time=0.071, grad_norm=10.754, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=3.646e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:19,306 (trainer:365) INFO: 9epoch results: [train] iter_time=0.004, forward_time=0.178, loss_ctc=115.596, loss_att=96.938, acc=0.141, loss=102.535, backward_time=0.076, grad_norm=8.364, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.504e-05, train_time=0.402, time=26.19 seconds, total_count=585, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=115.286, cer_ctc=0.921, loss_att=96.025, acc=0.134, cer=0.803, wer=1.000, loss=101.803, time=11.83 seconds, total_count=423, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:21,800 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:21,815 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/6epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:21,816 (trainer:299) INFO: 10/50epoch started. Estimated time to finish: 27 minutes and 23.01 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:26,046 (trainer:780) INFO: 10epoch:train:1-10batch: iter_time=0.025, forward_time=0.172, loss_ctc=127.453, loss_att=106.272, acc=0.136, loss=112.626, backward_time=0.077, grad_norm=9.070, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=3.741e-05, train_time=0.423\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:30,043 (trainer:780) INFO: 10epoch:train:11-20batch: iter_time=7.538e-05, forward_time=0.178, loss_ctc=114.683, loss_att=95.424, acc=0.147, loss=101.202, backward_time=0.076, grad_norm=7.298, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.804e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:34,047 (trainer:780) INFO: 10epoch:train:21-30batch: iter_time=1.033e-04, forward_time=0.176, loss_ctc=130.173, loss_att=108.135, acc=0.132, loss=114.746, backward_time=0.078, grad_norm=9.673, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.867e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:38,048 (trainer:780) INFO: 10epoch:train:31-40batch: iter_time=1.131e-04, forward_time=0.177, loss_ctc=116.143, loss_att=96.540, acc=0.141, loss=102.421, backward_time=0.077, grad_norm=7.673, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.931e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:42,045 (trainer:780) INFO: 10epoch:train:41-50batch: iter_time=7.926e-05, forward_time=0.179, loss_ctc=111.444, loss_att=92.285, acc=0.148, loss=98.033, backward_time=0.077, grad_norm=7.364, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.994e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:46,033 (trainer:780) INFO: 10epoch:train:51-60batch: iter_time=1.112e-04, forward_time=0.178, loss_ctc=98.723, loss_att=81.533, acc=0.163, loss=86.690, backward_time=0.077, grad_norm=7.175, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=4.057e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:40:58,928 (trainer:365) INFO: 10epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=115.172, loss_att=95.589, acc=0.146, loss=101.464, backward_time=0.076, grad_norm=8.667, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=3.915e-05, train_time=0.399, time=25.96 seconds, total_count=650, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=114.794, cer_ctc=0.922, loss_att=94.699, acc=0.139, cer=0.765, wer=1.000, loss=100.727, time=11.15 seconds, total_count=470, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:01,053 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:01,067 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/7epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:01,068 (trainer:299) INFO: 11/50epoch started. Estimated time to finish: 26 minutes and 39.65 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:05,356 (trainer:780) INFO: 11epoch:train:1-10batch: iter_time=0.024, forward_time=0.181, loss_ctc=110.078, loss_att=90.570, acc=0.154, loss=96.423, backward_time=0.076, grad_norm=9.057, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=4.152e-05, train_time=0.428\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:09,351 (trainer:780) INFO: 11epoch:train:11-20batch: iter_time=8.176e-05, forward_time=0.177, loss_ctc=116.752, loss_att=96.300, acc=0.148, loss=102.435, backward_time=0.077, grad_norm=7.889, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=4.215e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:13,342 (trainer:780) INFO: 11epoch:train:21-30batch: iter_time=1.171e-04, forward_time=0.178, loss_ctc=107.492, loss_att=88.245, acc=0.154, loss=94.019, backward_time=0.076, grad_norm=6.916, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=4.279e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:17,046 (trainer:780) INFO: 11epoch:train:31-40batch: iter_time=8.265e-05, forward_time=0.166, loss_ctc=111.816, loss_att=91.735, acc=0.156, loss=97.760, backward_time=0.072, grad_norm=12.681, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=4.342e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:21,049 (trainer:780) INFO: 11epoch:train:41-50batch: iter_time=1.200e-04, forward_time=0.177, loss_ctc=120.606, loss_att=98.708, acc=0.143, loss=105.277, backward_time=0.077, grad_norm=9.147, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=4.405e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:25,043 (trainer:780) INFO: 11epoch:train:51-60batch: iter_time=8.932e-05, forward_time=0.177, loss_ctc=124.457, loss_att=101.845, acc=0.138, loss=108.629, backward_time=0.077, grad_norm=7.915, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=4.468e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:38,427 (trainer:365) INFO: 11epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=114.834, loss_att=94.228, acc=0.150, loss=100.409, backward_time=0.076, grad_norm=8.806, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=4.326e-05, train_time=0.399, time=26 seconds, total_count=715, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=114.444, cer_ctc=0.907, loss_att=93.240, acc=0.144, cer=0.759, wer=1.000, loss=99.601, time=11.36 seconds, total_count=517, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:40,770 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:40,785 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/8epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:40,786 (trainer:299) INFO: 12/50epoch started. Estimated time to finish: 25 minutes and 58.69 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:45,040 (trainer:780) INFO: 12epoch:train:1-10batch: iter_time=0.024, forward_time=0.177, loss_ctc=121.527, loss_att=99.106, acc=0.144, loss=105.832, backward_time=0.076, grad_norm=7.394, clip=100.000, loss_scale=1.000optim_step_time=0.005, optim0_lr0=4.563e-05, train_time=0.425\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:49,046 (trainer:780) INFO: 12epoch:train:11-20batch: iter_time=1.014e-04, forward_time=0.180, loss_ctc=107.536, loss_att=87.339, acc=0.159, loss=93.398, backward_time=0.076, grad_norm=7.002, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=4.626e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:53,051 (trainer:780) INFO: 12epoch:train:21-30batch: iter_time=9.273e-05, forward_time=0.176, loss_ctc=120.093, loss_att=97.336, acc=0.149, loss=104.163, backward_time=0.078, grad_norm=10.124, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=4.690e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:41:57,048 (trainer:780) INFO: 12epoch:train:31-40batch: iter_time=7.807e-05, forward_time=0.179, loss_ctc=109.746, loss_att=88.673, acc=0.158, loss=94.995, backward_time=0.077, grad_norm=7.367, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=4.753e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:00,747 (trainer:780) INFO: 12epoch:train:41-50batch: iter_time=9.048e-05, forward_time=0.167, loss_ctc=115.824, loss_att=93.387, acc=0.151, loss=100.118, backward_time=0.071, grad_norm=12.488, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=4.816e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:04,758 (trainer:780) INFO: 12epoch:train:51-60batch: iter_time=7.845e-05, forward_time=0.178, loss_ctc=114.004, loss_att=92.058, acc=0.154, loss=98.642, backward_time=0.077, grad_norm=9.052, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=4.879e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:18,177 (trainer:365) INFO: 12epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=114.546, loss_att=92.744, acc=0.153, loss=99.284, backward_time=0.076, grad_norm=8.879, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=4.737e-05, train_time=0.399, time=26 seconds, total_count=780, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=114.218, cer_ctc=0.908, loss_att=91.762, acc=0.147, cer=0.761, wer=1.000, loss=98.499, time=11.39 seconds, total_count=564, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:20,645 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:20,661 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/9epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:20,661 (trainer:299) INFO: 13/50epoch started. Estimated time to finish: 25 minutes and 18.44 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:24,942 (trainer:780) INFO: 13epoch:train:1-10batch: iter_time=0.025, forward_time=0.178, loss_ctc=102.546, loss_att=82.604, acc=0.166, loss=88.586, backward_time=0.077, grad_norm=7.971, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=4.974e-05, train_time=0.428\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:28,644 (trainer:780) INFO: 13epoch:train:11-20batch: iter_time=8.964e-05, forward_time=0.167, loss_ctc=103.849, loss_att=83.303, acc=0.165, loss=89.466, backward_time=0.071, grad_norm=10.983, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.038e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:32,644 (trainer:780) INFO: 13epoch:train:21-30batch: iter_time=1.027e-04, forward_time=0.176, loss_ctc=124.362, loss_att=99.401, acc=0.147, loss=106.889, backward_time=0.077, grad_norm=8.344, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.101e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:36,644 (trainer:780) INFO: 13epoch:train:31-40batch: iter_time=1.003e-04, forward_time=0.176, loss_ctc=126.945, loss_att=101.129, acc=0.146, loss=108.874, backward_time=0.077, grad_norm=8.344, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.164e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:40,640 (trainer:780) INFO: 13epoch:train:41-50batch: iter_time=8.669e-05, forward_time=0.179, loss_ctc=110.291, loss_att=87.726, acc=0.162, loss=94.496, backward_time=0.076, grad_norm=9.390, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=5.227e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:44,648 (trainer:780) INFO: 13epoch:train:51-60batch: iter_time=9.032e-05, forward_time=0.177, loss_ctc=116.126, loss_att=92.136, acc=0.157, loss=99.333, backward_time=0.077, grad_norm=8.202, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.290e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:42:57,798 (trainer:365) INFO: 13epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=114.268, loss_att=91.184, acc=0.157, loss=98.110, backward_time=0.076, grad_norm=8.890, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.148e-05, train_time=0.399, time=26.01 seconds, total_count=845, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=113.989, cer_ctc=0.915, loss_att=90.298, acc=0.151, cer=0.749, wer=1.000, loss=97.405, time=11.13 seconds, total_count=611, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:00,264 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:00,278 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/10epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:00,279 (trainer:299) INFO: 14/50epoch started. Estimated time to finish: 24 minutes and 37.51 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:04,547 (trainer:780) INFO: 14epoch:train:1-10batch: iter_time=0.027, forward_time=0.175, loss_ctc=99.923, loss_att=79.263, acc=0.175, loss=85.461, backward_time=0.077, grad_norm=8.489, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=5.385e-05, train_time=0.426\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:08,546 (trainer:780) INFO: 14epoch:train:11-20batch: iter_time=7.521e-05, forward_time=0.179, loss_ctc=112.460, loss_att=88.513, acc=0.159, loss=95.697, backward_time=0.077, grad_norm=7.017, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.449e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:12,547 (trainer:780) INFO: 14epoch:train:21-30batch: iter_time=1.221e-04, forward_time=0.177, loss_ctc=114.585, loss_att=90.400, acc=0.165, loss=97.655, backward_time=0.077, grad_norm=9.418, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.512e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:16,541 (trainer:780) INFO: 14epoch:train:31-40batch: iter_time=9.687e-05, forward_time=0.176, loss_ctc=120.221, loss_att=94.522, acc=0.152, loss=102.232, backward_time=0.077, grad_norm=8.835, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.575e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:20,248 (trainer:780) INFO: 14epoch:train:41-50batch: iter_time=7.604e-05, forward_time=0.168, loss_ctc=111.143, loss_att=87.147, acc=0.172, loss=94.345, backward_time=0.071, grad_norm=12.941, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=5.638e-05, train_time=0.371\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:24,242 (trainer:780) INFO: 14epoch:train:51-60batch: iter_time=1.003e-04, forward_time=0.178, loss_ctc=124.692, loss_att=97.334, acc=0.153, loss=105.541, backward_time=0.076, grad_norm=7.796, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.702e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:37,583 (trainer:365) INFO: 14epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=114.015, loss_att=89.679, acc=0.162, loss=96.980, backward_time=0.076, grad_norm=9.204, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.559e-05, train_time=0.399, time=26 seconds, total_count=910, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=115.008, cer_ctc=0.915, loss_att=88.780, acc=0.156, cer=0.741, wer=1.000, loss=96.648, time=11.3 seconds, total_count=658, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:40,025 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:40,039 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/11epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:40,039 (trainer:299) INFO: 15/50epoch started. Estimated time to finish: 23 minutes and 57.13 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:44,343 (trainer:780) INFO: 15epoch:train:1-10batch: iter_time=0.028, forward_time=0.179, loss_ctc=109.097, loss_att=84.974, acc=0.169, loss=92.211, backward_time=0.077, grad_norm=10.758, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=5.796e-05, train_time=0.430\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:48,357 (trainer:780) INFO: 15epoch:train:11-20batch: iter_time=8.958e-05, forward_time=0.180, loss_ctc=90.758, loss_att=70.722, acc=0.190, loss=76.733, backward_time=0.077, grad_norm=7.775, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.860e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:52,338 (trainer:780) INFO: 15epoch:train:21-30batch: iter_time=1.100e-04, forward_time=0.175, loss_ctc=124.573, loss_att=96.768, acc=0.158, loss=105.110, backward_time=0.077, grad_norm=7.763, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.923e-05, train_time=0.398\n",
      "[jupyter-wpc0385] 2025-07-03 10:43:56,349 (trainer:780) INFO: 15epoch:train:31-40batch: iter_time=9.767e-05, forward_time=0.178, loss_ctc=109.271, loss_att=84.668, acc=0.174, loss=92.049, backward_time=0.078, grad_norm=8.087, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=5.986e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:00,341 (trainer:780) INFO: 15epoch:train:41-50batch: iter_time=1.337e-04, forward_time=0.175, loss_ctc=132.305, loss_att=102.008, acc=0.150, loss=111.097, backward_time=0.077, grad_norm=11.221, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.049e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:04,344 (trainer:780) INFO: 15epoch:train:51-60batch: iter_time=1.136e-04, forward_time=0.177, loss_ctc=122.715, loss_att=94.774, acc=0.157, loss=103.157, backward_time=0.077, grad_norm=7.586, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.113e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:17,281 (trainer:365) INFO: 15epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=113.776, loss_att=88.209, acc=0.167, loss=95.879, backward_time=0.076, grad_norm=9.400, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=5.970e-05, train_time=0.400, time=26.03 seconds, total_count=975, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=113.646, cer_ctc=0.904, loss_att=87.373, acc=0.160, cer=0.724, wer=1.000, loss=95.255, time=11.21 seconds, total_count=705, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:19,619 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:19,634 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/12epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:19,635 (trainer:299) INFO: 16/50epoch started. Estimated time to finish: 23 minutes and 16.45 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:23,943 (trainer:780) INFO: 16epoch:train:1-10batch: iter_time=0.023, forward_time=0.181, loss_ctc=113.424, loss_att=87.497, acc=0.168, loss=95.275, backward_time=0.077, grad_norm=8.900, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=6.208e-05, train_time=0.430\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:27,943 (trainer:780) INFO: 16epoch:train:11-20batch: iter_time=9.414e-05, forward_time=0.178, loss_ctc=126.272, loss_att=96.551, acc=0.155, loss=105.467, backward_time=0.077, grad_norm=9.168, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.271e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:31,949 (trainer:780) INFO: 16epoch:train:21-30batch: iter_time=1.073e-04, forward_time=0.179, loss_ctc=113.320, loss_att=86.437, acc=0.173, loss=94.502, backward_time=0.077, grad_norm=7.947, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.334e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:35,947 (trainer:780) INFO: 16epoch:train:31-40batch: iter_time=7.715e-05, forward_time=0.178, loss_ctc=122.051, loss_att=93.138, acc=0.161, loss=101.812, backward_time=0.077, grad_norm=8.298, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.397e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:39,643 (trainer:780) INFO: 16epoch:train:41-50batch: iter_time=9.963e-05, forward_time=0.166, loss_ctc=107.174, loss_att=81.700, acc=0.179, loss=89.342, backward_time=0.072, grad_norm=12.690, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.461e-05, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:43,648 (trainer:780) INFO: 16epoch:train:51-60batch: iter_time=1.260e-04, forward_time=0.179, loss_ctc=99.220, loss_att=75.934, acc=0.190, loss=82.920, backward_time=0.077, grad_norm=8.828, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.524e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:56,882 (trainer:365) INFO: 16epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=113.459, loss_att=86.761, acc=0.172, loss=94.770, backward_time=0.076, grad_norm=9.671, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.381e-05, train_time=0.400, time=26.05 seconds, total_count=1040, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=113.880, cer_ctc=0.901, loss_att=86.045, acc=0.166, cer=0.724, wer=1.000, loss=94.395, time=11.2 seconds, total_count=752, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:59,247 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:59,264 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/13epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:44:59,265 (trainer:299) INFO: 17/50epoch started. Estimated time to finish: 22 minutes and 35.99 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:03,544 (trainer:780) INFO: 17epoch:train:1-10batch: iter_time=0.025, forward_time=0.180, loss_ctc=107.560, loss_att=81.593, acc=0.179, loss=89.383, backward_time=0.076, grad_norm=7.037, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=6.619e-05, train_time=0.427\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:07,245 (trainer:780) INFO: 17epoch:train:11-20batch: iter_time=1.098e-04, forward_time=0.168, loss_ctc=109.747, loss_att=83.034, acc=0.178, loss=91.048, backward_time=0.071, grad_norm=10.992, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.682e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:11,239 (trainer:780) INFO: 17epoch:train:21-30batch: iter_time=9.500e-05, forward_time=0.179, loss_ctc=108.453, loss_att=82.096, acc=0.182, loss=90.003, backward_time=0.076, grad_norm=8.086, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=6.745e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:15,342 (trainer:780) INFO: 17epoch:train:31-40batch: iter_time=1.351e-04, forward_time=0.188, loss_ctc=117.807, loss_att=88.807, acc=0.172, loss=97.507, backward_time=0.077, grad_norm=9.937, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.808e-05, train_time=0.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:19,349 (trainer:780) INFO: 17epoch:train:41-50batch: iter_time=9.225e-05, forward_time=0.178, loss_ctc=116.618, loss_att=87.770, acc=0.176, loss=96.425, backward_time=0.077, grad_norm=10.580, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.872e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:23,342 (trainer:780) INFO: 17epoch:train:51-60batch: iter_time=1.008e-04, forward_time=0.176, loss_ctc=117.483, loss_att=88.487, acc=0.177, loss=97.186, backward_time=0.077, grad_norm=12.018, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.935e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:36,692 (trainer:365) INFO: 17epoch results: [train] iter_time=0.004, forward_time=0.178, loss_ctc=113.097, loss_att=85.389, acc=0.177, loss=93.701, backward_time=0.076, grad_norm=9.595, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=6.793e-05, train_time=0.401, time=26.12 seconds, total_count=1105, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=113.098, cer_ctc=0.899, loss_att=84.770, acc=0.172, cer=0.721, wer=1.000, loss=93.269, time=11.31 seconds, total_count=799, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:38,790 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:38,804 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/14epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:38,805 (trainer:299) INFO: 18/50epoch started. Estimated time to finish: 21 minutes and 55.44 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:43,144 (trainer:780) INFO: 18epoch:train:1-10batch: iter_time=0.026, forward_time=0.184, loss_ctc=124.022, loss_att=93.009, acc=0.165, loss=102.313, backward_time=0.077, grad_norm=9.657, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=7.030e-05, train_time=0.433\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:47,140 (trainer:780) INFO: 18epoch:train:11-20batch: iter_time=7.683e-05, forward_time=0.180, loss_ctc=107.087, loss_att=79.904, acc=0.189, loss=88.059, backward_time=0.076, grad_norm=10.315, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=7.093e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:51,149 (trainer:780) INFO: 18epoch:train:21-30batch: iter_time=7.778e-05, forward_time=0.180, loss_ctc=103.137, loss_att=76.980, acc=0.190, loss=84.827, backward_time=0.076, grad_norm=8.365, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.156e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:54,841 (trainer:780) INFO: 18epoch:train:31-40batch: iter_time=9.272e-05, forward_time=0.165, loss_ctc=110.032, loss_att=82.260, acc=0.187, loss=90.591, backward_time=0.072, grad_norm=13.760, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.219e-05, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 10:45:58,862 (trainer:780) INFO: 18epoch:train:41-50batch: iter_time=9.613e-05, forward_time=0.176, loss_ctc=119.229, loss_att=89.609, acc=0.179, loss=98.495, backward_time=0.078, grad_norm=10.160, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.283e-05, train_time=0.402\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:02,838 (trainer:780) INFO: 18epoch:train:51-60batch: iter_time=1.024e-04, forward_time=0.175, loss_ctc=115.877, loss_att=86.486, acc=0.178, loss=95.303, backward_time=0.077, grad_norm=9.318, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=7.346e-05, train_time=0.398\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:16,082 (trainer:365) INFO: 18epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=112.672, loss_att=84.221, acc=0.182, loss=92.756, backward_time=0.076, grad_norm=10.162, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=7.204e-05, train_time=0.400, time=26.07 seconds, total_count=1170, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=112.374, cer_ctc=0.906, loss_att=83.737, acc=0.175, cer=0.719, wer=1.000, loss=92.328, time=11.2 seconds, total_count=846, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:18,122 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:18,139 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/15epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:18,139 (trainer:299) INFO: 19/50epoch started. Estimated time to finish: 21 minutes and 14.64 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:22,547 (trainer:780) INFO: 19epoch:train:1-10batch: iter_time=0.025, forward_time=0.190, loss_ctc=128.591, loss_att=95.724, acc=0.168, loss=105.584, backward_time=0.077, grad_norm=9.963, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=7.441e-05, train_time=0.440\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:26,245 (trainer:780) INFO: 19epoch:train:11-20batch: iter_time=1.054e-04, forward_time=0.167, loss_ctc=112.153, loss_att=82.929, acc=0.188, loss=91.696, backward_time=0.071, grad_norm=13.439, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=7.504e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:30,252 (trainer:780) INFO: 19epoch:train:21-30batch: iter_time=9.151e-05, forward_time=0.179, loss_ctc=105.329, loss_att=78.300, acc=0.194, loss=86.409, backward_time=0.077, grad_norm=10.941, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.567e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:34,242 (trainer:780) INFO: 19epoch:train:31-40batch: iter_time=8.351e-05, forward_time=0.178, loss_ctc=97.369, loss_att=72.056, acc=0.202, loss=79.650, backward_time=0.077, grad_norm=9.652, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.631e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:38,240 (trainer:780) INFO: 19epoch:train:41-50batch: iter_time=1.055e-04, forward_time=0.177, loss_ctc=126.557, loss_att=93.732, acc=0.173, loss=103.580, backward_time=0.077, grad_norm=9.296, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.694e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:42,261 (trainer:780) INFO: 19epoch:train:51-60batch: iter_time=1.002e-04, forward_time=0.180, loss_ctc=106.483, loss_att=78.802, acc=0.192, loss=87.106, backward_time=0.077, grad_norm=8.132, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=7.757e-05, train_time=0.402\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:55,531 (trainer:365) INFO: 19epoch results: [train] iter_time=0.004, forward_time=0.178, loss_ctc=112.126, loss_att=83.109, acc=0.187, loss=91.814, backward_time=0.076, grad_norm=10.016, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.615e-05, train_time=0.401, time=26.14 seconds, total_count=1235, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=111.837, cer_ctc=0.897, loss_att=82.652, acc=0.182, cer=0.717, wer=1.000, loss=91.408, time=11.25 seconds, total_count=893, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:57,591 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:57,608 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/16epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:46:57,608 (trainer:299) INFO: 20/50epoch started. Estimated time to finish: 20 minutes and 34.21 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:01,943 (trainer:780) INFO: 20epoch:train:1-10batch: iter_time=0.028, forward_time=0.179, loss_ctc=107.619, loss_att=80.024, acc=0.199, loss=88.302, backward_time=0.078, grad_norm=9.728, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=7.852e-05, train_time=0.433\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:05,948 (trainer:780) INFO: 20epoch:train:11-20batch: iter_time=1.084e-04, forward_time=0.179, loss_ctc=99.880, loss_att=73.695, acc=0.202, loss=81.550, backward_time=0.077, grad_norm=8.592, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=7.915e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:09,645 (trainer:780) INFO: 20epoch:train:21-30batch: iter_time=1.267e-04, forward_time=0.168, loss_ctc=112.598, loss_att=82.564, acc=0.190, loss=91.574, backward_time=0.071, grad_norm=12.828, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=7.978e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:13,646 (trainer:780) INFO: 20epoch:train:31-40batch: iter_time=1.040e-04, forward_time=0.177, loss_ctc=118.396, loss_att=87.261, acc=0.183, loss=96.601, backward_time=0.077, grad_norm=8.315, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.042e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:17,646 (trainer:780) INFO: 20epoch:train:41-50batch: iter_time=9.478e-05, forward_time=0.180, loss_ctc=107.341, loss_att=78.495, acc=0.195, loss=87.149, backward_time=0.076, grad_norm=7.061, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.105e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:21,645 (trainer:780) INFO: 20epoch:train:51-60batch: iter_time=7.425e-05, forward_time=0.178, loss_ctc=116.532, loss_att=85.386, acc=0.190, loss=94.730, backward_time=0.077, grad_norm=8.833, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=8.168e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:34,720 (trainer:365) INFO: 20epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=111.499, loss_att=82.026, acc=0.192, loss=90.868, backward_time=0.076, grad_norm=9.191, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.026e-05, train_time=0.400, time=26.06 seconds, total_count=1300, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=111.210, cer_ctc=0.887, loss_att=81.690, acc=0.186, cer=0.714, wer=1.000, loss=90.546, time=11.05 seconds, total_count=940, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:37,222 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:37,236 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/17epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:37,237 (trainer:299) INFO: 21/50epoch started. Estimated time to finish: 19 minutes and 54.12 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:41,545 (trainer:780) INFO: 21epoch:train:1-10batch: iter_time=0.025, forward_time=0.179, loss_ctc=120.489, loss_att=88.523, acc=0.187, loss=98.113, backward_time=0.078, grad_norm=12.575, clip=100.000, loss_scale=1.000optim_step_time=0.005, optim0_lr0=8.263e-05, train_time=0.430\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:45,545 (trainer:780) INFO: 21epoch:train:11-20batch: iter_time=1.023e-04, forward_time=0.177, loss_ctc=120.652, loss_att=88.016, acc=0.193, loss=97.807, backward_time=0.077, grad_norm=13.239, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.326e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:49,248 (trainer:780) INFO: 21epoch:train:21-30batch: iter_time=9.190e-05, forward_time=0.167, loss_ctc=119.739, loss_att=87.099, acc=0.190, loss=96.891, backward_time=0.071, grad_norm=15.854, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=8.390e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:53,202 (trainer:780) INFO: 21epoch:train:31-40batch: iter_time=1.032e-04, forward_time=0.176, loss_ctc=104.775, loss_att=76.459, acc=0.198, loss=84.954, backward_time=0.076, grad_norm=8.701, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=8.453e-05, train_time=0.395\n",
      "[jupyter-wpc0385] 2025-07-03 10:47:57,250 (trainer:780) INFO: 21epoch:train:41-50batch: iter_time=7.815e-05, forward_time=0.183, loss_ctc=116.559, loss_att=84.961, acc=0.191, loss=94.441, backward_time=0.076, grad_norm=8.788, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=8.516e-05, train_time=0.405\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:01,243 (trainer:780) INFO: 21epoch:train:51-60batch: iter_time=7.884e-05, forward_time=0.178, loss_ctc=105.823, loss_att=76.947, acc=0.206, loss=85.610, backward_time=0.076, grad_norm=8.725, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=8.579e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:14,495 (trainer:365) INFO: 21epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=110.950, loss_att=80.990, acc=0.197, loss=89.978, backward_time=0.076, grad_norm=11.784, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=8.437e-05, train_time=0.400, time=26.03 seconds, total_count=1365, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=111.189, cer_ctc=0.893, loss_att=80.973, acc=0.189, cer=0.718, wer=1.000, loss=90.038, time=11.23 seconds, total_count=987, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:16,889 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:16,904 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/18epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:16,905 (trainer:299) INFO: 22/50epoch started. Estimated time to finish: 19 minutes and 14.13 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:21,144 (trainer:780) INFO: 22epoch:train:1-10batch: iter_time=0.026, forward_time=0.174, loss_ctc=105.943, loss_att=77.755, acc=0.204, loss=86.212, backward_time=0.077, grad_norm=13.807, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=8.674e-05, train_time=0.423\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:25,140 (trainer:780) INFO: 22epoch:train:11-20batch: iter_time=1.404e-04, forward_time=0.176, loss_ctc=102.561, loss_att=75.239, acc=0.200, loss=83.436, backward_time=0.077, grad_norm=16.438, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.737e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:29,149 (trainer:780) INFO: 22epoch:train:21-30batch: iter_time=8.871e-05, forward_time=0.180, loss_ctc=115.952, loss_att=84.481, acc=0.190, loss=93.922, backward_time=0.076, grad_norm=10.573, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.801e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:33,143 (trainer:780) INFO: 22epoch:train:31-40batch: iter_time=9.783e-05, forward_time=0.176, loss_ctc=116.053, loss_att=84.407, acc=0.193, loss=93.900, backward_time=0.077, grad_norm=8.244, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.864e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:37,142 (trainer:780) INFO: 22epoch:train:41-50batch: iter_time=1.139e-04, forward_time=0.179, loss_ctc=107.779, loss_att=77.992, acc=0.202, loss=86.928, backward_time=0.076, grad_norm=7.469, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.927e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:41,142 (trainer:780) INFO: 22epoch:train:51-60batch: iter_time=1.254e-04, forward_time=0.179, loss_ctc=111.480, loss_att=80.947, acc=0.205, loss=90.107, backward_time=0.077, grad_norm=9.098, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.990e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:54,507 (trainer:365) INFO: 22epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=110.327, loss_att=80.342, acc=0.199, loss=89.337, backward_time=0.076, grad_norm=11.538, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=8.848e-05, train_time=0.398, time=25.94 seconds, total_count=1430, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=109.973, cer_ctc=0.877, loss_att=80.151, acc=0.195, cer=0.711, wer=1.000, loss=89.098, time=11.66 seconds, total_count=1034, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:56,838 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:56,852 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/19epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:48:56,853 (trainer:299) INFO: 23/50epoch started. Estimated time to finish: 18 minutes and 34.53 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:01,142 (trainer:780) INFO: 23epoch:train:1-10batch: iter_time=0.029, forward_time=0.177, loss_ctc=106.261, loss_att=76.841, acc=0.214, loss=85.667, backward_time=0.076, grad_norm=11.737, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=9.085e-05, train_time=0.428\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:05,144 (trainer:780) INFO: 23epoch:train:11-20batch: iter_time=9.343e-05, forward_time=0.179, loss_ctc=114.706, loss_att=82.727, acc=0.198, loss=92.321, backward_time=0.077, grad_norm=11.109, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.148e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:09,140 (trainer:780) INFO: 23epoch:train:21-30batch: iter_time=9.141e-05, forward_time=0.178, loss_ctc=106.582, loss_att=77.214, acc=0.206, loss=86.024, backward_time=0.077, grad_norm=9.020, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=9.212e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:13,147 (trainer:780) INFO: 23epoch:train:31-40batch: iter_time=7.562e-05, forward_time=0.178, loss_ctc=113.320, loss_att=82.066, acc=0.200, loss=91.442, backward_time=0.077, grad_norm=11.286, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=9.275e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:16,848 (trainer:780) INFO: 23epoch:train:41-50batch: iter_time=1.123e-04, forward_time=0.165, loss_ctc=121.190, loss_att=87.426, acc=0.201, loss=97.555, backward_time=0.072, grad_norm=16.404, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=9.338e-05, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:20,841 (trainer:780) INFO: 23epoch:train:51-60batch: iter_time=8.742e-05, forward_time=0.179, loss_ctc=107.833, loss_att=77.526, acc=0.204, loss=86.618, backward_time=0.076, grad_norm=10.378, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=9.401e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:34,177 (trainer:365) INFO: 23epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=109.721, loss_att=79.235, acc=0.206, loss=88.381, backward_time=0.076, grad_norm=11.452, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=9.259e-05, train_time=0.400, time=26.03 seconds, total_count=1495, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=109.300, cer_ctc=0.874, loss_att=79.352, acc=0.199, cer=0.713, wer=1.000, loss=88.336, time=11.3 seconds, total_count=1081, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:36,335 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:36,349 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/20epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:36,350 (trainer:299) INFO: 24/50epoch started. Estimated time to finish: 17 minutes and 54.36 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:40,653 (trainer:780) INFO: 24epoch:train:1-10batch: iter_time=0.024, forward_time=0.181, loss_ctc=109.813, loss_att=78.962, acc=0.211, loss=88.218, backward_time=0.077, grad_norm=8.329, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=9.496e-05, train_time=0.430\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:44,642 (trainer:780) INFO: 24epoch:train:11-20batch: iter_time=8.869e-05, forward_time=0.177, loss_ctc=116.425, loss_att=83.781, acc=0.204, loss=93.574, backward_time=0.077, grad_norm=9.149, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.560e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:48,643 (trainer:780) INFO: 24epoch:train:21-30batch: iter_time=8.259e-05, forward_time=0.181, loss_ctc=98.030, loss_att=70.230, acc=0.223, loss=78.570, backward_time=0.076, grad_norm=9.253, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=9.623e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:52,650 (trainer:780) INFO: 24epoch:train:31-40batch: iter_time=9.605e-05, forward_time=0.180, loss_ctc=104.314, loss_att=75.159, acc=0.212, loss=83.905, backward_time=0.076, grad_norm=8.655, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.686e-05, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:49:56,644 (trainer:780) INFO: 24epoch:train:41-50batch: iter_time=1.229e-04, forward_time=0.178, loss_ctc=104.541, loss_att=75.378, acc=0.212, loss=84.127, backward_time=0.076, grad_norm=7.916, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.749e-05, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:00,753 (trainer:780) INFO: 24epoch:train:51-60batch: iter_time=8.926e-05, forward_time=0.187, loss_ctc=114.341, loss_att=82.633, acc=0.208, loss=92.145, backward_time=0.077, grad_norm=10.619, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.813e-05, train_time=0.411\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:13,701 (trainer:365) INFO: 24epoch results: [train] iter_time=0.004, forward_time=0.178, loss_ctc=108.819, loss_att=78.367, acc=0.211, loss=87.502, backward_time=0.076, grad_norm=10.064, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.670e-05, train_time=0.401, time=26.13 seconds, total_count=1560, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=108.908, cer_ctc=0.879, loss_att=78.610, acc=0.203, cer=0.709, wer=1.000, loss=87.699, time=11.22 seconds, total_count=1128, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:16,175 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:16,190 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/21epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:16,190 (trainer:299) INFO: 25/50epoch started. Estimated time to finish: 17 minutes and 14.62 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:20,143 (trainer:780) INFO: 25epoch:train:1-10batch: iter_time=0.025, forward_time=0.163, loss_ctc=123.796, loss_att=88.952, acc=0.193, loss=99.405, backward_time=0.072, grad_norm=16.367, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=9.907e-05, train_time=0.395\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:24,145 (trainer:780) INFO: 25epoch:train:11-20batch: iter_time=7.846e-05, forward_time=0.181, loss_ctc=90.983, loss_att=65.048, acc=0.231, loss=72.829, backward_time=0.076, grad_norm=8.435, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=9.971e-05, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:28,110 (trainer:780) INFO: 25epoch:train:21-30batch: iter_time=7.508e-05, forward_time=0.175, loss_ctc=103.573, loss_att=74.103, acc=0.217, loss=82.944, backward_time=0.077, grad_norm=9.762, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.003e-04, train_time=0.396\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:32,239 (trainer:780) INFO: 25epoch:train:31-40batch: iter_time=1.057e-04, forward_time=0.184, loss_ctc=118.728, loss_att=85.131, acc=0.202, loss=95.210, backward_time=0.077, grad_norm=11.972, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.010e-04, train_time=0.413\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:36,244 (trainer:780) INFO: 25epoch:train:41-50batch: iter_time=8.924e-05, forward_time=0.178, loss_ctc=111.028, loss_att=79.560, acc=0.208, loss=89.000, backward_time=0.077, grad_norm=10.687, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.016e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:40,242 (trainer:780) INFO: 25epoch:train:51-60batch: iter_time=7.256e-05, forward_time=0.176, loss_ctc=111.521, loss_att=80.639, acc=0.212, loss=89.903, backward_time=0.077, grad_norm=13.025, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.022e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:53,583 (trainer:365) INFO: 25epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=108.095, loss_att=77.573, acc=0.213, loss=86.729, backward_time=0.076, grad_norm=11.649, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.008e-04, train_time=0.401, time=26.1 seconds, total_count=1625, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=107.980, cer_ctc=0.862, loss_att=78.144, acc=0.203, cer=0.713, wer=1.000, loss=87.095, time=11.29 seconds, total_count=1175, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:56,069 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:56,083 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/22epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:50:56,084 (trainer:299) INFO: 26/50epoch started. Estimated time to finish: 16 minutes and 34.93 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:00,357 (trainer:780) INFO: 26epoch:train:1-10batch: iter_time=0.026, forward_time=0.174, loss_ctc=108.930, loss_att=78.199, acc=0.219, loss=87.418, backward_time=0.077, grad_norm=11.654, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.032e-04, train_time=0.427\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:04,341 (trainer:780) INFO: 26epoch:train:11-20batch: iter_time=7.121e-05, forward_time=0.178, loss_ctc=93.661, loss_att=67.386, acc=0.230, loss=75.268, backward_time=0.077, grad_norm=8.956, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.038e-04, train_time=0.398\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:08,043 (trainer:780) INFO: 26epoch:train:21-30batch: iter_time=7.817e-05, forward_time=0.168, loss_ctc=103.090, loss_att=73.758, acc=0.224, loss=82.558, backward_time=0.071, grad_norm=15.775, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.045e-04, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:12,050 (trainer:780) INFO: 26epoch:train:31-40batch: iter_time=9.831e-05, forward_time=0.179, loss_ctc=108.764, loss_att=77.816, acc=0.214, loss=87.100, backward_time=0.077, grad_norm=9.048, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.051e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:16,044 (trainer:780) INFO: 26epoch:train:41-50batch: iter_time=1.001e-04, forward_time=0.178, loss_ctc=113.526, loss_att=81.288, acc=0.209, loss=90.959, backward_time=0.077, grad_norm=11.030, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.057e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:20,042 (trainer:780) INFO: 26epoch:train:51-60batch: iter_time=8.867e-05, forward_time=0.177, loss_ctc=122.497, loss_att=87.834, acc=0.199, loss=98.233, backward_time=0.078, grad_norm=11.590, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.063e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:33,283 (trainer:365) INFO: 26epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=107.078, loss_att=76.820, acc=0.217, loss=85.898, backward_time=0.076, grad_norm=11.304, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.049e-04, train_time=0.399, time=25.95 seconds, total_count=1690, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=106.361, cer_ctc=0.870, loss_att=77.343, acc=0.207, cer=0.708, wer=1.000, loss=86.049, time=11.24 seconds, total_count=1222, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:35,397 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:35,411 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/23epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:35,412 (trainer:299) INFO: 27/50epoch started. Estimated time to finish: 15 minutes and 54.7 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:39,604 (trainer:780) INFO: 27epoch:train:1-10batch: iter_time=0.023, forward_time=0.170, loss_ctc=123.206, loss_att=88.649, acc=0.202, loss=99.016, backward_time=0.077, grad_norm=10.689, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.073e-04, train_time=0.419\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:43,646 (trainer:780) INFO: 27epoch:train:11-20batch: iter_time=7.634e-05, forward_time=0.184, loss_ctc=92.417, loss_att=66.263, acc=0.227, loss=74.109, backward_time=0.076, grad_norm=8.612, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.079e-04, train_time=0.404\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:47,347 (trainer:780) INFO: 27epoch:train:21-30batch: iter_time=9.263e-05, forward_time=0.166, loss_ctc=103.243, loss_att=74.253, acc=0.221, loss=82.950, backward_time=0.072, grad_norm=15.572, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.086e-04, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:51,350 (trainer:780) INFO: 27epoch:train:31-40batch: iter_time=7.647e-05, forward_time=0.178, loss_ctc=109.240, loss_att=78.338, acc=0.214, loss=87.609, backward_time=0.077, grad_norm=10.221, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.092e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:55,341 (trainer:780) INFO: 27epoch:train:41-50batch: iter_time=1.114e-04, forward_time=0.174, loss_ctc=104.462, loss_att=75.829, acc=0.218, loss=84.419, backward_time=0.078, grad_norm=11.695, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.098e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:51:59,343 (trainer:780) INFO: 27epoch:train:51-60batch: iter_time=7.226e-05, forward_time=0.178, loss_ctc=112.694, loss_att=80.706, acc=0.212, loss=90.303, backward_time=0.077, grad_norm=11.016, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.105e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:12,696 (trainer:365) INFO: 27epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=105.901, loss_att=76.180, acc=0.218, loss=85.096, backward_time=0.076, grad_norm=11.208, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.090e-04, train_time=0.399, time=25.97 seconds, total_count=1755, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=104.987, cer_ctc=0.857, loss_att=77.002, acc=0.209, cer=0.714, wer=1.000, loss=85.398, time=11.32 seconds, total_count=1269, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:14,862 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:14,880 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/24epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:14,880 (trainer:299) INFO: 28/50epoch started. Estimated time to finish: 15 minutes and 14.66 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:19,145 (trainer:780) INFO: 28epoch:train:1-10batch: iter_time=0.026, forward_time=0.178, loss_ctc=94.460, loss_att=67.784, acc=0.235, loss=75.787, backward_time=0.076, grad_norm=9.258, clip=100.000, loss_scale=1.000optim_step_time=0.005, optim0_lr0=1.114e-04, train_time=0.426\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:23,144 (trainer:780) INFO: 28epoch:train:11-20batch: iter_time=1.046e-04, forward_time=0.175, loss_ctc=125.605, loss_att=90.774, acc=0.201, loss=101.223, backward_time=0.077, grad_norm=11.096, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.120e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:27,147 (trainer:780) INFO: 28epoch:train:21-30batch: iter_time=8.770e-05, forward_time=0.179, loss_ctc=102.371, loss_att=73.502, acc=0.223, loss=82.162, backward_time=0.077, grad_norm=10.743, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.127e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:31,145 (trainer:780) INFO: 28epoch:train:31-40batch: iter_time=8.791e-05, forward_time=0.178, loss_ctc=109.333, loss_att=78.540, acc=0.218, loss=87.778, backward_time=0.077, grad_norm=10.552, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.133e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:35,147 (trainer:780) INFO: 28epoch:train:41-50batch: iter_time=8.750e-05, forward_time=0.178, loss_ctc=106.498, loss_att=77.166, acc=0.220, loss=85.966, backward_time=0.077, grad_norm=12.106, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.139e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:38,842 (trainer:780) INFO: 28epoch:train:51-60batch: iter_time=8.828e-05, forward_time=0.166, loss_ctc=92.120, loss_att=66.708, acc=0.235, loss=74.332, backward_time=0.072, grad_norm=15.770, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.146e-04, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:52,283 (trainer:365) INFO: 28epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=104.632, loss_att=75.483, acc=0.222, loss=84.228, backward_time=0.076, grad_norm=11.828, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.131e-04, train_time=0.400, time=26.02 seconds, total_count=1820, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=104.299, cer_ctc=0.813, loss_att=76.465, acc=0.210, cer=0.705, wer=1.000, loss=84.816, time=11.38 seconds, total_count=1316, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:54,652 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:54,667 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/25epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:54,667 (trainer:299) INFO: 29/50epoch started. Estimated time to finish: 14 minutes and 34.9 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:52:58,945 (trainer:780) INFO: 29epoch:train:1-10batch: iter_time=0.024, forward_time=0.181, loss_ctc=102.926, loss_att=74.449, acc=0.222, loss=82.992, backward_time=0.076, grad_norm=8.965, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.155e-04, train_time=0.427\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:02,943 (trainer:780) INFO: 29epoch:train:11-20batch: iter_time=9.675e-05, forward_time=0.179, loss_ctc=98.022, loss_att=70.892, acc=0.231, loss=79.031, backward_time=0.076, grad_norm=9.640, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.162e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:06,946 (trainer:780) INFO: 29epoch:train:21-30batch: iter_time=8.047e-05, forward_time=0.179, loss_ctc=99.608, loss_att=72.273, acc=0.229, loss=80.474, backward_time=0.077, grad_norm=15.326, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.168e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:10,957 (trainer:780) INFO: 29epoch:train:31-40batch: iter_time=1.134e-04, forward_time=0.178, loss_ctc=94.976, loss_att=69.109, acc=0.231, loss=76.869, backward_time=0.077, grad_norm=12.755, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.174e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:14,646 (trainer:780) INFO: 29epoch:train:41-50batch: iter_time=7.806e-05, forward_time=0.164, loss_ctc=119.544, loss_att=86.765, acc=0.209, loss=96.599, backward_time=0.072, grad_norm=17.162, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.180e-04, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:18,648 (trainer:780) INFO: 29epoch:train:51-60batch: iter_time=1.179e-04, forward_time=0.178, loss_ctc=109.169, loss_att=79.223, acc=0.220, loss=88.207, backward_time=0.077, grad_norm=10.832, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.187e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:31,771 (trainer:365) INFO: 29epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=103.322, loss_att=74.887, acc=0.224, loss=83.418, backward_time=0.076, grad_norm=12.184, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.173e-04, train_time=0.400, time=26.01 seconds, total_count=1885, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=102.954, cer_ctc=0.822, loss_att=75.883, acc=0.214, cer=0.708, wer=1.000, loss=84.004, time=11.09 seconds, total_count=1363, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:34,179 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:34,193 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/26epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:34,194 (trainer:299) INFO: 30/50epoch started. Estimated time to finish: 13 minutes and 54.96 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:38,441 (trainer:780) INFO: 30epoch:train:1-10batch: iter_time=0.025, forward_time=0.177, loss_ctc=97.236, loss_att=70.130, acc=0.232, loss=78.262, backward_time=0.077, grad_norm=9.269, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.196e-04, train_time=0.424\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:42,443 (trainer:780) INFO: 30epoch:train:11-20batch: iter_time=9.682e-05, forward_time=0.178, loss_ctc=111.672, loss_att=81.249, acc=0.219, loss=90.376, backward_time=0.077, grad_norm=10.000, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.203e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:46,443 (trainer:780) INFO: 30epoch:train:21-30batch: iter_time=1.079e-04, forward_time=0.180, loss_ctc=97.870, loss_att=70.873, acc=0.236, loss=78.972, backward_time=0.076, grad_norm=10.130, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.209e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:50,124 (trainer:780) INFO: 30epoch:train:31-40batch: iter_time=7.408e-05, forward_time=0.163, loss_ctc=111.788, loss_att=81.787, acc=0.215, loss=90.787, backward_time=0.074, grad_norm=17.835, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.215e-04, train_time=0.368\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:54,145 (trainer:780) INFO: 30epoch:train:41-50batch: iter_time=9.792e-05, forward_time=0.182, loss_ctc=97.270, loss_att=70.580, acc=0.233, loss=78.587, backward_time=0.076, grad_norm=12.461, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.222e-04, train_time=0.402\n",
      "[jupyter-wpc0385] 2025-07-03 10:53:58,143 (trainer:780) INFO: 30epoch:train:51-60batch: iter_time=9.455e-05, forward_time=0.173, loss_ctc=119.668, loss_att=88.655, acc=0.209, loss=97.959, backward_time=0.078, grad_norm=17.585, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.228e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:11,293 (trainer:365) INFO: 30epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=101.890, loss_att=74.223, acc=0.228, loss=82.523, backward_time=0.076, grad_norm=12.594, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.214e-04, train_time=0.399, time=25.95 seconds, total_count=1950, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=100.129, cer_ctc=0.825, loss_att=75.271, acc=0.218, cer=0.704, wer=1.000, loss=82.728, time=11.15 seconds, total_count=1410, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:13,379 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:13,394 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/27epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:13,394 (trainer:299) INFO: 31/50epoch started. Estimated time to finish: 13 minutes and 14.83 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:17,747 (trainer:780) INFO: 31epoch:train:1-10batch: iter_time=0.023, forward_time=0.185, loss_ctc=120.169, loss_att=88.445, acc=0.214, loss=97.963, backward_time=0.078, grad_norm=12.473, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.237e-04, train_time=0.435\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:21,760 (trainer:780) INFO: 31epoch:train:11-20batch: iter_time=1.033e-04, forward_time=0.179, loss_ctc=93.501, loss_att=68.994, acc=0.236, loss=76.347, backward_time=0.077, grad_norm=10.845, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.244e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:25,448 (trainer:780) INFO: 31epoch:train:21-30batch: iter_time=1.086e-04, forward_time=0.168, loss_ctc=90.898, loss_att=66.228, acc=0.245, loss=73.629, backward_time=0.071, grad_norm=14.959, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.250e-04, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:29,443 (trainer:780) INFO: 31epoch:train:31-40batch: iter_time=9.871e-05, forward_time=0.176, loss_ctc=110.182, loss_att=81.246, acc=0.219, loss=89.927, backward_time=0.077, grad_norm=12.412, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.256e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:33,446 (trainer:780) INFO: 31epoch:train:41-50batch: iter_time=9.027e-05, forward_time=0.179, loss_ctc=95.087, loss_att=69.977, acc=0.233, loss=77.510, backward_time=0.077, grad_norm=11.034, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.263e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:37,445 (trainer:780) INFO: 31epoch:train:51-60batch: iter_time=8.864e-05, forward_time=0.178, loss_ctc=101.741, loss_att=74.784, acc=0.226, loss=82.871, backward_time=0.077, grad_norm=10.647, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.269e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:50,683 (trainer:365) INFO: 31epoch results: [train] iter_time=0.004, forward_time=0.178, loss_ctc=100.083, loss_att=73.622, acc=0.230, loss=81.560, backward_time=0.076, grad_norm=12.030, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.255e-04, train_time=0.401, time=26.08 seconds, total_count=2015, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=98.610, cer_ctc=0.775, loss_att=75.386, acc=0.216, cer=0.707, wer=1.000, loss=82.353, time=11.2 seconds, total_count=1457, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:53,175 (trainer:431) INFO: There are no improvements in this epoch\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:53,192 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/28epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:53,193 (trainer:299) INFO: 32/50epoch started. Estimated time to finish: 12 minutes and 35.12 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:54:57,443 (trainer:780) INFO: 32epoch:train:1-10batch: iter_time=0.026, forward_time=0.176, loss_ctc=97.728, loss_att=71.871, acc=0.232, loss=79.628, backward_time=0.076, grad_norm=12.704, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.279e-04, train_time=0.424\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:01,447 (trainer:780) INFO: 32epoch:train:11-20batch: iter_time=7.875e-05, forward_time=0.178, loss_ctc=103.270, loss_att=76.839, acc=0.220, loss=84.768, backward_time=0.077, grad_norm=12.809, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.285e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:05,129 (trainer:780) INFO: 32epoch:train:21-30batch: iter_time=7.921e-05, forward_time=0.166, loss_ctc=87.914, loss_att=65.524, acc=0.242, loss=72.241, backward_time=0.072, grad_norm=17.099, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.291e-04, train_time=0.368\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:09,146 (trainer:780) INFO: 32epoch:train:31-40batch: iter_time=1.127e-04, forward_time=0.180, loss_ctc=95.856, loss_att=71.203, acc=0.231, loss=78.599, backward_time=0.077, grad_norm=13.542, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.297e-04, train_time=0.402\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:13,141 (trainer:780) INFO: 32epoch:train:41-50batch: iter_time=9.509e-05, forward_time=0.177, loss_ctc=94.727, loss_att=70.637, acc=0.238, loss=77.864, backward_time=0.077, grad_norm=12.634, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.304e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:17,146 (trainer:780) INFO: 32epoch:train:51-60batch: iter_time=8.731e-05, forward_time=0.175, loss_ctc=120.385, loss_att=89.967, acc=0.210, loss=99.092, backward_time=0.078, grad_norm=15.946, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.310e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:30,507 (trainer:365) INFO: 32epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=98.522, loss_att=73.195, acc=0.231, loss=80.793, backward_time=0.076, grad_norm=14.037, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.296e-04, train_time=0.399, time=25.95 seconds, total_count=2080, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=97.145, cer_ctc=0.787, loss_att=74.487, acc=0.222, cer=0.701, wer=1.000, loss=81.285, time=11.36 seconds, total_count=1504, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:32,854 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:32,872 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/29epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:32,872 (trainer:299) INFO: 33/50epoch started. Estimated time to finish: 11 minutes and 55.34 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:37,144 (trainer:780) INFO: 33epoch:train:1-10batch: iter_time=0.028, forward_time=0.174, loss_ctc=99.188, loss_att=73.896, acc=0.234, loss=81.483, backward_time=0.077, grad_norm=12.614, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.320e-04, train_time=0.427\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:41,154 (trainer:780) INFO: 33epoch:train:11-20batch: iter_time=8.524e-05, forward_time=0.177, loss_ctc=105.860, loss_att=79.253, acc=0.232, loss=87.235, backward_time=0.077, grad_norm=11.998, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.326e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:44,846 (trainer:780) INFO: 33epoch:train:21-30batch: iter_time=7.697e-05, forward_time=0.167, loss_ctc=93.469, loss_att=69.737, acc=0.236, loss=76.857, backward_time=0.071, grad_norm=15.917, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.332e-04, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:48,849 (trainer:780) INFO: 33epoch:train:31-40batch: iter_time=1.004e-04, forward_time=0.180, loss_ctc=75.651, loss_att=56.526, acc=0.261, loss=62.264, backward_time=0.077, grad_norm=9.971, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.339e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:52,848 (trainer:780) INFO: 33epoch:train:41-50batch: iter_time=1.036e-04, forward_time=0.178, loss_ctc=101.749, loss_att=76.303, acc=0.230, loss=83.937, backward_time=0.077, grad_norm=13.310, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.345e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:55:56,845 (trainer:780) INFO: 33epoch:train:51-60batch: iter_time=9.112e-05, forward_time=0.177, loss_ctc=101.962, loss_att=76.967, acc=0.222, loss=84.466, backward_time=0.077, grad_norm=14.270, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.351e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:10,094 (trainer:365) INFO: 33epoch results: [train] iter_time=0.004, forward_time=0.174, loss_ctc=96.778, loss_att=72.566, acc=0.236, loss=79.829, backward_time=0.076, grad_norm=13.036, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.337e-04, train_time=0.399, time=25.95 seconds, total_count=2145, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=94.583, cer_ctc=0.753, loss_att=74.095, acc=0.224, cer=0.702, wer=1.000, loss=80.241, time=11.27 seconds, total_count=1551, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:12,676 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:12,696 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/31epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:12,697 (trainer:299) INFO: 34/50epoch started. Estimated time to finish: 11 minutes and 15.64 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:16,943 (trainer:780) INFO: 34epoch:train:1-10batch: iter_time=0.024, forward_time=0.174, loss_ctc=101.494, loss_att=77.338, acc=0.232, loss=84.585, backward_time=0.078, grad_norm=12.490, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.361e-04, train_time=0.424\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:21,010 (trainer:780) INFO: 34epoch:train:11-20batch: iter_time=7.558e-05, forward_time=0.178, loss_ctc=101.851, loss_att=77.274, acc=0.228, loss=84.647, backward_time=0.077, grad_norm=12.946, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.367e-04, train_time=0.407\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:24,743 (trainer:780) INFO: 34epoch:train:21-30batch: iter_time=1.010e-04, forward_time=0.172, loss_ctc=81.171, loss_att=61.527, acc=0.254, loss=67.420, backward_time=0.071, grad_norm=18.000, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.373e-04, train_time=0.373\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:28,758 (trainer:780) INFO: 34epoch:train:31-40batch: iter_time=8.599e-05, forward_time=0.178, loss_ctc=98.967, loss_att=75.411, acc=0.231, loss=82.478, backward_time=0.077, grad_norm=14.737, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.380e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:32,738 (trainer:780) INFO: 34epoch:train:41-50batch: iter_time=9.614e-05, forward_time=0.178, loss_ctc=91.856, loss_att=69.326, acc=0.239, loss=76.085, backward_time=0.076, grad_norm=11.358, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.386e-04, train_time=0.398\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:36,739 (trainer:780) INFO: 34epoch:train:51-60batch: iter_time=9.527e-05, forward_time=0.177, loss_ctc=101.237, loss_att=77.983, acc=0.231, loss=84.959, backward_time=0.078, grad_norm=13.267, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.392e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:50,122 (trainer:365) INFO: 34epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=94.716, loss_att=72.027, acc=0.237, loss=78.834, backward_time=0.076, grad_norm=13.575, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.378e-04, train_time=0.400, time=26.08 seconds, total_count=2210, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=92.075, cer_ctc=0.738, loss_att=73.632, acc=0.225, cer=0.700, wer=1.000, loss=79.165, time=11.35 seconds, total_count=1598, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:52,681 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:52,701 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/30epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:52,702 (trainer:299) INFO: 35/50epoch started. Estimated time to finish: 10 minutes and 36.02 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:56:57,051 (trainer:780) INFO: 35epoch:train:1-10batch: iter_time=0.026, forward_time=0.186, loss_ctc=86.196, loss_att=65.490, acc=0.249, loss=71.702, backward_time=0.076, grad_norm=9.993, clip=100.000, loss_scale=1.000optim_step_time=0.005, optim0_lr0=1.402e-04, train_time=0.434\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:01,047 (trainer:780) INFO: 35epoch:train:11-20batch: iter_time=7.711e-05, forward_time=0.178, loss_ctc=88.733, loss_att=68.226, acc=0.247, loss=74.378, backward_time=0.077, grad_norm=12.269, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.408e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:05,038 (trainer:780) INFO: 35epoch:train:21-30batch: iter_time=8.992e-05, forward_time=0.179, loss_ctc=97.193, loss_att=74.314, acc=0.235, loss=81.177, backward_time=0.076, grad_norm=12.637, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.414e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:09,046 (trainer:780) INFO: 35epoch:train:31-40batch: iter_time=7.743e-05, forward_time=0.176, loss_ctc=109.994, loss_att=86.251, acc=0.224, loss=93.374, backward_time=0.078, grad_norm=16.844, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.421e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:13,040 (trainer:780) INFO: 35epoch:train:41-50batch: iter_time=1.002e-04, forward_time=0.177, loss_ctc=101.211, loss_att=79.044, acc=0.225, loss=85.694, backward_time=0.077, grad_norm=14.156, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.427e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:16,738 (trainer:780) INFO: 35epoch:train:51-60batch: iter_time=7.445e-05, forward_time=0.168, loss_ctc=85.001, loss_att=65.516, acc=0.248, loss=71.361, backward_time=0.071, grad_norm=19.655, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.433e-04, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:29,984 (trainer:365) INFO: 35epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=92.669, loss_att=71.452, acc=0.241, loss=77.817, backward_time=0.076, grad_norm=13.978, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.419e-04, train_time=0.400, time=26.05 seconds, total_count=2275, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=90.132, cer_ctc=0.720, loss_att=73.328, acc=0.228, cer=0.700, wer=1.000, loss=78.369, time=11.23 seconds, total_count=1645, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:32,580 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:32,595 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/32epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:32,595 (trainer:299) INFO: 36/50epoch started. Estimated time to finish: 9 minutes and 56.33 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:36,943 (trainer:780) INFO: 36epoch:train:1-10batch: iter_time=0.028, forward_time=0.184, loss_ctc=75.824, loss_att=58.340, acc=0.266, loss=63.585, backward_time=0.077, grad_norm=12.030, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.443e-04, train_time=0.434\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:40,952 (trainer:780) INFO: 36epoch:train:11-20batch: iter_time=1.078e-04, forward_time=0.176, loss_ctc=105.937, loss_att=84.099, acc=0.227, loss=90.651, backward_time=0.078, grad_norm=14.578, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.449e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:44,944 (trainer:780) INFO: 36epoch:train:21-30batch: iter_time=7.783e-05, forward_time=0.178, loss_ctc=87.482, loss_att=68.554, acc=0.248, loss=74.233, backward_time=0.077, grad_norm=13.288, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.456e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:48,942 (trainer:780) INFO: 36epoch:train:31-40batch: iter_time=8.257e-05, forward_time=0.178, loss_ctc=89.614, loss_att=70.256, acc=0.241, loss=76.063, backward_time=0.077, grad_norm=13.757, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.462e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:52,942 (trainer:780) INFO: 36epoch:train:41-50batch: iter_time=7.623e-05, forward_time=0.178, loss_ctc=89.880, loss_att=70.634, acc=0.245, loss=76.408, backward_time=0.077, grad_norm=13.290, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.468e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:57:56,648 (trainer:780) INFO: 36epoch:train:51-60batch: iter_time=1.082e-04, forward_time=0.167, loss_ctc=95.459, loss_att=74.676, acc=0.238, loss=80.911, backward_time=0.071, grad_norm=19.518, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.475e-04, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:09,684 (trainer:365) INFO: 36epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=90.402, loss_att=70.902, acc=0.244, loss=76.752, backward_time=0.076, grad_norm=14.291, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.460e-04, train_time=0.401, time=26.08 seconds, total_count=2340, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=87.476, cer_ctc=0.696, loss_att=72.957, acc=0.230, cer=0.699, wer=1.000, loss=77.313, time=11.01 seconds, total_count=1692, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:12,425 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:12,440 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/33epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:12,440 (trainer:299) INFO: 37/50epoch started. Estimated time to finish: 9 minutes and 16.61 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:16,454 (trainer:780) INFO: 37epoch:train:1-10batch: iter_time=0.025, forward_time=0.170, loss_ctc=100.757, loss_att=80.719, acc=0.230, loss=86.731, backward_time=0.072, grad_norm=21.003, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.484e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:20,449 (trainer:780) INFO: 37epoch:train:11-20batch: iter_time=7.993e-05, forward_time=0.177, loss_ctc=86.926, loss_att=68.581, acc=0.248, loss=74.084, backward_time=0.077, grad_norm=14.253, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.490e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:24,451 (trainer:780) INFO: 37epoch:train:21-30batch: iter_time=7.856e-05, forward_time=0.178, loss_ctc=85.274, loss_att=67.381, acc=0.255, loss=72.749, backward_time=0.077, grad_norm=13.974, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.497e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:28,445 (trainer:780) INFO: 37epoch:train:31-40batch: iter_time=7.455e-05, forward_time=0.178, loss_ctc=86.525, loss_att=68.106, acc=0.250, loss=73.632, backward_time=0.077, grad_norm=14.546, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.503e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:32,442 (trainer:780) INFO: 37epoch:train:41-50batch: iter_time=8.731e-05, forward_time=0.180, loss_ctc=79.308, loss_att=62.528, acc=0.254, loss=67.562, backward_time=0.076, grad_norm=11.348, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.509e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:36,447 (trainer:780) INFO: 37epoch:train:51-60batch: iter_time=1.007e-04, forward_time=0.177, loss_ctc=98.144, loss_att=79.157, acc=0.232, loss=84.853, backward_time=0.077, grad_norm=15.878, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.516e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:49,893 (trainer:365) INFO: 37epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=88.660, loss_att=70.446, acc=0.245, loss=75.910, backward_time=0.076, grad_norm=15.116, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.501e-04, train_time=0.400, time=26.04 seconds, total_count=2405, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=85.646, cer_ctc=0.678, loss_att=72.844, acc=0.231, cer=0.692, wer=1.000, loss=76.684, time=11.41 seconds, total_count=1739, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:51,922 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:51,943 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/34epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:51,943 (trainer:299) INFO: 38/50epoch started. Estimated time to finish: 8 minutes and 36.76 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:58:56,042 (trainer:780) INFO: 38epoch:train:1-10batch: iter_time=0.031, forward_time=0.171, loss_ctc=89.901, loss_att=72.927, acc=0.246, loss=78.019, backward_time=0.072, grad_norm=21.302, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.525e-04, train_time=0.409\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:00,041 (trainer:780) INFO: 38epoch:train:11-20batch: iter_time=1.118e-04, forward_time=0.181, loss_ctc=81.712, loss_att=64.826, acc=0.260, loss=69.892, backward_time=0.076, grad_norm=12.488, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.531e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:04,046 (trainer:780) INFO: 38epoch:train:21-30batch: iter_time=7.586e-05, forward_time=0.180, loss_ctc=80.844, loss_att=64.650, acc=0.254, loss=69.508, backward_time=0.076, grad_norm=14.178, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.538e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:08,048 (trainer:780) INFO: 38epoch:train:31-40batch: iter_time=7.425e-05, forward_time=0.178, loss_ctc=90.271, loss_att=73.715, acc=0.245, loss=78.682, backward_time=0.077, grad_norm=15.027, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.544e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:12,047 (trainer:780) INFO: 38epoch:train:41-50batch: iter_time=1.041e-04, forward_time=0.179, loss_ctc=87.294, loss_att=71.038, acc=0.239, loss=75.915, backward_time=0.076, grad_norm=14.633, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.550e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:16,048 (trainer:780) INFO: 38epoch:train:51-60batch: iter_time=1.088e-04, forward_time=0.175, loss_ctc=92.439, loss_att=76.426, acc=0.243, loss=81.230, backward_time=0.078, grad_norm=17.065, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.557e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:29,292 (trainer:365) INFO: 38epoch results: [train] iter_time=0.005, forward_time=0.177, loss_ctc=86.307, loss_att=69.940, acc=0.249, loss=74.850, backward_time=0.076, grad_norm=15.588, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.543e-04, train_time=0.401, time=26.13 seconds, total_count=2470, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=83.626, cer_ctc=0.673, loss_att=72.381, acc=0.233, cer=0.696, wer=1.000, loss=75.755, time=11.22 seconds, total_count=1786, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:32,041 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:32,056 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/35epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:32,056 (trainer:299) INFO: 39/50epoch started. Estimated time to finish: 7 minutes and 57.13 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:36,343 (trainer:780) INFO: 39epoch:train:1-10batch: iter_time=0.025, forward_time=0.178, loss_ctc=84.044, loss_att=68.968, acc=0.255, loss=73.491, backward_time=0.077, grad_norm=15.134, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.566e-04, train_time=0.428\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:40,343 (trainer:780) INFO: 39epoch:train:11-20batch: iter_time=7.955e-05, forward_time=0.177, loss_ctc=88.315, loss_att=72.808, acc=0.244, loss=77.460, backward_time=0.077, grad_norm=17.028, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.573e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:44,338 (trainer:780) INFO: 39epoch:train:21-30batch: iter_time=8.011e-05, forward_time=0.180, loss_ctc=76.695, loss_att=62.182, acc=0.261, loss=66.536, backward_time=0.076, grad_norm=15.733, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.579e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:48,345 (trainer:780) INFO: 39epoch:train:31-40batch: iter_time=8.973e-05, forward_time=0.179, loss_ctc=84.604, loss_att=69.227, acc=0.248, loss=73.840, backward_time=0.077, grad_norm=15.963, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.585e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:52,345 (trainer:780) INFO: 39epoch:train:41-50batch: iter_time=8.268e-05, forward_time=0.179, loss_ctc=83.799, loss_att=69.035, acc=0.250, loss=73.464, backward_time=0.077, grad_norm=13.533, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.592e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 10:59:56,311 (trainer:780) INFO: 39epoch:train:51-60batch: iter_time=9.203e-05, forward_time=0.173, loss_ctc=93.957, loss_att=78.833, acc=0.236, loss=83.370, backward_time=0.078, grad_norm=15.733, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.598e-04, train_time=0.396\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:09,401 (trainer:365) INFO: 39epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=84.491, loss_att=69.473, acc=0.251, loss=73.979, backward_time=0.076, grad_norm=16.819, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.584e-04, train_time=0.399, time=25.99 seconds, total_count=2535, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=81.755, cer_ctc=0.658, loss_att=71.997, acc=0.237, cer=0.696, wer=1.000, loss=74.924, time=11.35 seconds, total_count=1833, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:12,232 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:12,249 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/36epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:12,250 (trainer:299) INFO: 40/50epoch started. Estimated time to finish: 7 minutes and 17.49 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:16,240 (trainer:780) INFO: 40epoch:train:1-10batch: iter_time=0.024, forward_time=0.168, loss_ctc=95.192, loss_att=79.295, acc=0.243, loss=84.064, backward_time=0.073, grad_norm=23.225, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.607e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:20,247 (trainer:780) INFO: 40epoch:train:11-20batch: iter_time=9.925e-05, forward_time=0.180, loss_ctc=78.970, loss_att=65.484, acc=0.262, loss=69.530, backward_time=0.076, grad_norm=14.026, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.614e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:24,244 (trainer:780) INFO: 40epoch:train:21-30batch: iter_time=8.974e-05, forward_time=0.178, loss_ctc=84.716, loss_att=70.554, acc=0.250, loss=74.803, backward_time=0.077, grad_norm=16.956, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.620e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:28,256 (trainer:780) INFO: 40epoch:train:31-40batch: iter_time=8.795e-05, forward_time=0.180, loss_ctc=81.018, loss_att=67.347, acc=0.251, loss=71.448, backward_time=0.077, grad_norm=15.614, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.626e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:32,248 (trainer:780) INFO: 40epoch:train:41-50batch: iter_time=7.633e-05, forward_time=0.177, loss_ctc=85.228, loss_att=71.658, acc=0.251, loss=75.729, backward_time=0.077, grad_norm=16.670, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.633e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:36,259 (trainer:780) INFO: 40epoch:train:51-60batch: iter_time=1.099e-04, forward_time=0.177, loss_ctc=79.708, loss_att=67.375, acc=0.262, loss=71.075, backward_time=0.078, grad_norm=16.026, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.639e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:49,600 (trainer:365) INFO: 40epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=82.607, loss_att=68.933, acc=0.255, loss=73.035, backward_time=0.076, grad_norm=16.755, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.625e-04, train_time=0.400, time=26.03 seconds, total_count=2600, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=79.890, cer_ctc=0.623, loss_att=71.844, acc=0.237, cer=0.692, wer=1.000, loss=74.258, time=11.32 seconds, total_count=1880, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:52,227 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:52,242 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/37epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:52,243 (trainer:299) INFO: 41/50epoch started. Estimated time to finish: 6 minutes and 37.77 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:00:56,233 (trainer:780) INFO: 41epoch:train:1-10batch: iter_time=0.027, forward_time=0.168, loss_ctc=72.384, loss_att=59.854, acc=0.270, loss=63.613, backward_time=0.071, grad_norm=20.022, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.648e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:00,245 (trainer:780) INFO: 41epoch:train:11-20batch: iter_time=7.786e-05, forward_time=0.179, loss_ctc=85.831, loss_att=72.922, acc=0.248, loss=76.795, backward_time=0.077, grad_norm=14.841, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.655e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:04,240 (trainer:780) INFO: 41epoch:train:21-30batch: iter_time=1.025e-04, forward_time=0.176, loss_ctc=85.825, loss_att=74.057, acc=0.250, loss=77.588, backward_time=0.078, grad_norm=17.671, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.661e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:08,246 (trainer:780) INFO: 41epoch:train:31-40batch: iter_time=1.172e-04, forward_time=0.179, loss_ctc=73.733, loss_att=62.038, acc=0.268, loss=65.546, backward_time=0.077, grad_norm=15.610, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.667e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:12,244 (trainer:780) INFO: 41epoch:train:41-50batch: iter_time=1.384e-04, forward_time=0.177, loss_ctc=88.949, loss_att=76.800, acc=0.245, loss=80.445, backward_time=0.077, grad_norm=17.422, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.674e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:16,259 (trainer:780) INFO: 41epoch:train:51-60batch: iter_time=9.530e-05, forward_time=0.178, loss_ctc=81.461, loss_att=70.042, acc=0.255, loss=73.468, backward_time=0.077, grad_norm=19.100, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.680e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:29,897 (trainer:365) INFO: 41epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=80.410, loss_att=68.462, acc=0.258, loss=72.046, backward_time=0.076, grad_norm=17.343, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.666e-04, train_time=0.400, time=26.03 seconds, total_count=2665, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=78.201, cer_ctc=0.644, loss_att=71.901, acc=0.238, cer=0.690, wer=1.000, loss=73.791, time=11.62 seconds, total_count=1927, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:32,490 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:32,505 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/38epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:32,505 (trainer:299) INFO: 42/50epoch started. Estimated time to finish: 5 minutes and 58.1 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:36,546 (trainer:780) INFO: 42epoch:train:1-10batch: iter_time=0.027, forward_time=0.173, loss_ctc=68.552, loss_att=58.678, acc=0.279, loss=61.640, backward_time=0.071, grad_norm=26.213, clip=100.000, loss_scale=1.000optim_step_time=0.005, optim0_lr0=1.690e-04, train_time=0.404\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:40,546 (trainer:780) INFO: 42epoch:train:11-20batch: iter_time=8.839e-05, forward_time=0.177, loss_ctc=91.955, loss_att=80.684, acc=0.239, loss=84.065, backward_time=0.077, grad_norm=20.116, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.696e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:44,541 (trainer:780) INFO: 42epoch:train:21-30batch: iter_time=9.702e-05, forward_time=0.178, loss_ctc=71.506, loss_att=60.600, acc=0.272, loss=63.872, backward_time=0.077, grad_norm=17.196, clip=100.000, loss_scale=1.000, optim_step_time=0.007, optim0_lr0=1.702e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:48,644 (trainer:780) INFO: 42epoch:train:31-40batch: iter_time=9.984e-05, forward_time=0.189, loss_ctc=80.596, loss_att=69.667, acc=0.251, loss=72.946, backward_time=0.077, grad_norm=17.422, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.709e-04, train_time=0.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:52,648 (trainer:780) INFO: 42epoch:train:41-50batch: iter_time=8.990e-05, forward_time=0.177, loss_ctc=80.121, loss_att=69.246, acc=0.260, loss=72.508, backward_time=0.077, grad_norm=19.929, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.715e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:01:56,643 (trainer:780) INFO: 42epoch:train:51-60batch: iter_time=7.391e-05, forward_time=0.180, loss_ctc=80.739, loss_att=70.517, acc=0.255, loss=73.584, backward_time=0.076, grad_norm=15.723, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.721e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:09,884 (trainer:365) INFO: 42epoch results: [train] iter_time=0.004, forward_time=0.179, loss_ctc=78.740, loss_att=68.075, acc=0.260, loss=71.274, backward_time=0.076, grad_norm=19.279, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.707e-04, train_time=0.402, time=26.16 seconds, total_count=2730, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=76.225, cer_ctc=0.597, loss_att=71.074, acc=0.244, cer=0.686, wer=1.000, loss=72.619, time=11.22 seconds, total_count=1974, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:12,834 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:12,850 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/39epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:12,851 (trainer:299) INFO: 43/50epoch started. Estimated time to finish: 5 minutes and 18.42 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:17,144 (trainer:780) INFO: 43epoch:train:1-10batch: iter_time=0.025, forward_time=0.181, loss_ctc=80.296, loss_att=70.610, acc=0.257, loss=73.516, backward_time=0.077, grad_norm=16.693, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.731e-04, train_time=0.429\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:21,141 (trainer:780) INFO: 43epoch:train:11-20batch: iter_time=9.638e-05, forward_time=0.178, loss_ctc=77.851, loss_att=68.020, acc=0.258, loss=70.969, backward_time=0.076, grad_norm=18.150, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.737e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:25,145 (trainer:780) INFO: 43epoch:train:21-30batch: iter_time=8.771e-05, forward_time=0.179, loss_ctc=72.885, loss_att=62.965, acc=0.273, loss=65.941, backward_time=0.077, grad_norm=18.789, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.743e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:29,146 (trainer:780) INFO: 43epoch:train:31-40batch: iter_time=7.798e-05, forward_time=0.178, loss_ctc=83.836, loss_att=73.946, acc=0.255, loss=76.913, backward_time=0.077, grad_norm=19.208, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.750e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:33,141 (trainer:780) INFO: 43epoch:train:41-50batch: iter_time=7.669e-05, forward_time=0.176, loss_ctc=79.506, loss_att=69.986, acc=0.260, loss=72.842, backward_time=0.077, grad_norm=19.969, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.756e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:36,839 (trainer:780) INFO: 43epoch:train:51-60batch: iter_time=7.572e-05, forward_time=0.166, loss_ctc=84.858, loss_att=75.104, acc=0.249, loss=78.030, backward_time=0.072, grad_norm=28.433, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.762e-04, train_time=0.370\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:50,183 (trainer:365) INFO: 43epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=77.164, loss_att=67.469, acc=0.264, loss=70.377, backward_time=0.076, grad_norm=19.712, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.748e-04, train_time=0.400, time=26.03 seconds, total_count=2795, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=75.026, cer_ctc=0.591, loss_att=70.819, acc=0.247, cer=0.687, wer=1.000, loss=72.081, time=11.3 seconds, total_count=2021, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:52,208 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:52,224 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/40epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:52,225 (trainer:299) INFO: 44/50epoch started. Estimated time to finish: 4 minutes and 38.55 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:02:56,240 (trainer:780) INFO: 44epoch:train:1-10batch: iter_time=0.028, forward_time=0.167, loss_ctc=78.602, loss_att=69.888, acc=0.267, loss=72.502, backward_time=0.072, grad_norm=25.771, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.772e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:00,247 (trainer:780) INFO: 44epoch:train:11-20batch: iter_time=7.864e-05, forward_time=0.177, loss_ctc=84.643, loss_att=76.298, acc=0.254, loss=78.802, backward_time=0.077, grad_norm=18.826, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.778e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:04,238 (trainer:780) INFO: 44epoch:train:21-30batch: iter_time=7.759e-05, forward_time=0.179, loss_ctc=72.817, loss_att=64.223, acc=0.267, loss=66.801, backward_time=0.077, grad_norm=16.358, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.784e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:08,212 (trainer:780) INFO: 44epoch:train:31-40batch: iter_time=8.365e-05, forward_time=0.175, loss_ctc=82.466, loss_att=74.393, acc=0.257, loss=76.815, backward_time=0.077, grad_norm=18.507, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.791e-04, train_time=0.397\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:12,245 (trainer:780) INFO: 44epoch:train:41-50batch: iter_time=7.971e-05, forward_time=0.182, loss_ctc=71.250, loss_att=63.352, acc=0.272, loss=65.721, backward_time=0.077, grad_norm=22.843, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.797e-04, train_time=0.403\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:16,256 (trainer:780) INFO: 44epoch:train:51-60batch: iter_time=8.719e-05, forward_time=0.180, loss_ctc=68.349, loss_att=60.596, acc=0.277, loss=62.922, backward_time=0.076, grad_norm=17.642, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.803e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:29,482 (trainer:365) INFO: 44epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=75.329, loss_att=67.080, acc=0.267, loss=69.555, backward_time=0.076, grad_norm=19.671, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.789e-04, train_time=0.399, time=26.01 seconds, total_count=2860, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=72.715, cer_ctc=0.577, loss_att=70.372, acc=0.249, cer=0.678, wer=1.000, loss=71.075, time=11.25 seconds, total_count=2068, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:32,130 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:32,145 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/41epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:32,145 (trainer:299) INFO: 45/50epoch started. Estimated time to finish: 3 minutes and 58.77 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:36,647 (trainer:780) INFO: 45epoch:train:1-10batch: iter_time=0.025, forward_time=0.203, loss_ctc=69.458, loss_att=61.411, acc=0.285, loss=63.825, backward_time=0.076, grad_norm=17.170, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.813e-04, train_time=0.450\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:40,340 (trainer:780) INFO: 45epoch:train:11-20batch: iter_time=1.308e-04, forward_time=0.165, loss_ctc=83.968, loss_att=77.677, acc=0.248, loss=79.564, backward_time=0.072, grad_norm=27.665, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.819e-04, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:44,337 (trainer:780) INFO: 45epoch:train:21-30batch: iter_time=1.073e-04, forward_time=0.180, loss_ctc=72.448, loss_att=64.765, acc=0.268, loss=67.070, backward_time=0.076, grad_norm=20.372, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.826e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:48,348 (trainer:780) INFO: 45epoch:train:31-40batch: iter_time=7.655e-05, forward_time=0.180, loss_ctc=71.595, loss_att=63.657, acc=0.275, loss=66.039, backward_time=0.076, grad_norm=17.671, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.832e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:52,550 (trainer:780) INFO: 45epoch:train:41-50batch: iter_time=8.976e-05, forward_time=0.199, loss_ctc=68.027, loss_att=60.066, acc=0.277, loss=62.454, backward_time=0.077, grad_norm=15.728, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.838e-04, train_time=0.420\n",
      "[jupyter-wpc0385] 2025-07-03 11:03:56,509 (trainer:780) INFO: 45epoch:train:51-60batch: iter_time=9.737e-05, forward_time=0.172, loss_ctc=82.938, loss_att=77.041, acc=0.254, loss=78.810, backward_time=0.078, grad_norm=19.478, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.845e-04, train_time=0.396\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:09,879 (trainer:365) INFO: 45epoch results: [train] iter_time=0.004, forward_time=0.183, loss_ctc=73.937, loss_att=66.598, acc=0.270, loss=68.800, backward_time=0.076, grad_norm=19.705, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.830e-04, train_time=0.406, time=26.42 seconds, total_count=2925, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=71.439, cer_ctc=0.576, loss_att=70.087, acc=0.252, cer=0.677, wer=1.000, loss=70.492, time=11.31 seconds, total_count=2115, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:12,699 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:12,714 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/42epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:12,715 (trainer:299) INFO: 46/50epoch started. Estimated time to finish: 3 minutes and 19.06 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:16,942 (trainer:780) INFO: 46epoch:train:1-10batch: iter_time=0.025, forward_time=0.176, loss_ctc=71.221, loss_att=64.668, acc=0.272, loss=66.634, backward_time=0.077, grad_norm=15.892, clip=100.000, loss_scale=1.000optim_step_time=0.005, optim0_lr0=1.854e-04, train_time=0.422\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:20,935 (trainer:780) INFO: 46epoch:train:11-20batch: iter_time=7.606e-05, forward_time=0.176, loss_ctc=74.049, loss_att=68.551, acc=0.275, loss=70.200, backward_time=0.077, grad_norm=19.689, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.860e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:24,644 (trainer:780) INFO: 46epoch:train:21-30batch: iter_time=7.520e-05, forward_time=0.169, loss_ctc=73.039, loss_att=65.972, acc=0.278, loss=68.092, backward_time=0.071, grad_norm=26.888, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.867e-04, train_time=0.371\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:28,643 (trainer:780) INFO: 46epoch:train:31-40batch: iter_time=7.512e-05, forward_time=0.177, loss_ctc=68.539, loss_att=62.403, acc=0.280, loss=64.244, backward_time=0.077, grad_norm=17.956, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.873e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:32,642 (trainer:780) INFO: 46epoch:train:41-50batch: iter_time=7.726e-05, forward_time=0.179, loss_ctc=69.485, loss_att=63.206, acc=0.274, loss=65.090, backward_time=0.077, grad_norm=20.042, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.879e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:36,599 (trainer:780) INFO: 46epoch:train:51-60batch: iter_time=1.100e-04, forward_time=0.172, loss_ctc=84.254, loss_att=79.881, acc=0.253, loss=81.193, backward_time=0.077, grad_norm=20.959, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.886e-04, train_time=0.396\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:49,984 (trainer:365) INFO: 46epoch results: [train] iter_time=0.004, forward_time=0.176, loss_ctc=72.096, loss_att=66.068, acc=0.273, loss=67.876, backward_time=0.076, grad_norm=20.115, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.871e-04, train_time=0.399, time=25.95 seconds, total_count=2990, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=70.558, cer_ctc=0.546, loss_att=69.805, acc=0.254, cer=0.670, wer=1.000, loss=70.031, time=11.32 seconds, total_count=2162, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:52,657 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:52,673 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/43epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:52,674 (trainer:299) INFO: 47/50epoch started. Estimated time to finish: 2 minutes and 39.26 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:04:57,036 (trainer:780) INFO: 47epoch:train:1-10batch: iter_time=0.026, forward_time=0.188, loss_ctc=69.881, loss_att=64.467, acc=0.276, loss=66.091, backward_time=0.076, grad_norm=21.711, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.895e-04, train_time=0.436\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:01,050 (trainer:780) INFO: 47epoch:train:11-20batch: iter_time=7.323e-05, forward_time=0.179, loss_ctc=78.856, loss_att=75.958, acc=0.257, loss=76.827, backward_time=0.077, grad_norm=21.590, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.901e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:05,041 (trainer:780) INFO: 47epoch:train:21-30batch: iter_time=9.228e-05, forward_time=0.177, loss_ctc=75.937, loss_att=72.062, acc=0.264, loss=73.224, backward_time=0.076, grad_norm=20.776, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.908e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:08,734 (trainer:780) INFO: 47epoch:train:31-40batch: iter_time=1.274e-04, forward_time=0.164, loss_ctc=73.785, loss_att=68.479, acc=0.276, loss=70.071, backward_time=0.072, grad_norm=31.463, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.914e-04, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:12,740 (trainer:780) INFO: 47epoch:train:41-50batch: iter_time=7.484e-05, forward_time=0.179, loss_ctc=68.816, loss_att=62.802, acc=0.284, loss=64.606, backward_time=0.077, grad_norm=18.474, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.920e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:16,741 (trainer:780) INFO: 47epoch:train:51-60batch: iter_time=7.495e-05, forward_time=0.181, loss_ctc=63.746, loss_att=57.625, acc=0.286, loss=59.461, backward_time=0.076, grad_norm=15.309, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.927e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:30,183 (trainer:365) INFO: 47epoch results: [train] iter_time=0.004, forward_time=0.178, loss_ctc=70.615, loss_att=65.625, acc=0.276, loss=67.122, backward_time=0.076, grad_norm=21.419, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.913e-04, train_time=0.401, time=26.11 seconds, total_count=3055, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=68.346, cer_ctc=0.532, loss_att=69.500, acc=0.256, cer=0.674, wer=1.000, loss=69.153, time=11.4 seconds, total_count=2209, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:32,337 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:32,353 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/44epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:32,354 (trainer:299) INFO: 48/50epoch started. Estimated time to finish: 1 minute and 59.44 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:36,636 (trainer:780) INFO: 48epoch:train:1-10batch: iter_time=0.023, forward_time=0.178, loss_ctc=78.912, loss_att=77.097, acc=0.266, loss=77.642, backward_time=0.078, grad_norm=21.862, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.936e-04, train_time=0.428\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:40,643 (trainer:780) INFO: 48epoch:train:11-20batch: iter_time=7.600e-05, forward_time=0.179, loss_ctc=65.839, loss_att=61.819, acc=0.286, loss=63.025, backward_time=0.077, grad_norm=19.279, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.943e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:44,641 (trainer:780) INFO: 48epoch:train:21-30batch: iter_time=1.254e-04, forward_time=0.178, loss_ctc=69.786, loss_att=65.933, acc=0.278, loss=67.089, backward_time=0.077, grad_norm=17.823, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.949e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:48,638 (trainer:780) INFO: 48epoch:train:31-40batch: iter_time=8.588e-05, forward_time=0.180, loss_ctc=65.826, loss_att=60.890, acc=0.284, loss=62.370, backward_time=0.076, grad_norm=20.664, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.955e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:52,640 (trainer:780) INFO: 48epoch:train:41-50batch: iter_time=8.854e-05, forward_time=0.178, loss_ctc=69.196, loss_att=65.208, acc=0.286, loss=66.405, backward_time=0.077, grad_norm=17.985, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.962e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:05:56,647 (trainer:780) INFO: 48epoch:train:51-60batch: iter_time=7.494e-05, forward_time=0.180, loss_ctc=64.085, loss_att=59.081, acc=0.293, loss=60.582, backward_time=0.076, grad_norm=17.021, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=1.968e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:09,624 (trainer:365) INFO: 48epoch results: [train] iter_time=0.004, forward_time=0.175, loss_ctc=68.987, loss_att=64.949, acc=0.282, loss=66.160, backward_time=0.076, grad_norm=20.404, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.954e-04, train_time=0.398, time=25.92 seconds, total_count=3120, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=67.451, cer_ctc=0.532, loss_att=69.022, acc=0.262, cer=0.669, wer=1.000, loss=68.551, time=11.35 seconds, total_count=2256, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:11,813 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:11,827 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/45epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:11,827 (trainer:299) INFO: 49/50epoch started. Estimated time to finish: 1 minute and 19.61 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:16,141 (trainer:780) INFO: 49epoch:train:1-10batch: iter_time=0.024, forward_time=0.184, loss_ctc=66.268, loss_att=62.370, acc=0.292, loss=63.539, backward_time=0.076, grad_norm=17.741, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=1.977e-04, train_time=0.431\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:19,856 (trainer:780) INFO: 49epoch:train:11-20batch: iter_time=1.016e-04, forward_time=0.166, loss_ctc=70.815, loss_att=68.847, acc=0.280, loss=69.437, backward_time=0.072, grad_norm=36.194, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.984e-04, train_time=0.371\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:23,823 (trainer:780) INFO: 49epoch:train:21-30batch: iter_time=1.003e-04, forward_time=0.173, loss_ctc=74.559, loss_att=72.405, acc=0.274, loss=73.051, backward_time=0.077, grad_norm=23.787, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.990e-04, train_time=0.397\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:27,817 (trainer:780) INFO: 49epoch:train:31-40batch: iter_time=7.881e-05, forward_time=0.176, loss_ctc=72.845, loss_att=69.522, acc=0.280, loss=70.519, backward_time=0.078, grad_norm=24.070, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.996e-04, train_time=0.399\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:31,848 (trainer:780) INFO: 49epoch:train:41-50batch: iter_time=8.612e-05, forward_time=0.182, loss_ctc=62.746, loss_att=58.250, acc=0.299, loss=59.599, backward_time=0.077, grad_norm=18.662, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.003e-04, train_time=0.403\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:35,846 (trainer:780) INFO: 49epoch:train:51-60batch: iter_time=8.629e-05, forward_time=0.178, loss_ctc=65.567, loss_att=62.550, acc=0.285, loss=63.455, backward_time=0.077, grad_norm=19.468, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.009e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:49,120 (trainer:365) INFO: 49epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=67.795, loss_att=64.426, acc=0.287, loss=65.437, backward_time=0.076, grad_norm=22.829, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=1.995e-04, train_time=0.400, time=26.05 seconds, total_count=3185, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=66.303, cer_ctc=0.516, loss_att=69.020, acc=0.261, cer=0.672, wer=1.000, loss=68.205, time=11.24 seconds, total_count=2303, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:51,863 (trainer:431) INFO: There are no improvements in this epoch\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:51,878 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/46epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:51,878 (trainer:299) INFO: 50/50epoch started. Estimated time to finish: 39.81 seconds\n",
      "[jupyter-wpc0385] 2025-07-03 11:06:56,142 (trainer:780) INFO: 50epoch:train:1-10batch: iter_time=0.026, forward_time=0.176, loss_ctc=58.030, loss_att=54.498, acc=0.313, loss=55.557, backward_time=0.077, grad_norm=16.486, clip=100.000, loss_scale=1.000optim_step_time=0.006, optim0_lr0=2.018e-04, train_time=0.426\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:00,138 (trainer:780) INFO: 50epoch:train:11-20batch: iter_time=1.015e-04, forward_time=0.179, loss_ctc=65.497, loss_att=63.491, acc=0.292, loss=64.093, backward_time=0.076, grad_norm=17.897, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.025e-04, train_time=0.400\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:04,152 (trainer:780) INFO: 50epoch:train:21-30batch: iter_time=8.082e-05, forward_time=0.178, loss_ctc=69.041, loss_att=67.372, acc=0.285, loss=67.873, backward_time=0.077, grad_norm=18.557, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.031e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:07,839 (trainer:780) INFO: 50epoch:train:31-40batch: iter_time=1.117e-04, forward_time=0.166, loss_ctc=66.436, loss_att=64.602, acc=0.292, loss=65.152, backward_time=0.071, grad_norm=27.715, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.037e-04, train_time=0.369\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:11,852 (trainer:780) INFO: 50epoch:train:41-50batch: iter_time=8.874e-05, forward_time=0.180, loss_ctc=66.429, loss_att=64.151, acc=0.289, loss=64.834, backward_time=0.077, grad_norm=19.282, clip=100.000, loss_scale=1.000, optim_step_time=0.005, optim0_lr0=2.044e-04, train_time=0.401\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:15,906 (trainer:780) INFO: 50epoch:train:51-60batch: iter_time=1.082e-04, forward_time=0.181, loss_ctc=71.200, loss_att=69.406, acc=0.283, loss=69.944, backward_time=0.078, grad_norm=22.537, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.050e-04, train_time=0.405\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:29,175 (trainer:365) INFO: 50epoch results: [train] iter_time=0.004, forward_time=0.177, loss_ctc=66.017, loss_att=63.769, acc=0.292, loss=64.444, backward_time=0.076, grad_norm=20.421, clip=100.000, loss_scale=1.000, optim_step_time=0.006, optim0_lr0=2.036e-04, train_time=0.401, time=26.09 seconds, total_count=3250, gpu_max_cached_mem_GB=27.410, [valid] loss_ctc=64.890, cer_ctc=0.506, loss_att=68.302, acc=0.266, cer=0.665, wer=1.000, loss=67.279, time=11.2 seconds, total_count=2350, gpu_max_cached_mem_GB=27.410\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:31,725 (trainer:433) INFO: The best model has been updated: valid.acc\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:31,740 (trainer:487) INFO: The model files were removed: exp/train_asr_branchformer_e24_amp/47epoch.pth\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:31,741 (trainer:505) INFO: The training was finished at 50 epochs \n",
      "[jupyter-wpc0385] 2025-07-03 11:07:31,741 (average_nbest_models:69) INFO: Averaging 3best models: criterion=\"valid.acc\": exp/train_asr_branchformer_e24_amp/valid.acc.ave_3best.pth\n",
      "/opt/conda/envs/espnet/lib/python3.10/site-packages/espnet2/main_funcs/average_nbest_models.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _loaded[e] = torch.load(\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:35,992 (average_nbest_models:96) INFO: Accumulating encoder.encoders.0.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:35,993 (average_nbest_models:96) INFO: Accumulating encoder.encoders.1.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,092 (average_nbest_models:96) INFO: Accumulating encoder.encoders.2.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,192 (average_nbest_models:96) INFO: Accumulating encoder.encoders.3.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,291 (average_nbest_models:96) INFO: Accumulating encoder.encoders.4.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,391 (average_nbest_models:96) INFO: Accumulating encoder.encoders.5.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,491 (average_nbest_models:96) INFO: Accumulating encoder.encoders.6.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,591 (average_nbest_models:96) INFO: Accumulating encoder.encoders.7.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,592 (average_nbest_models:96) INFO: Accumulating encoder.encoders.8.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,692 (average_nbest_models:96) INFO: Accumulating encoder.encoders.9.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,791 (average_nbest_models:96) INFO: Accumulating encoder.encoders.10.conv_module.norm.num_batches_tracked instead of averaging\n",
      "[jupyter-wpc0385] 2025-07-03 11:07:36,891 (average_nbest_models:96) INFO: Accumulating encoder.encoders.11.conv_module.norm.num_batches_tracked instead of averaging\n"
     ]
    }
   ],
   "source": [
    "trainer.train() # Start the training process using the Trainer class.\n",
    "# This executes the training loop.\n",
    "# 1. Forward pass: The model processes the input data and generates predictions.\n",
    "# 2. Loss calculation: The loss function computes the difference between the predicted and actual values. \n",
    "# Combines CTC and attention losses.\n",
    "# 3. Backpropagation: The gradients are calculated and used to update the model parameters.\n",
    "# 4. Validation: The model is evaluated on the validation set to monitor its performance.\n",
    "# 5. Model saving: The best model is saved based on the validation performance.\n",
    "\n",
    "# MODEL ARCHITECTURE FLOW\n",
    "# The model architecture consists of an encoder and a decoder.\n",
    "# The encoder processes the input audio features and generates a sequence of hidden states.\n",
    "# The decoder takes these hidden states and generates the output text sequence.\n",
    "# The encoder uses a conformer architecture, which combines convolutional and self-attention mechanisms.\n",
    "# The decoder uses a transformer architecture with attention mechanisms.\n",
    "# The training process involves optimizing the model parameters using a hybrid CTC/attention loss function.\n",
    "# The CTC loss allows the model to learn alignments between input and output sequences, while the attention loss helps the model focus on relevant parts of the input during decoding.\n",
    "# The training process iteratively updates the model parameters to minimize the loss function, improving the model's performance on the ASR task.\n",
    "# The model is trained using a dataset of audio recordings and their corresponding transcriptions.\n",
    "\n",
    "# 1. Audio Input (16khz waveform)\n",
    "# 2. Frontend Feature Extraction (mel-spectrogram)\n",
    "# 3. Encoder (Conformer)\n",
    "#    - Convolutional layers (Conv2D input layer)\n",
    "#    - 12 Conformer blocks (self-attention, feed-forward, and CNN modules)\n",
    "#    - Outputs acoustic representation (256-dimensional features)\n",
    "# 4. Decoder (Transformer)\n",
    "#    - 6 Transformer blocks (self-attention, feed-forward)\n",
    "#    - Outputs text sequence (token IDs)\n",
    "# 5. Output: BPE tokens (text sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d__0SgXCQ7UJ"
   },
   "source": [
    "## Inference\n",
    "You can just use the inference API of the ESPnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using legacy_rel_pos and it will be deprecated in the future.\n",
      "WARNING:root:Using legacy_rel_selfattn and it will be deprecated in the future.\n"
     ]
    }
   ],
   "source": [
    "# How to use the trained model for inference\n",
    "# Loads the trained model with specified configurations and performs inference on audio data.\n",
    "# Beam search: uses beam_size = 20 for better accuracy. Beam search is a decoding strategy that explores multiple possible output sequences to find the most likely one.\n",
    "# It maintains a fixed number of hypotheses (beam size) at each decoding step, allowing it to consider multiple paths in the output space.\n",
    "# This helps improve the accuracy of the transcriptions by exploring different possible sequences and selecting the most likely one based on the model's predictions.\n",
    "# Language model (LM) integration: uses a language model to improve transcription accuracy.\n",
    "# The language model is trained separately and is used to provide context and improve the accuracy of the transcriptions.\n",
    "# The LM weight is set to 0.2, which balances the contribution of the language model and the acoustic model during decoding.\n",
    "# The CTC weight is set to 0.8, which determines the influence of the CTC loss in the hybrid CTC/attention decoding\n",
    "# process. This weight can be adjusted to compare CTC and attention decoding.\n",
    "\n",
    "\n",
    "from espnet2.bin.asr_inference import Speech2Text\n",
    "\n",
    "m = Speech2Text(\n",
    "    asr_train_config=\"./exp/train_asr_branchformer_e24_amp/config.yaml\",\n",
    "    asr_model_file=\"./exp/train_asr_branchformer_e24_amp/valid.acc.best.pth\",\n",
    "    lm_train_config=\"exp/lm/cy/rnn/config.yaml\",  # LM config\n",
    "    lm_file=\"exp/lm/cy/rnn/valid.loss.ave.pth\",  # LM model\n",
    "    token_type=\"bpe\",\n",
    "    bpemodel=\"data/bpemodel/bpe.model\",\n",
    "    device=\"cuda\",\n",
    "    beam_size=20, # Beam size for decoding\n",
    "    lm_weight=0.2,\n",
    "    ctc_weight=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADDgu6ttQ7UJ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Yr oedd yn wedwr llai, gan yr eglwys arfantus.\n",
      "Label: Yr oedd yn bregethwr lleyg yn yr Eglwys\n"
     ]
    }
   ],
   "source": [
    "import librosa # librosa is a Python library for audio and music analysis.\n",
    "\n",
    "i = 5 # Index of the sample to be processed\n",
    "\n",
    "with open(\"./dump/valid/wav.scp\", \"r\") as f: # Read the audio file paths\n",
    "    sample_path = f.readlines()[i]\n",
    "\n",
    "with open(\"./dump/valid/text\", \"r\") as f: # Read the transcriptions\n",
    "    transription = \" \".join(f.readlines()[i].split(\" \")[1:-1])\n",
    "\n",
    "y, sr = librosa.load(sample_path.split()[1], sr=16000, mono=True)\n",
    "nbests = m(y) # run inference on (n) number of best performing models\n",
    "text, *_ = nbests[0] # get the 1st (best) model result\n",
    "\n",
    "print(\"Predicted:\", text)\n",
    "print(\"Label:\", transription)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "espnet",
   "language": "python",
   "name": "espnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
